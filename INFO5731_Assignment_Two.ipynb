{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USSdXHuqnwv9"
   },
   "source": [
    "# **INFO5731 Assignment Two**\n",
    "\n",
    "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWxodXh5n4xF"
   },
   "source": [
    "# **Question 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TenBkDJ5n95k"
   },
   "source": [
    "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
    "\n",
    "(1) Collect all the customer reviews of the product [2019 Dell labtop](https://www.amazon.com/Dell-Inspiron-5000-5570-Laptop/dp/B07N49F51N/ref=sr_1_11?crid=1IJ7UWF2F4GHH&keywords=dell%2Bxps%2B15&qid=1580173569&sprefix=dell%2Caps%2C181&sr=8-11&th=1) on amazon.\n",
    "\n",
    "(2) Collect the top 100 User Reviews of the film [Joker](https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv) from IMDB.\n",
    "\n",
    "(3) Collect the abstracts of the top 100 research papers by using the query [natural language processing](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
    "\n",
    "(4) Collect the top 100 tweets by using hashtag [\"#CovidVaccine\"](https://twitter.com/hashtag/CovidVaccine) from Twitter. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuFPKhC0m1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\racha\\.conda\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\racha\\.conda\\lib\\site-packages (from beautifulsoup4) (2.0.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Tag.prettify of <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n",
       "\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
       "\n",
       "<html lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\">\n",
       "<head profile=\"http://www.w3.org/2005/11/profile http://a9.com/-/spec/opensearch/1.1/\">\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
       "<meta content=\"/images/csx_logo_front.png\" property=\"og:image\"/>\n",
       "<title>CiteSeerX — Search Results — natural language processing</title>\n",
       "<meta content=\"CiteSeerX - Scientific articles matching the query: natural language processing\" name=\"description\"/>\n",
       "<meta content=\"CiteSeerX, natural language processing\" name=\"keywords\"/>\n",
       "<link href=\"/favicon.ico;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
       "<link href=\"/search_plugins/citeseerx_general.xml;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" rel=\"search\" title=\"CiteSeerX\" type=\"application/opensearchdescription+xml\"/>\n",
       "<link href=\"/search_plugins/citeseerx_author.xml;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" rel=\"search\" title=\"CiteSeerX Author\" type=\"application/opensearchdescription+xml\"/>\n",
       "<link href=\"/search_plugins/citeseerx_title.xml;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" rel=\"search\" title=\"CiteSeerX Title\" type=\"application/opensearchdescription+xml\"/>\n",
       "<link href=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc&amp;sort=rlv&amp;feed=atom\" rel=\"alternate\" title=\"CiteSeerX Search Results - Atom\" type=\"application/atom+xml\"/>\n",
       "<link href=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc&amp;sort=rlv&amp;feed=rss\" rel=\"alternate\" title=\"CiteSeerX Search Results - RSS\" type=\"application/rss+xml\"/>\n",
       "<link href=\"/css/main.css;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<script src=\"/js/jquery-1.4.2.min.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/jquery-ui-1.8.custom.min.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/jquery.idTabs.min.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/metacart.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/topnav.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/citeseerx.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/correctionutils.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/checkboxes.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/ga.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "<script src=\"/js/s2button.js;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"text/javascript\"></script>\n",
       "</head>\n",
       "<body>\n",
       "<div id=\"wrapper\">\n",
       "<div id=\"topnav\">\n",
       "<ul id=\"search_nav\">\n",
       "<li class=\"active\"><a class=\"slink\" href=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural language processing&amp;t=doc&amp;sort=rlv\">Documents</a></li>\n",
       "<li><a class=\"slink\" href=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural language processing&amp;t=auth&amp;uauth=1&amp;sort=ndocs\">Authors</a></li>\n",
       "<li><a class=\"slink\" href=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural language processing&amp;t=table&amp;sort=rlv\">Tables</a></li>\n",
       "</ul>\n",
       "<ul id=\"toptools\">\n",
       "<li><a href=\"/myciteseer/login;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\">Log in</a></li>\n",
       "<li><a href=\"/mcsutils/newAccount;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\">Sign up</a></li>\n",
       "<li><a href=\"/metacart;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\">MetaCart</a></li>\n",
       "<li><a href=\"https://www.psu.edu/copyright-information/\" target=\"_blank\">DMCA</a></li>\n",
       "<li><a href=\"http://www.givenow.psu.edu/CiteseerxFund\"><font color=\"#045FB4\">Donate</font></a></li>\n",
       "</ul>\n",
       "</div>\n",
       "<div id=\"header\">\n",
       "<h1 id=\"title\"><a href=\"/;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" title=\"CiteSeerX\"><img alt=\"CiteSeerX logo\" height=\"50%\" src=\"/images/csx_logo.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" width=\"50%\"/></a></h1>\n",
       "</div>\n",
       "<div id=\"main\">\n",
       "<div id=\"search\">\n",
       "<div id=\"search_docs\">\n",
       "<form action=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" enctype=\"application/x-www-form-urlencoded\" method=\"get\">\n",
       "<label>Documents:</label>\n",
       "<input class=\"s_field\" name=\"q\" type=\"text\" value=\"natural language processing\"/>\n",
       "<input alt=\"Search\" class=\"s_button\" name=\"submit\" onclick='this.form.action=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\"; return true;' src=\"/images/search_icon.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"image\" value=\"Search\"/>\n",
       "<input alt=\"Semantic Scholar\" class=\"s_button\" name=\"s2\" onclick=\"this.form.action='https://www.semanticscholar.org/search'; return true;\" src=\"/images/s2_icon.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" type=\"image\" value=\"Semantic Scholar\"/>\n",
       "<div class=\"opts\">\n",
       "<a href=\"/advanced_search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" title=\"Search full text, title, abstract, date, author name, author affiliation, etc.\">Advanced Search</a>\n",
       "<input class=\"c_box\" name=\"ic\" type=\"checkbox\" value=\"1\"/> Include Citations\n",
       "\t\t   </div>\n",
       "<input name=\"sort\" type=\"hidden\" value=\"rlv\"/>\n",
       "<input name=\"t\" type=\"hidden\" value=\"doc\"/>\n",
       "</form>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"sidebar\" id=\"content\">\n",
       "<div id=\"sidebar\">\n",
       "<h3>Tools</h3>\n",
       "<!-- <div id=\"feeds\">\n",
       "    <a href=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&t=doc&sort=rlv&feed=rss\"><img src=\"/images/rss.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" alt=\"RSS\"/></a>\n",
       "  </div> -->\n",
       "<div id=\"sorting\">Sorted by: \n",
       "    <select class=\"pulldown\" id=\"sortvalue\" name=\"sortvalue\" onchange=\"location = this.options[this.selectedIndex].value;\">\n",
       "<option selected=\"\" value=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc\">Relevance</option>\n",
       "<option value=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc&amp;sort=cite\">Citation Count</option>\n",
       "<option value=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc&amp;sort=date\">Year (Descending)</option>\n",
       "<option value=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc&amp;sort=ascdate\">Year (Ascending)</option>\n",
       "<option value=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc&amp;sort=recent\">Recency</option>\n",
       "</select>\n",
       "</div>\n",
       "<div id=\"qother\">Try your query at:\n",
       "    \n",
       "    \n",
       "    \n",
       "    \n",
       "    \n",
       "    \n",
       "    <table border=\"0\" cellpadding=\"5\" cellspacing=\"5\">\n",
       "<tr>\n",
       "<td><a href=\"https://www.semanticscholar.org/search?q=natural+language+processing\" title=\"AllenAI Semantic Scholar\"><img alt=\"Semantic Scholar\" height=\"30\" src=\"/images/ai2_icon.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" width=\"30\"/></a></td>\n",
       "<td><a href=\"http://scholar.google.com/scholar?q=natural+language+processing&amp;hl=en&amp;btnG=Search\" title=\"Google Scholar\"><img alt=\"Scholar\" height=\"24\" src=\"/images/googlescholar_icon.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" width=\"24\"/></a></td>\n",
       "<td><a href=\"http://academic.research.microsoft.com/Search.aspx?query=natural+language+processing&amp;submit=Search\" title=\"Microsoft Academic Search\"><img alt=\"Academic\" height=\"24\" src=\"/images/microsoftacademicsearch_icon.jpg;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" width=\"24\"/></a></td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td><a href=\"https://www.google.com/search?q=natural+language+processing\" title=\"Google\"><img alt=\"Google\" height=\"24\" src=\"/images/google_icon.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" width=\"24\"/></a></td>\n",
       "<td><a href=\"http://www.bing.com/search?q=natural+language+processing\" title=\"Bing\"><img alt=\"Bing\" height=\"24\" src=\"/images/bing_icon.ico;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" width=\"24\"/></a></td>\n",
       "<td><a href=\"http://dblp.uni-trier.de/search?q=natural+language+processing\" title=\"DBLP Computer Science Bibliography\"><img alt=\"DBLP\" height=\"30\" src=\"/images/dblp_icon.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" width=\"30\"/></a></td>\n",
       "</tr>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div id=\"result_info\">\n",
       "      \n",
       "\n",
       "Results <strong>1 - 10\n",
       "</strong> of\n",
       "<strong>136,310</strong>\n",
       "<div id=\"pager\">\n",
       "<a href=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc&amp;sort=rlv&amp;start=10\">Next 10 →</a>\n",
       "</div>\n",
       "</div>\n",
       "<div id=\"result_list\">\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.121.2604&amp;rank=1&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "                  Foundations of statistical <em>natural</em> <em>language</em> <em>processing</em>\n",
       "</a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Christopher D. Manning,  Hinrich Schütze\n",
       "                  \n",
       "                </span>\n",
       "<span class=\"pubyear\">, 2000</span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"...   ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                 - \n",
       "                  <a class=\"citation remove\" href=\"/showciting;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?cid=21019\" title=\"number of citations\">Cited by 1139 (5 self)</a>\n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(21019)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_21019\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "                    Abstract not found\n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.121.2604&amp;rft.atitle=Foundations+of+statistical+%3Cem%3Enatural%3C%2Fem%3E+%3Cem%3Elanguage%3C%2Fem%3E+%3Cem%3Eprocessing%3C%2Fem%3E&amp;rft.jtitle=&amp;rft.date=2000&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=Manning&amp;rft.aufirst=+Christopher+D.&amp;rft.au=Manning%2C+Christopher+D.&amp;rft.au=Sch%C3%BCtze%2C+Hinrich\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.103.7637&amp;rank=2&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "                  A Maximum Entropy approach to <em>Natural</em> <em>Language</em> <em>Processing</em>\n",
       "</a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Adam L. Berger, Stephen A. Della Pietra  , Vincent J. Della Pietra  \n",
       "                  \n",
       "                </span>\n",
       "<span class=\"pubvenue\">- COMPUTATIONAL LINGUISTICS</span>\n",
       "<span class=\"pubyear\">, 1996</span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"... The concept of maximum entropy can be traced back along multiple threads to Biblical times. Only recently, however, have computers become powerful enough to permit the widescale application of this concept to real world problems in statistical estimation and pattern recognition. In this paper we des ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                 - \n",
       "                  <a class=\"citation remove\" href=\"/showciting;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?cid=10728\" title=\"number of citations\">Cited by 1366 (5 self)</a>\n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(10728)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_10728\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "                     describe a method for statistical modeling based on maximum entropy. We present a maximum-likelihood approach for automatically constructing maximum entropy models and describe how to implement this approach efficiently, using as examples several problems in <em>natural</em> <em>language</em> <em>processing</em>.  \n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.103.7637&amp;rft.atitle=A+Maximum+Entropy+approach+to+%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3ELanguage%3C%2Fem%3E+%3Cem%3EProcessing%3C%2Fem%3E&amp;rft.jtitle=COMPUTATIONAL+LINGUISTICS&amp;rft.date=1996&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=Berger&amp;rft.aufirst=+Adam+L.&amp;rft.au=Berger%2C+Adam+L.&amp;rft.au=Pietra%2C+Stephen+A.+Della&amp;rft.au=Pietra%2C+Vincent+J.+Della\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.905.8483&amp;rank=3&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "<em>Natural</em> <em>Language</em> <em>Processing</em>\n",
       "</a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Cohn Trevor A, Trevor A. Cohn\n",
       "                  \n",
       "                </span>\n",
       "<span class=\"pubyear\">, 2007</span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"... Scaling conditional random fields for natural language processing Terms and Conditions: Terms and Conditions: Copyright in works deposited in Minerva Access is retained by the ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(64380258)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_64380258\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "                    Scaling conditional random fields for <em>natural</em> <em>language</em> <em>processing</em> Terms and Conditions: Terms and Conditions: Copyright in works deposited in Minerva Access is retained by the\n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.905.8483&amp;rft.atitle=%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3ELanguage%3C%2Fem%3E+%3Cem%3EProcessing%3C%2Fem%3E&amp;rft.jtitle=&amp;rft.date=2007&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=A&amp;rft.aufirst=+Cohn+Trevor&amp;rft.au=A%2C+Cohn+Trevor&amp;rft.au=Cohn%2C+Trevor+A.\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.463.8510&amp;rank=4&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "                  Linguistics and <em>Natural</em> <em>Language</em> <em>Processing</em>\n",
       "</a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Victor Raskin\n",
       "                  \n",
       "                </span>\n",
       "<span class=\"pubvenue\">- Machine Translation: Theoretical and Methodological Issues</span>\n",
       "<span class=\"pubyear\">, 1987</span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"... The paper addresses the issue of cooperation between linguistics and natural language processing (NLP), in general, and between linguistics and machine translation (MT), in particular. It focuses on just one direction of such cooperation, namely applications of linguistics to NLP, virtually ignoring ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                 - \n",
       "                  <a class=\"citation remove\" href=\"/showciting;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?cid=899745\" title=\"number of citations\">Cited by 6 (3 self)</a>\n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(899745)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_899745\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "                    The paper addresses the issue of cooperation between linguistics and <em>natural</em> <em>language</em> <em>processing</em> (NLP), in general, and between linguistics and machine translation (MT), in particular. It focuses on just one direction of such cooperation, namely applications of linguistics to NLP, virtually\n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.463.8510&amp;rft.atitle=Linguistics+and+%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3ELanguage%3C%2Fem%3E+%3Cem%3EProcessing%3C%2Fem%3E&amp;rft.jtitle=MACHINE+TRANSLATION%3A+THEORETICAL+AND+METHODOLOGICAL+ISSUES&amp;rft.date=1987&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=Raskin&amp;rft.aufirst=+Victor&amp;rft.au=Raskin%2C+Victor\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.21.6514&amp;rank=5&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "<em>Natural</em> <em>Language</em> <em>Processing</em>\n",
       "</a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Enrico Franconi\n",
       "                  \n",
       "                </span>\n",
       "<span class=\"pubyear\">, 2001</span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"... In most natural language processing applications, Description Logics have been used to encode in a knowledge base some syntactic, semantic, and pragmatic elements needed to drive the semantic interpretation and the natural language generation processes. More recently, Description Logics have been us ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                 - \n",
       "                  <a class=\"citation remove\" href=\"/showciting;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?cid=1965661\" title=\"number of citations\">Cited by 4 (0 self)</a>\n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(1965661)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_1965661\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "                    In most <em>natural</em> <em>language</em> <em>processing</em> applications, Description Logics have been used to encode in a knowledge base some syntactic, semantic, and pragmatic elements needed to drive the semantic interpretation and the <em>natural</em> <em>language</em> generation <em>processes</em>. More recently, Description Logics have been\n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.21.6514&amp;rft.atitle=%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3ELanguage%3C%2Fem%3E+%3Cem%3EProcessing%3C%2Fem%3E&amp;rft.jtitle=&amp;rft.date=2001&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=Franconi&amp;rft.aufirst=+Enrico&amp;rft.au=Franconi%2C+Enrico\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.231.4614&amp;rank=6&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "<em>Natural</em> <em>language</em> <em>processing</em> (almost) from scratch \n",
       "                  </a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen, Koray Kavukcuoglu, Pavel Kuksa\n",
       "                  \n",
       "                </span>\n",
       "<span class=\"pubyear\">, 2011</span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"... We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific eng ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                 - \n",
       "                  <a class=\"citation remove\" href=\"/showciting;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?cid=13197488\" title=\"number of citations\">Cited by 248 (18 self)</a>\n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(13197488)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_13197488\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "                    We propose a unified neural network architecture and learning algorithm that can be applied to various <em>natural</em> <em>language</em> <em>processing</em> tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task\n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.231.4614&amp;rft.atitle=%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3Elanguage%3C%2Fem%3E+%3Cem%3Eprocessing%3C%2Fem%3E+%28almost%29+from+scratch+&amp;rft.jtitle=&amp;rft.date=2011&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=Collobert&amp;rft.aufirst=+Ronan&amp;rft.au=Collobert%2C+Ronan&amp;rft.au=Weston%2C+Jason&amp;rft.au=Bottou%2C+L%C3%A9on&amp;rft.au=Karlen%2C+Michael&amp;rft.au=Kavukcuoglu%2C+Koray&amp;rft.au=Kuksa%2C+Pavel\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.650.6553&amp;rank=7&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "<em>Natural</em> <em>language</em> <em>processing</em>\n",
       "</a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Mark Steedman, Linc Lab, Mark Steedman, Mark Steedman\n",
       "                  \n",
       "                </span>\n",
       "<span class=\"pubvenue\">- In M. Boden (Ed.), Artificial Intelligence</span>\n",
       "<span class=\"pubyear\">, 1996</span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"... Natural Language Processing The subject of Natural Language Processing can be considered in both broad and narrow senses. In the broad sense, it covers processing issues at all levels of natural language understanding, including speech recognition, syntactic and semantic analysis of sentences, refer ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                 - \n",
       "                  <a class=\"citation remove\" href=\"/showciting;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?cid=39507340\" title=\"number of citations\">Cited by 2 (0 self)</a>\n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(39507340)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_39507340\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "<em>Natural</em> <em>Language</em> <em>Processing</em> The subject of <em>Natural</em> <em>Language</em> <em>Processing</em> can be considered in both broad and narrow senses. In the broad sense, it covers <em>processing</em> issues at all levels of <em>natural</em> <em>language</em> understanding, including speech recognition, syntactic and semantic analysis of sentences\n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.650.6553&amp;rft.atitle=%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3Elanguage%3C%2Fem%3E+%3Cem%3Eprocessing%3C%2Fem%3E&amp;rft.jtitle=IN+M.+BODEN+%28ED.%29%2C+ARTIFICIAL+INTELLIGENCE&amp;rft.date=1996&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=Steedman&amp;rft.aufirst=+Mark&amp;rft.au=Steedman%2C+Mark&amp;rft.au=Lab%2C+Linc&amp;rft.au=Steedman%2C+Mark&amp;rft.au=Steedman%2C+Mark\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.91.9793&amp;rank=8&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "<em>Natural</em> <em>Language</em> <em>Processing</em>/Robotics\n",
       "                  </a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Timothy Brick\n",
       "                  \n",
       "                </span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"... Robots that interact with humans face-to-face using natural language need to be responsive to the way humans use language in those situations. We propose a psychologicallyinspired natural language processing system for robots which performs incremental semantic interpretation of spoken utterances, i ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(5167262)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_5167262\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "                    Robots that interact with humans face-to-face using <em>natural</em> <em>language</em> need to be responsive to the way humans use <em>language</em> in those situations. We propose a psychologicallyinspired <em>natural</em> <em>language</em> <em>processing</em> system for robots which performs incremental semantic interpretation of spoken utterances\n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.91.9793&amp;rft.atitle=%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3ELanguage%3C%2Fem%3E+%3Cem%3EProcessing%3C%2Fem%3E%2FRobotics&amp;rft.jtitle=&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=Brick&amp;rft.aufirst=+Timothy&amp;rft.au=Brick%2C+Timothy\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.100.4660&amp;rank=9&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "                  Tutorial on <em>Natural</em> <em>Language</em> <em>Processing</em>\n",
       "</a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  unknown authors\n",
       "                  \n",
       "                </span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"... Natural languages are languages spoken by humans. Currently we are not yet at the point where these languages in all of their unprocessed forms can be understood by computers. Natural language processing is the collection of techniques employed to try and accomplish that goal. The field of natural l ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(279427)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_279427\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "<em>Natural</em> <em>languages</em> are <em>languages</em> spoken by humans. Currently we are not yet at the point where these <em>languages</em> in all of their unprocessed forms can be understood by computers. <em>Natural</em> <em>language</em> <em>processing</em> is the collection of techniques employed to try and accomplish that goal. The field of <em>natural</em>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.100.4660&amp;rft.atitle=Tutorial+on+%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3ELanguage%3C%2Fem%3E+%3Cem%3EProcessing%3C%2Fem%3E&amp;rft.jtitle=&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=authors&amp;rft.aufirst=+unknown&amp;rft.au=authors%2C+unknown\"></span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"result\">\n",
       "<h3>\n",
       "<a class=\"remove doc_details\" href=\"/viewdoc/summary;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?doi=10.1.1.1065.7780&amp;rank=10&amp;q=natural language processing&amp;osm=&amp;ossid=\">\n",
       "                  Ambiguities in <em>Natural</em> <em>Language</em> <em>Processing</em>\n",
       "</a>\n",
       "</h3>\n",
       "<div class=\"pubinfo\">\n",
       "<span class=\"authors\">by \n",
       "                  Anjali M , Babu Anto \n",
       "                  \n",
       "                </span>\n",
       "</div>\n",
       "<div class=\"snippet\">\"...  ABSTRACT: Ambiguity can be referred as the ability of having more than one meaning or being understood in more than one way. Natural languages are ambiguous, so computers are not able to understand language the way people do. Natural Language Processing (NLP) is concerned with the development of co ...\"</div>\n",
       "<div class=\"pubextras\">\n",
       "<a class=\"abstract_toggle\">Abstract</a>\n",
       "                \n",
       "                \n",
       "                - <a class=\"save_doc\" onclick=\"addToCartProxy(75621707)\">Add to MetaCart</a>\n",
       "<span class=\"cartmsg\" id=\"cmsg_75621707\"></span>\n",
       "<div class=\"pubabstract\">\n",
       "                     ABSTRACT: Ambiguity can be referred as the ability of having more than one meaning or being understood in more than one way. <em>Natural</em> <em>languages</em> are ambiguous, so computers are not able to understand <em>language</em> the way people do. <em>Natural</em> <em>Language</em> <em>Processing</em> (NLP) is concerned with the development\n",
       "                  </div>\n",
       "</div>\n",
       "<div class=\"pubtools\">\n",
       "<span class=\"Z3988\" title=\"url_ver=Z39.88-2004&amp;url_ctx_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Actx&amp;ctx_ver=Z39.88-2004&amp;ctx_enc=info%3Aofi%2Fenc%3AUTF-8&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.1065.7780&amp;rft.atitle=Ambiguities+in+%3Cem%3ENatural%3C%2Fem%3E+%3Cem%3ELanguage%3C%2Fem%3E+%3Cem%3EProcessing%3C%2Fem%3E&amp;rft.jtitle=&amp;rft.pages=&amp;rft.genre=unknown&amp;rft.aulast=M&amp;rft.aufirst=+Anjali&amp;rft.au=M%2C+Anjali&amp;rft.au=Anto%2C+Babu\"></span>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div id=\"result_info\">\n",
       "<div id=\"pager\">\n",
       "<a href=\"/search;jsessionid=15E105695A57E1D3C11FC8C4908BAB63?q=natural+language+processing&amp;t=doc&amp;sort=rlv&amp;start=10\">Next 10 →</a>\n",
       "</div>\n",
       "        \n",
       "\n",
       "Results <strong>1 - 10\n",
       "</strong> of\n",
       "<strong>136,310</strong>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"clear\"></div>\n",
       "</div>\n",
       "<div id=\"footer\">\n",
       "<div id=\"sponsors\">\n",
       "        \n",
       "        Powered by:\n",
       "  \t<a href=\"http://lucene.apache.org/solr/\"><img alt=\"Apache Solr\" height=\"8%\" src=\"/images/solrlogo1.png;jsessionid=15E105695A57E1D3C11FC8C4908BAB63\" width=\"8%\"/></a>\n",
       "</div>\n",
       "<ul class=\"links\">\n",
       "<li><a href=\"http://csxstatic.ist.psu.edu/home\" target=\"_blank\">About CiteSeerX</a></li>\n",
       "<li><a href=\"http://csxcrawlweb01.ist.psu.edu/submit_pub/\" target=\"_blank\">Submit and Index Documents</a></li>\n",
       "<li><a href=\"http://csxstatic.ist.psu.edu/privacy-policy\" target=\"_blank\">Privacy Policy</a></li>\n",
       "<li><a href=\"http://csxstatic.ist.psu.edu/help\" target=\"_blank\">Help</a></li>\n",
       "<li><a href=\"http://csxstatic.ist.psu.edu/downloads/data\" target=\"_blank\">Data</a></li>\n",
       "<li><a href=\"https://github.com/SeerLabs/CiteSeerX\" target=\"_blank\">Source</a></li>\n",
       "<li><a href=\"http://csxstatic.ist.psu.edu/contact\" target=\"_blank\">Contact Us</a></li>\n",
       "</ul>\n",
       "<p class=\"info\">Developed at and hosted by <a href=\"http://ist.psu.edu\">The College of Information Sciences and Technology</a></p>\n",
       "<p>© 2007-2019 <a href=\"http://www.psu.edu\">The Pennsylvania State University</a></p>\n",
       "</div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n",
       ">"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "!pip3 install beautifulsoup4\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "givenURL = 'https://citeseerx.ist.psu.edu/search?q=natural+language+processing&t=doc&sort=rlv&start={}'\n",
    "page = requests.get(givenURL)\n",
    "page.text\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup.prettify\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"... Introduction  Statistical natural language processing (SNLP)    is a field lying in the intersection of natural language processing and machine learning. SNLP di#ers from traditional natural language processing in that instead of having a linguist manually construct some model of a given linguistic  ...\"',\n",
       " '\"... The paper summarizes the essential properties of document retrieval and reviews both conventional practice and research findings, the latter suggesting that simple statistical techniques can be effective. It then considers the new opportunities and challenges presented by the ability to search full  ...\"',\n",
       " '\"... ABSTRACT: Language is way of communicating your words Language helps in understanding the world,we get a better insight of the world. Language helps speakers to be as vague or as precise as they like. NLP Stands for natural language processing.. Natural languages are those languages that are spoken  ...\"',\n",
       " '\"... We report experiments on the use of standard natural language processing (NLP) tools for the analysis of music lyrics. A significant amount of music audio has lyrics. Lyrics encode an important part of the semantics of a song, therefore their analysis complements that of acoustic and cultural metada ...\"',\n",
       " '\"... this paper, we will describe a simple rule-based approach to automated learning of linguistic knowledge. This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance. We present a detailed case study of this learni ...\"',\n",
       " '\"... This paper focuses on connectionist models in natural language processing. We briefly present and discuss several aspects of high level tasks which recently have been approached with connectionism, either with localist or parallel distributed processing models. Several interesting architectures have ...\"',\n",
       " '\"... Abstract: The article explores the possibility to construct a unified word feature out of the component features of letters. Each letter is modeled by a different attractor and finally embedded in a quadratic iterated map. The result is the word feature that can account for the meaning extraction pr ...\"',\n",
       " '\"... this paper (see [Schank 86] for a theoretical discussion and [Kass 86] and [Leake and Owens 86] for brief discussions of a program built around these .principles); the goal here is simply  to point out how our interest in natural language processing has led us naturally, and indeed inevitably, to de ...\"',\n",
       " '\"... Objectives To provide an overview and tutorial of natural language processing (NLP) and modern NLP-system design. Target audience This tutorial targets the medical informatics generalist who has limited acquaintance with the principles behind NLP and/or limited knowledge of the current state of the  ...\"',\n",
       " '\"... This paper briefly describes the current implementation status of an intelligent information retrieval system, MARIE, that employs natural language processing techniques. Descriptive captions are used to iden- tify photographic images concerning various military projects. The captions are parsed to  ...\"',\n",
       " '\"... Abstract: Metabolism is the machinery of life and signal transduction provides the regulatory mechanisms to control that machinery. Due to the complexity of signal transduction pathways, computational approaches are needed to aid the biologist in integrating available knowledge and in the formulatio ...\"',\n",
       " '\"... This report presents a detailed analysis and review of NLP evaluation, in principle and in practice. Part 1 examines evaluation concepts and establishes a framework for NLP system evaluation. This makes use of experience in the related area of information retrieval and the analysis also refers to ev ...\"',\n",
       " '\"... Web has emerged as the most important source of information in the world. This has resulted in need for automated software components to analyze web pages and harvest useful information from them. However, in typical web pages the informative content is surrounded by a very high degree of noise in t ...\"',\n",
       " '\"... Abstract-- Natural Language Processing is a theoretically motivated range of computational techniques for analysing and representing naturally occurring texts at one or more levels of linguistic analysis for the purpose of achieving human-like language processing for a range of tasks or applications ...\"',\n",
       " '\"... This paper reviews the processes involved in Natural Language Processing (NLP). It then demonstrates the various kinds of choices that need be taken during the execution of the word morphology, the syntactic text analysis, or text generation components. It compares the time complexity of traditional ...\"',\n",
       " '\"... This article focusses on the derivation of large lexicons for natural language processing. We describe the  development of a dictionary support environment linking a restructured version of the Longman  Dictionary of Contemporary English to natural language processing systems. The process of restruc ...\"',\n",
       " '\"... We introduce a method for analyzing the complexity of natural language processing tasks, and for predicting the difficulty new NLP tasks. Our complexity measures are derived from the Kolmogorov complexity of a class of automata — meaning automata, whose purpose is to extract relevant pieces of infor ...\"',\n",
       " '\"... Deep learning has emerged as a new area of machine learning research. It tries to mimic the human brain, which is capable of processing and learning from the complex input data and solving different kinds of complicated tasks well. It has been successfully applied to several fields such as images, s ...\"',\n",
       " '\"... This is an author-produced version of a paper published in The ...\"',\n",
       " '\"... Abstract—Natural language processing (NLP) is the application of automated parsing and machine learning techniques to analyze standard text. Applications of NLP to requirements engineering include extraction of ontologies from a requirements specification, and use of NLP to verify the consistency an ...\"',\n",
       " '\"... . Information retrieval addresses the problem of finding those  documents whose content matches a user\\'s request from among a large  collection of documents. Currently, the most successful general purpose  retrieval methods are statistical methods that treat text as little more  than a bag of w ...\"',\n",
       " '\"... Work in computational linguistics began very soon after the development of the first computers (Booth, Brandwood and Cleave 1958), yet in the intervening four decades there has been a pervasive feeling that progress in computer understanding of natural language has not been commensurate with progres ...\"',\n",
       " '\"... Abstract-A system that recognizes and authenticates the voice of a user by extracting the distinct features of their voice samples is usually termed as Voice recognition system. Voice identification is carried out by converting the human voice into digital data. The digitized audio samples then unde ...\"',\n",
       " '\"... Abstract: Testing against natural language requirements is the standard approach for system and acceptance testing. This test is often performed by an independent test organization unfamiliar with the application area. The only things the testers have to go by are the written requirements. So it is  ...\"',\n",
       " '\"...   ...\"',\n",
       " '\"... algorithms that allow understanding and generation of humor. There is the general aim of modeling humor, and if we can do that, it will provide us with lots of information about our cognitive abilities in general, such as reasoning, remembering, understanding situations, and understanding conversati ...\"',\n",
       " '\"...  ...\"',\n",
       " '\"... In recent years, machine learning (ML) has been used more and more to solve complex tasks in different disciplines, ranging from Data Mining to Information ...\"',\n",
       " '\"... We argue that manual and automatic thesauruses are alternative resources for the same NLP tasks. This involves the radical step of interpreting manual thesauruses as classifications of words rather than word senses: the case for this is made. The range of roles for thesauruses within NLP is briefly  ...\"',\n",
       " '\"... Introduction  Patterns in music have been the object of intensive studies in the past years. \\\\One of the purposes of analyzing musical structure and form is to discover the patterns that are explicit or implicit in musical works\" Simon [13]. Patterns comprise periodicity, make use of alphabets, ...\"',\n",
       " '\"... Abstract Many information retrieval(IR) systems retrieve relevant documents based on exact matching of keywords between a query and documents. This method degrades precision rate. In order to solve the problem, we collected semantically related words and assigned semantic relationships used in gener ...\"',\n",
       " '\"... this paper we argue that questionanswering  (QA) over technical domains  is distinctly different from TREC-based  QA or Web-based QA and it cannot  benefit lom data-intensive approaches ...\"',\n",
       " '\"... Universit&quot;at des Saarlandes ...\"',\n",
       " '\"... Proceedings of the Workshop on ...\"',\n",
       " '\"... uni-hamburg.de ...\"',\n",
       " '\"...  ...\"',\n",
       " '\"... 2 6 ...\"',\n",
       " '\"... SRI has developed a new architecture for integrating speech and natural-language processing that applies linguistic constraints during recognition by incrementally expanding the state-transition network embodied in a unification grammar. We compare this dynamic-gralnlnar-network (DGN) approach to it ...\"',\n",
       " '\"... This chapter considers the revolution that has taken place in natural language processing research over the last five years. It begins by providing a brief guide to the structure of the field and then presents a caricature of two competing paradigms of 1980s NLP research and indicates the reasons wh ...\"',\n",
       " '\"... visual development environment to support the visual assembly, execution and analysis of modular natural language processing systems. The visual model is an executable data flow program graph, automatically synthesised from data dependency declarations of language processing modules. The graph is th ...\"',\n",
       " '\"... In this Chapter the basic uses of Description Logics for Natural Language Processing will be analysed, together with a little bit of history, and the role of Description Logics in the current state of the art in computational linguistics will be pointed out.  18.1 Introduction  Since the early days  ...\"',\n",
       " '\"... We applied a structure learning model, Max-Margin Structure (MMS), to natural language processing (NLP) tasks, where the aim is to capture the latent relationships within the output language domain. We formulate this model as an extension of multi–class Support Vector Machine (SVM) and present a per ...\"',\n",
       " '\"... Vast quantities of text are becoming available in elec-tronic form, ranging from published documents (e.g., electronic dictionaries, encyclopedias, libraries and archives for information retrieval services), to private databases (e.g., marketing information, legal records, medical histories), to per ...\"',\n",
       " '\"... Over the last few years, a number of areas of natural language processing have begun applying graph-based techniques. These include, among others, text summarization, syntactic parsing, word sense disambiguation, ontology construction, sentiment and subjectivity analysis, text clustering. In this pa ...\"',\n",
       " '\"... In Natural Language Processing (NLP), research results  from software engineering and software technology  have often been neglected. ...\"',\n",
       " '\"... Kernelized sorting is an approach for matching objects from two sources (or domains) that does not require any prior notion of similarity between objects across the two sources. Unfortunately, this technique is highly sensitive to initialization and high dimensional data. We present variants of kern ...\"',\n",
       " '\"... Natural language is a complex and compound organization that structures basic linguistic elements to represent various meanings. Therefore, to understand the nature of natural language, we need a sophisticated treatment of the basic elements as well as the insights about how these elements will be s ...\"',\n",
       " '\"... In this paper, we describe a framework for developing probabilistic classifiers in natural language processing. Our focus is on formulating models that capture the most important interdependencies among features, to avoid overfitting the data while also characterizing the data well. The class of pro ...\"',\n",
       " '\"... Many Natural Language Processing (NLP) techniques have been used in Information Retrieval. The results are not encouraging. Simple methods (stopwording, porter-style stemming, etc.) usually yield significant improvements, while higher-level processing (chunking, parsing, word sense disambiguation, e ...\"',\n",
       " '\"... Abstract- This paper explains the information retrieval using natural language processing for Malayalam language in these basic ...\"',\n",
       " '\"... The research areas of plan recognition and natural language parsing share many common features and even algorithms. However, the dialog between these two disciplines has not been effective. Specifically, significant recent results in parsing mildly context sensitive grammars have not been leveraged  ...\"',\n",
       " '\"... The research areas of plan recognition and natural language parsing share many common features and even algorithms. However, the dialog between these two disciplines has not been effective. Specifically, significant recent results in parsing mildly context sensitive grammars have not been leveraged  ...\"',\n",
       " '\"... Information retrieval is the process of finding the documents in a document collection that satisfies the information need of the user. The documents are natural language constructs, and the motivation of this work is to investigate how natural language processing can be used to improve the performa ...\"',\n",
       " '\"... While computational logic has become widely used for representing and reasoning with linguistic knowledge, the cross-fertilization between logic programming and machine learning has given rise to a new discipline known as inductive logic programming. Inspired by, and building on the achievements of  ...\"',\n",
       " '\"... What is a statistical method and how can it be used in natural language  processing (NLP)? In this paper, we start from a definition of NLP as concerned with  the design and implementation of effective natural language input and output components  for computational systems. We distinguish three kind ...\"',\n",
       " '\"... In this report, some collaborative work between the fields of Machine Learning (ML) and Natural Language Processing (NLP) is presented. The document is structured in two parts. The first part includes a superficial but comprehensive survey covering the state--of--the--art of machine learning techniq ...\"',\n",
       " '\"... Abstract. This thesis examines the use of machine learning techniques in various tasks of natural language processing, mainly for the task of information extraction from texts. The objectives are the improvement of adaptability of information extraction systems to new thematic do-mains (or even lang ...\"',\n",
       " '\"... This chapter examines the application of natural language processing to computerassisted language learning including the history of work in this field over the last thirtyfive years but with a focus on current developments and opportunities.  36.1  ...\"',\n",
       " '\"... Traditional approaches tointerpretation in natural language processing typically fall into one of three classes: syntax-driven, semantics-driven, or frame/task based. Syntax-driven approaches use a domain-independent grammar to drive the interpretation process and produce a global parse of the input ...\"',\n",
       " '\"... Natural Language Processing (NLP) is a very large and diverse subtopic of artificial intelligence. As a result, NLP itself has many subtopics including optical character recognition, text to speech translators, foreign language reading and writing aids, machine translation, and speech recognition. W ...\"',\n",
       " '\"...   Probabilistic finite-state string transducers (FSTs) are extremely popular in natural language processing, due to powerful generic methods for applying, composing, and learning them. Unfortunately, FSTs are not a good fit for much of the current work on probabilistic modeling for machine translati ...\"',\n",
       " '\"... ABSTRACT. In this special issue of TAL, we look at the fundamental principles underlying evaluation in natural language processing. We adopt a global point of view that goes beyond the horizon of a single evaluation campaign or a particular protocol. After a brief review of history and terminology,  ...\"',\n",
       " '\"...   ...\"',\n",
       " '\"... Natural language processing systems (NLP) that extract clinical information from textual reports were shown to be effective for limited domains and for particular applications. Because an NLP system typically requires substantial resources to develop, it is beneficial if it is designed to be easily  ...\"',\n",
       " '\"... We propose a bifurcated paradigm for the construction of a Prolog knowl-edge base from a body of documents: first, an information extraction (IE) ap-plication that will annotate the corpus and output the annotated documents, and second, a Prolog knowledge base (KB) application that will transform th ...\"',\n",
       " '\"... We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and sem ...\"',\n",
       " '\"... We developed a prototype information retrieval system  which uses advanced natural language processing  techniques to enhance the effectiveness of traditional  key-word based document retrieval. The backbone  of our system is a statistical retrieval engine  which performs automated indexing of docum ...\"',\n",
       " '\"...  ...\"',\n",
       " '\"... In this paper we will discuss several issues and requirements for enabling natural language processing systems to become context-adaptive. Given the fact that emerging systems feature speaker independent continuous speech recognition restricted to individual domains and are equipped with syntactic a ...\"',\n",
       " '\"... In Fall 2004 I introduced a new course  called Applied Natural Language Processing,  in which students acquire an understanding  of which text analysis techniques  are currently feasible for practical applications. ...\"',\n",
       " '\"...   ...\"',\n",
       " '\"...  Abstract: Natural language processing is the study of mathematical and computational modelling of various aspects of language and the improvement of a wide range of systems. Natural language is any language that arises as an innate facility for language possessed by the human intellect; it may be s ...\"',\n",
       " '\"... Natural Language Processing (NLP), which is a branch of artificial intelligence, includes speech synthesis, Speech recognition, and Machine translation. Natural Language Processing has a wide range of applications in the Indian context. Most of the rural Indian community is unable to make use of  th ...\"',\n",
       " '\"... An Evaluation of LOLITA and related Natural Language Processing Systems  Paul Callaghan  Submitted to the University of Durham for the degree of Ph.D., August 1997  ---------------------  This research addresses the question, \"how do we evaluate systems like LOLITA?\" LOLITA is the Natural  ...\"',\n",
       " '\"... Previous work demonstrated that Web counts can be used to approximate bigram counts, suggesting that Web-based frequencies should be useful for a wide variety of Natural Language Processing (NLP) tasks. However, only a limited number of tasks have so far been tested using Web-scale data sets. The pr ...\"',\n",
       " '\"... This chapter examines the application of natural language processing to computerassisted language learning including the history of work in this field over the last thirtyfive years but with a focus on current developments and opportunities.  16.1 Introduction  This chapter focuses on applications o ...\"',\n",
       " '\"... This paper describes a natural language system which improves its own performance through learning. The system processes short English narratives and is able to acquire, from a single narrative, a new schema for a stereotypical set of actions. During the understanding process, the system attempts to ...\"',\n",
       " '\"... We classify and review current approaches  to software infrastructure for research, development  and delivery of NLP systems. The task ...\"',\n",
       " '\"... Confidence measures are a practical solution for improving the usefulness of Natural Language Processing applications. Confidence estimation is a generic machine learning approach for deriving confidence measures. We give an overview of the application of confidence estimation in various fields of N ...\"',\n",
       " '\"... ! lex-sign sense-id : sense-id dictionary ? = \"LDOCE\" ! lex-sign sense-id : sense-id ldb-entry-no ? = \"12364\" ! lex-sign sense-id : sense-id sense-no ? = \"0\".  When loaded into the LKB, (9) will be expanded into a fully-fledged representation for the transitive use of e ...\"',\n",
       " '\"... We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural lan-guage analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and govern-ment users of open source NLP technol-ogy. We suggest that  ...\"',\n",
       " '\"... Gaussian Processes (GPs) are a powerful mod-elling framework incorporating kernels and Bayesian inference, and are recognised as state-of-the-art for many machine learning tasks. ...\"',\n",
       " '\"... :  A fundamental issue in natural language processing is the prerequisite of an enormous quantity of preprogrammed knowledge concerning both the language and the domain under examination. Manual acquisition of this knowledge is tedious and error prone. Development of an automated acquisition process ...\"',\n",
       " '\"... A general, reusable computational resource has been de- veloped within the Penman text generation project for organizing domain knowledge appropriately for linguistic realization. This resource, called the upper model, provides a domain- and task-independent classification system\" that supports ...\"',\n",
       " '\"... Kohonen\\'s Self-Organizing Map (SOM) is one of the most popular artificial neural network algorithms. Word category maps are SOMs that have been organized according to word similarities, measured by the similarity of the short contexts of the words. Conceptually interrelated words tend to fall i ...\"',\n",
       " '\"... This paper presents a workbench built by Priberam Informática for the development of the company’s natural language processing technology. This workbench includes a set of linguistic resources and software tools that have been applied in a considerable number of practical purposes, covering proofing ...\"',\n",
       " '\"... Abstract—Natural Language Processing (NLP) is an effective approach for bringing improvement in educational setting. Implementing NLP involves initiating the process of learning through the natural acquisition in the educational systems. It is based on effective approaches for providing a solution f ...\"',\n",
       " '\"... ABSTRACT: After twenty years of disfavor, a technology has returned which imitates the processes of the brain. Natural language experiments (Sejnowski & Rosenberg: 1986) demonstrate that neural network computing architecture can learn from actual spoken language, observe rules of pronunciation,  ...\"',\n",
       " '\"... Text statistics are frequently used in stylometry and cryptography studies. In this paper, some text statistics tools are developed in ISO Prolog for natural language processing. Details are given on the usage of 21 user-callable predicates. Logic and limitations of the program are also discussed. 1 ...\"',\n",
       " '\"... We summarize our experience using FrameNet in two rather different projects in natural language processing (NLP). We conclude that NLP can benefit from FrameNet in different ways, but we sketch some problems that need to be overcome. 1 ...\"',\n",
       " '\"... Research in Natural Language Processing (NLP) has in recent years benefited from the enormous amount of raw textual data available on the World Wide Web. The presence of standard search engines has made this data accessible to computational linguists as a corpus of a size that had never existed befo ...\"',\n",
       " '\"... Natural language processing #NLP# programs are  confronted with various di#culties in processing HTML and XML documents, and have the potential to produce better results if linguistic information is annotated in the source texts. Wehave therefore developed the Linguistic Annotation Language  #or LAL ...\"',\n",
       " '\"... Introduction  Natural language processing appears on the surface to be a strongly symbolic activity. Words are symbols that stand for objects and concepts in the real world, and they are put together into sentences that obey well-specified grammar rules. It is no surprise that for several decades na ...\"',\n",
       " '\"... Abstract. Diff is a software program that detects differences between two data sets and is useful in natural language processing. This paper shows several examples of the application of diff. They include the detection of differences between two different datasets, extraction of rewriting rules, mer ...\"',\n",
       " '\"... In this paper, we present and compare automatically generated titles for machine-translated documents using several different statistics-based methods. A Naïve Bayesian, a K-Nearest Neighbour, a TF-IDF and an it-erative Expectation-Maximization method for title gen-eration were applied to 1000 origi ...\"',\n",
       " '\"...   9. Bibliography   ...\"',\n",
       " '\"... Applying Natural Language Processing techniques to biomedical text as a potential aid to curation has become the focus of intensive research. However, developing integrated systems which address the curators ’ real-world needs has been studied less rigorously. This paper addresses this question and  ...\"',\n",
       " '\"... Examples of natural languages are Chinese, English and Italian. They are called natural as they evolved in a more or less natural way, without too many deliberate considerations. This sets them apart from formal languages, amongst which are programming languages, which are designed to ...\"',\n",
       " '\"... A number of powerful modelling techniques have been developed in recent years to compress natural language text. The best of these are adaptive models operating on the character and word level which are able to perform almost as well as humans at predicting text. We show how to apply character based ...\"',\n",
       " '\"... A semi-automated approach for the design of databases in enhanced-ERD notation is presented. It focuses on the very early stage of the database development which is the stage of user requirement analysis. It is supposed to be used between the requirements determination stage and analysis. The approa ...\"']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "a=[i*10 for i in range(1,11)]\n",
    "b=[]\n",
    "for i in l1:\n",
    "    givenURL = 'https://citeseerx.ist.psu.edu/search?q=natural+language+processing&t=doc&sort=rlv&start={}'.format(i)\n",
    "    p = requests.get(givenURL)\n",
    "    s = BeautifulSoup(p.content, 'html.parser')\n",
    "    for i in s.find_all(\"div\",{\"class\":\"snippet\"}):\n",
    "        b.append(i.text)\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Abstract\n",
      "0   \"... Introduction  Statistical natural languag...\n",
      "1   \"... The paper summarizes the essential proper...\n",
      "2   \"... ABSTRACT: Language is way of communicatin...\n",
      "3   \"... We report experiments on the use of stand...\n",
      "4   \"... this paper, we will describe a simple rul...\n",
      "..                                                ...\n",
      "95                      \"...   9. Bibliography   ...\"\n",
      "96  \"... Applying Natural Language Processing tech...\n",
      "97  \"... Examples of natural languages are Chinese...\n",
      "98  \"... A number of powerful modelling techniques...\n",
      "99  \"... A semi-automated approach for the design ...\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d_f=pd.DataFrame({\"Abstract\":b})\n",
    "d_f.to_csv(\"assign4csv.csv\")\n",
    "d_f\n",
    "print(d_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfpMRCrRwN6Z"
   },
   "source": [
    "# **Question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dCQEbDawWCw"
   },
   "source": [
    "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
    "\n",
    "(1) Remove noise, such as special characters and punctuations.\n",
    "\n",
    "(2) Remove numbers.\n",
    "\n",
    "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
    "\n",
    "(4) Lowercase all texts\n",
    "\n",
    "(5) Stemming. \n",
    "\n",
    "(6) Lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vATjQNTY8buA"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "import re\n",
    "n=[]\n",
    "for i in d_f['Abstract']:\n",
    "  n.append(re.split(r'\\W+',i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\racha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\racha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "#filtered_words = [word for word in file1 if word not in stopwords.words('english')]\n",
    "#print(\"Number of stopwords\",len(file1)-len(filtered_words))\n",
    "stopwords.words('english')\n",
    "f1=[]\n",
    "for i in n:\n",
    "  #print(i)\n",
    "  filtered_words = [word for word in i if word not in stopwords.words('english')]\n",
    "  f1.append(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['',\n",
       "  'Introduction',\n",
       "  'Statistical',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'SNLP',\n",
       "  'field',\n",
       "  'lying',\n",
       "  'intersection',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'SNLP',\n",
       "  'di',\n",
       "  'ers',\n",
       "  'traditional',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'instead',\n",
       "  'linguist',\n",
       "  'manually',\n",
       "  'construct',\n",
       "  'model',\n",
       "  'given',\n",
       "  'linguistic',\n",
       "  ''],\n",
       " ['',\n",
       "  'The',\n",
       "  'paper',\n",
       "  'summarizes',\n",
       "  'essential',\n",
       "  'properties',\n",
       "  'document',\n",
       "  'retrieval',\n",
       "  'reviews',\n",
       "  'conventional',\n",
       "  'practice',\n",
       "  'research',\n",
       "  'findings',\n",
       "  'latter',\n",
       "  'suggesting',\n",
       "  'simple',\n",
       "  'statistical',\n",
       "  'techniques',\n",
       "  'effective',\n",
       "  'It',\n",
       "  'considers',\n",
       "  'new',\n",
       "  'opportunities',\n",
       "  'challenges',\n",
       "  'presented',\n",
       "  'ability',\n",
       "  'search',\n",
       "  'full',\n",
       "  ''],\n",
       " ['',\n",
       "  'ABSTRACT',\n",
       "  'Language',\n",
       "  'way',\n",
       "  'communicating',\n",
       "  'words',\n",
       "  'Language',\n",
       "  'helps',\n",
       "  'understanding',\n",
       "  'world',\n",
       "  'get',\n",
       "  'better',\n",
       "  'insight',\n",
       "  'world',\n",
       "  'Language',\n",
       "  'helps',\n",
       "  'speakers',\n",
       "  'vague',\n",
       "  'precise',\n",
       "  'like',\n",
       "  'NLP',\n",
       "  'Stands',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'Natural',\n",
       "  'languages',\n",
       "  'languages',\n",
       "  'spoken',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'report',\n",
       "  'experiments',\n",
       "  'use',\n",
       "  'standard',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'NLP',\n",
       "  'tools',\n",
       "  'analysis',\n",
       "  'music',\n",
       "  'lyrics',\n",
       "  'A',\n",
       "  'significant',\n",
       "  'amount',\n",
       "  'music',\n",
       "  'audio',\n",
       "  'lyrics',\n",
       "  'Lyrics',\n",
       "  'encode',\n",
       "  'important',\n",
       "  'part',\n",
       "  'semantics',\n",
       "  'song',\n",
       "  'therefore',\n",
       "  'analysis',\n",
       "  'complements',\n",
       "  'acoustic',\n",
       "  'cultural',\n",
       "  'metada',\n",
       "  ''],\n",
       " ['',\n",
       "  'paper',\n",
       "  'describe',\n",
       "  'simple',\n",
       "  'rule',\n",
       "  'based',\n",
       "  'approach',\n",
       "  'automated',\n",
       "  'learning',\n",
       "  'linguistic',\n",
       "  'knowledge',\n",
       "  'This',\n",
       "  'approach',\n",
       "  'shown',\n",
       "  'number',\n",
       "  'tasks',\n",
       "  'capture',\n",
       "  'information',\n",
       "  'clearer',\n",
       "  'direct',\n",
       "  'fashion',\n",
       "  'without',\n",
       "  'compromise',\n",
       "  'performance',\n",
       "  'We',\n",
       "  'present',\n",
       "  'detailed',\n",
       "  'case',\n",
       "  'study',\n",
       "  'learni',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'focuses',\n",
       "  'connectionist',\n",
       "  'models',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'We',\n",
       "  'briefly',\n",
       "  'present',\n",
       "  'discuss',\n",
       "  'several',\n",
       "  'aspects',\n",
       "  'high',\n",
       "  'level',\n",
       "  'tasks',\n",
       "  'recently',\n",
       "  'approached',\n",
       "  'connectionism',\n",
       "  'either',\n",
       "  'localist',\n",
       "  'parallel',\n",
       "  'distributed',\n",
       "  'processing',\n",
       "  'models',\n",
       "  'Several',\n",
       "  'interesting',\n",
       "  'architectures',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'The',\n",
       "  'article',\n",
       "  'explores',\n",
       "  'possibility',\n",
       "  'construct',\n",
       "  'unified',\n",
       "  'word',\n",
       "  'feature',\n",
       "  'component',\n",
       "  'features',\n",
       "  'letters',\n",
       "  'Each',\n",
       "  'letter',\n",
       "  'modeled',\n",
       "  'different',\n",
       "  'attractor',\n",
       "  'finally',\n",
       "  'embedded',\n",
       "  'quadratic',\n",
       "  'iterated',\n",
       "  'map',\n",
       "  'The',\n",
       "  'result',\n",
       "  'word',\n",
       "  'feature',\n",
       "  'account',\n",
       "  'meaning',\n",
       "  'extraction',\n",
       "  'pr',\n",
       "  ''],\n",
       " ['',\n",
       "  'paper',\n",
       "  'see',\n",
       "  'Schank',\n",
       "  '86',\n",
       "  'theoretical',\n",
       "  'discussion',\n",
       "  'Kass',\n",
       "  '86',\n",
       "  'Leake',\n",
       "  'Owens',\n",
       "  '86',\n",
       "  'brief',\n",
       "  'discussions',\n",
       "  'program',\n",
       "  'built',\n",
       "  'around',\n",
       "  'principles',\n",
       "  'goal',\n",
       "  'simply',\n",
       "  'point',\n",
       "  'interest',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'led',\n",
       "  'us',\n",
       "  'naturally',\n",
       "  'indeed',\n",
       "  'inevitably',\n",
       "  'de',\n",
       "  ''],\n",
       " ['',\n",
       "  'Objectives',\n",
       "  'To',\n",
       "  'provide',\n",
       "  'overview',\n",
       "  'tutorial',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'NLP',\n",
       "  'modern',\n",
       "  'NLP',\n",
       "  'system',\n",
       "  'design',\n",
       "  'Target',\n",
       "  'audience',\n",
       "  'This',\n",
       "  'tutorial',\n",
       "  'targets',\n",
       "  'medical',\n",
       "  'informatics',\n",
       "  'generalist',\n",
       "  'limited',\n",
       "  'acquaintance',\n",
       "  'principles',\n",
       "  'behind',\n",
       "  'NLP',\n",
       "  'limited',\n",
       "  'knowledge',\n",
       "  'current',\n",
       "  'state',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'briefly',\n",
       "  'describes',\n",
       "  'current',\n",
       "  'implementation',\n",
       "  'status',\n",
       "  'intelligent',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'system',\n",
       "  'MARIE',\n",
       "  'employs',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'techniques',\n",
       "  'Descriptive',\n",
       "  'captions',\n",
       "  'used',\n",
       "  'iden',\n",
       "  'tify',\n",
       "  'photographic',\n",
       "  'images',\n",
       "  'concerning',\n",
       "  'various',\n",
       "  'military',\n",
       "  'projects',\n",
       "  'The',\n",
       "  'captions',\n",
       "  'parsed',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'Metabolism',\n",
       "  'machinery',\n",
       "  'life',\n",
       "  'signal',\n",
       "  'transduction',\n",
       "  'provides',\n",
       "  'regulatory',\n",
       "  'mechanisms',\n",
       "  'control',\n",
       "  'machinery',\n",
       "  'Due',\n",
       "  'complexity',\n",
       "  'signal',\n",
       "  'transduction',\n",
       "  'pathways',\n",
       "  'computational',\n",
       "  'approaches',\n",
       "  'needed',\n",
       "  'aid',\n",
       "  'biologist',\n",
       "  'integrating',\n",
       "  'available',\n",
       "  'knowledge',\n",
       "  'formulatio',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'report',\n",
       "  'presents',\n",
       "  'detailed',\n",
       "  'analysis',\n",
       "  'review',\n",
       "  'NLP',\n",
       "  'evaluation',\n",
       "  'principle',\n",
       "  'practice',\n",
       "  'Part',\n",
       "  '1',\n",
       "  'examines',\n",
       "  'evaluation',\n",
       "  'concepts',\n",
       "  'establishes',\n",
       "  'framework',\n",
       "  'NLP',\n",
       "  'system',\n",
       "  'evaluation',\n",
       "  'This',\n",
       "  'makes',\n",
       "  'use',\n",
       "  'experience',\n",
       "  'related',\n",
       "  'area',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'analysis',\n",
       "  'also',\n",
       "  'refers',\n",
       "  'ev',\n",
       "  ''],\n",
       " ['',\n",
       "  'Web',\n",
       "  'emerged',\n",
       "  'important',\n",
       "  'source',\n",
       "  'information',\n",
       "  'world',\n",
       "  'This',\n",
       "  'resulted',\n",
       "  'need',\n",
       "  'automated',\n",
       "  'software',\n",
       "  'components',\n",
       "  'analyze',\n",
       "  'web',\n",
       "  'pages',\n",
       "  'harvest',\n",
       "  'useful',\n",
       "  'information',\n",
       "  'However',\n",
       "  'typical',\n",
       "  'web',\n",
       "  'pages',\n",
       "  'informative',\n",
       "  'content',\n",
       "  'surrounded',\n",
       "  'high',\n",
       "  'degree',\n",
       "  'noise',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'theoretically',\n",
       "  'motivated',\n",
       "  'range',\n",
       "  'computational',\n",
       "  'techniques',\n",
       "  'analysing',\n",
       "  'representing',\n",
       "  'naturally',\n",
       "  'occurring',\n",
       "  'texts',\n",
       "  'one',\n",
       "  'levels',\n",
       "  'linguistic',\n",
       "  'analysis',\n",
       "  'purpose',\n",
       "  'achieving',\n",
       "  'human',\n",
       "  'like',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'range',\n",
       "  'tasks',\n",
       "  'applications',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'reviews',\n",
       "  'processes',\n",
       "  'involved',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'It',\n",
       "  'demonstrates',\n",
       "  'various',\n",
       "  'kinds',\n",
       "  'choices',\n",
       "  'need',\n",
       "  'taken',\n",
       "  'execution',\n",
       "  'word',\n",
       "  'morphology',\n",
       "  'syntactic',\n",
       "  'text',\n",
       "  'analysis',\n",
       "  'text',\n",
       "  'generation',\n",
       "  'components',\n",
       "  'It',\n",
       "  'compares',\n",
       "  'time',\n",
       "  'complexity',\n",
       "  'traditional',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'article',\n",
       "  'focusses',\n",
       "  'derivation',\n",
       "  'large',\n",
       "  'lexicons',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'We',\n",
       "  'describe',\n",
       "  'development',\n",
       "  'dictionary',\n",
       "  'support',\n",
       "  'environment',\n",
       "  'linking',\n",
       "  'restructured',\n",
       "  'version',\n",
       "  'Longman',\n",
       "  'Dictionary',\n",
       "  'Contemporary',\n",
       "  'English',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'The',\n",
       "  'process',\n",
       "  'restruc',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'introduce',\n",
       "  'method',\n",
       "  'analyzing',\n",
       "  'complexity',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'tasks',\n",
       "  'predicting',\n",
       "  'difficulty',\n",
       "  'new',\n",
       "  'NLP',\n",
       "  'tasks',\n",
       "  'Our',\n",
       "  'complexity',\n",
       "  'measures',\n",
       "  'derived',\n",
       "  'Kolmogorov',\n",
       "  'complexity',\n",
       "  'class',\n",
       "  'automata',\n",
       "  'meaning',\n",
       "  'automata',\n",
       "  'whose',\n",
       "  'purpose',\n",
       "  'extract',\n",
       "  'relevant',\n",
       "  'pieces',\n",
       "  'infor',\n",
       "  ''],\n",
       " ['',\n",
       "  'Deep',\n",
       "  'learning',\n",
       "  'emerged',\n",
       "  'new',\n",
       "  'area',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'research',\n",
       "  'It',\n",
       "  'tries',\n",
       "  'mimic',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'capable',\n",
       "  'processing',\n",
       "  'learning',\n",
       "  'complex',\n",
       "  'input',\n",
       "  'data',\n",
       "  'solving',\n",
       "  'different',\n",
       "  'kinds',\n",
       "  'complicated',\n",
       "  'tasks',\n",
       "  'well',\n",
       "  'It',\n",
       "  'successfully',\n",
       "  'applied',\n",
       "  'several',\n",
       "  'fields',\n",
       "  'images',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'author',\n",
       "  'produced',\n",
       "  'version',\n",
       "  'paper',\n",
       "  'published',\n",
       "  'The',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'NLP',\n",
       "  'application',\n",
       "  'automated',\n",
       "  'parsing',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'techniques',\n",
       "  'analyze',\n",
       "  'standard',\n",
       "  'text',\n",
       "  'Applications',\n",
       "  'NLP',\n",
       "  'requirements',\n",
       "  'engineering',\n",
       "  'include',\n",
       "  'extraction',\n",
       "  'ontologies',\n",
       "  'requirements',\n",
       "  'specification',\n",
       "  'use',\n",
       "  'NLP',\n",
       "  'verify',\n",
       "  'consistency',\n",
       "  ''],\n",
       " ['',\n",
       "  'Information',\n",
       "  'retrieval',\n",
       "  'addresses',\n",
       "  'problem',\n",
       "  'finding',\n",
       "  'documents',\n",
       "  'whose',\n",
       "  'content',\n",
       "  'matches',\n",
       "  'user',\n",
       "  'request',\n",
       "  'among',\n",
       "  'large',\n",
       "  'collection',\n",
       "  'documents',\n",
       "  'Currently',\n",
       "  'successful',\n",
       "  'general',\n",
       "  'purpose',\n",
       "  'retrieval',\n",
       "  'methods',\n",
       "  'statistical',\n",
       "  'methods',\n",
       "  'treat',\n",
       "  'text',\n",
       "  'little',\n",
       "  'bag',\n",
       "  'w',\n",
       "  ''],\n",
       " ['',\n",
       "  'Work',\n",
       "  'computational',\n",
       "  'linguistics',\n",
       "  'began',\n",
       "  'soon',\n",
       "  'development',\n",
       "  'first',\n",
       "  'computers',\n",
       "  'Booth',\n",
       "  'Brandwood',\n",
       "  'Cleave',\n",
       "  '1958',\n",
       "  'yet',\n",
       "  'intervening',\n",
       "  'four',\n",
       "  'decades',\n",
       "  'pervasive',\n",
       "  'feeling',\n",
       "  'progress',\n",
       "  'computer',\n",
       "  'understanding',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'commensurate',\n",
       "  'progres',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'A',\n",
       "  'system',\n",
       "  'recognizes',\n",
       "  'authenticates',\n",
       "  'voice',\n",
       "  'user',\n",
       "  'extracting',\n",
       "  'distinct',\n",
       "  'features',\n",
       "  'voice',\n",
       "  'samples',\n",
       "  'usually',\n",
       "  'termed',\n",
       "  'Voice',\n",
       "  'recognition',\n",
       "  'system',\n",
       "  'Voice',\n",
       "  'identification',\n",
       "  'carried',\n",
       "  'converting',\n",
       "  'human',\n",
       "  'voice',\n",
       "  'digital',\n",
       "  'data',\n",
       "  'The',\n",
       "  'digitized',\n",
       "  'audio',\n",
       "  'samples',\n",
       "  'unde',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'Testing',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'requirements',\n",
       "  'standard',\n",
       "  'approach',\n",
       "  'system',\n",
       "  'acceptance',\n",
       "  'testing',\n",
       "  'This',\n",
       "  'test',\n",
       "  'often',\n",
       "  'performed',\n",
       "  'independent',\n",
       "  'test',\n",
       "  'organization',\n",
       "  'unfamiliar',\n",
       "  'application',\n",
       "  'area',\n",
       "  'The',\n",
       "  'things',\n",
       "  'testers',\n",
       "  'go',\n",
       "  'written',\n",
       "  'requirements',\n",
       "  'So',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'algorithms',\n",
       "  'allow',\n",
       "  'understanding',\n",
       "  'generation',\n",
       "  'humor',\n",
       "  'There',\n",
       "  'general',\n",
       "  'aim',\n",
       "  'modeling',\n",
       "  'humor',\n",
       "  'provide',\n",
       "  'us',\n",
       "  'lots',\n",
       "  'information',\n",
       "  'cognitive',\n",
       "  'abilities',\n",
       "  'general',\n",
       "  'reasoning',\n",
       "  'remembering',\n",
       "  'understanding',\n",
       "  'situations',\n",
       "  'understanding',\n",
       "  'conversati',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'In',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'ML',\n",
       "  'used',\n",
       "  'solve',\n",
       "  'complex',\n",
       "  'tasks',\n",
       "  'different',\n",
       "  'disciplines',\n",
       "  'ranging',\n",
       "  'Data',\n",
       "  'Mining',\n",
       "  'Information',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'argue',\n",
       "  'manual',\n",
       "  'automatic',\n",
       "  'thesauruses',\n",
       "  'alternative',\n",
       "  'resources',\n",
       "  'NLP',\n",
       "  'tasks',\n",
       "  'This',\n",
       "  'involves',\n",
       "  'radical',\n",
       "  'step',\n",
       "  'interpreting',\n",
       "  'manual',\n",
       "  'thesauruses',\n",
       "  'classifications',\n",
       "  'words',\n",
       "  'rather',\n",
       "  'word',\n",
       "  'senses',\n",
       "  'case',\n",
       "  'made',\n",
       "  'The',\n",
       "  'range',\n",
       "  'roles',\n",
       "  'thesauruses',\n",
       "  'within',\n",
       "  'NLP',\n",
       "  'briefly',\n",
       "  ''],\n",
       " ['',\n",
       "  'Introduction',\n",
       "  'Patterns',\n",
       "  'music',\n",
       "  'object',\n",
       "  'intensive',\n",
       "  'studies',\n",
       "  'past',\n",
       "  'years',\n",
       "  'One',\n",
       "  'purposes',\n",
       "  'analyzing',\n",
       "  'musical',\n",
       "  'structure',\n",
       "  'form',\n",
       "  'discover',\n",
       "  'patterns',\n",
       "  'explicit',\n",
       "  'implicit',\n",
       "  'musical',\n",
       "  'works',\n",
       "  'Simon',\n",
       "  '13',\n",
       "  'Patterns',\n",
       "  'comprise',\n",
       "  'periodicity',\n",
       "  'make',\n",
       "  'use',\n",
       "  'alphabets',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'Many',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'IR',\n",
       "  'systems',\n",
       "  'retrieve',\n",
       "  'relevant',\n",
       "  'documents',\n",
       "  'based',\n",
       "  'exact',\n",
       "  'matching',\n",
       "  'keywords',\n",
       "  'query',\n",
       "  'documents',\n",
       "  'This',\n",
       "  'method',\n",
       "  'degrades',\n",
       "  'precision',\n",
       "  'rate',\n",
       "  'In',\n",
       "  'order',\n",
       "  'solve',\n",
       "  'problem',\n",
       "  'collected',\n",
       "  'semantically',\n",
       "  'related',\n",
       "  'words',\n",
       "  'assigned',\n",
       "  'semantic',\n",
       "  'relationships',\n",
       "  'used',\n",
       "  'gener',\n",
       "  ''],\n",
       " ['',\n",
       "  'paper',\n",
       "  'argue',\n",
       "  'questionanswering',\n",
       "  'QA',\n",
       "  'technical',\n",
       "  'domains',\n",
       "  'distinctly',\n",
       "  'different',\n",
       "  'TREC',\n",
       "  'based',\n",
       "  'QA',\n",
       "  'Web',\n",
       "  'based',\n",
       "  'QA',\n",
       "  'cannot',\n",
       "  'benefit',\n",
       "  'lom',\n",
       "  'data',\n",
       "  'intensive',\n",
       "  'approaches',\n",
       "  ''],\n",
       " ['', 'Universit', 'quot', 'des', 'Saarlandes', ''],\n",
       " ['', 'Proceedings', 'Workshop', ''],\n",
       " ['', 'uni', 'hamburg', 'de', ''],\n",
       " ['', ''],\n",
       " ['', '2', '6', ''],\n",
       " ['',\n",
       "  'SRI',\n",
       "  'developed',\n",
       "  'new',\n",
       "  'architecture',\n",
       "  'integrating',\n",
       "  'speech',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'applies',\n",
       "  'linguistic',\n",
       "  'constraints',\n",
       "  'recognition',\n",
       "  'incrementally',\n",
       "  'expanding',\n",
       "  'state',\n",
       "  'transition',\n",
       "  'network',\n",
       "  'embodied',\n",
       "  'unification',\n",
       "  'grammar',\n",
       "  'We',\n",
       "  'compare',\n",
       "  'dynamic',\n",
       "  'gralnlnar',\n",
       "  'network',\n",
       "  'DGN',\n",
       "  'approach',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'chapter',\n",
       "  'considers',\n",
       "  'revolution',\n",
       "  'taken',\n",
       "  'place',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'research',\n",
       "  'last',\n",
       "  'five',\n",
       "  'years',\n",
       "  'It',\n",
       "  'begins',\n",
       "  'providing',\n",
       "  'brief',\n",
       "  'guide',\n",
       "  'structure',\n",
       "  'field',\n",
       "  'presents',\n",
       "  'caricature',\n",
       "  'two',\n",
       "  'competing',\n",
       "  'paradigms',\n",
       "  '1980s',\n",
       "  'NLP',\n",
       "  'research',\n",
       "  'indicates',\n",
       "  'reasons',\n",
       "  'wh',\n",
       "  ''],\n",
       " ['',\n",
       "  'visual',\n",
       "  'development',\n",
       "  'environment',\n",
       "  'support',\n",
       "  'visual',\n",
       "  'assembly',\n",
       "  'execution',\n",
       "  'analysis',\n",
       "  'modular',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'The',\n",
       "  'visual',\n",
       "  'model',\n",
       "  'executable',\n",
       "  'data',\n",
       "  'flow',\n",
       "  'program',\n",
       "  'graph',\n",
       "  'automatically',\n",
       "  'synthesised',\n",
       "  'data',\n",
       "  'dependency',\n",
       "  'declarations',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'modules',\n",
       "  'The',\n",
       "  'graph',\n",
       "  'th',\n",
       "  ''],\n",
       " ['',\n",
       "  'In',\n",
       "  'Chapter',\n",
       "  'basic',\n",
       "  'uses',\n",
       "  'Description',\n",
       "  'Logics',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'analysed',\n",
       "  'together',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'history',\n",
       "  'role',\n",
       "  'Description',\n",
       "  'Logics',\n",
       "  'current',\n",
       "  'state',\n",
       "  'art',\n",
       "  'computational',\n",
       "  'linguistics',\n",
       "  'pointed',\n",
       "  '18',\n",
       "  '1',\n",
       "  'Introduction',\n",
       "  'Since',\n",
       "  'early',\n",
       "  'days',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'applied',\n",
       "  'structure',\n",
       "  'learning',\n",
       "  'model',\n",
       "  'Max',\n",
       "  'Margin',\n",
       "  'Structure',\n",
       "  'MMS',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'NLP',\n",
       "  'tasks',\n",
       "  'aim',\n",
       "  'capture',\n",
       "  'latent',\n",
       "  'relationships',\n",
       "  'within',\n",
       "  'output',\n",
       "  'language',\n",
       "  'domain',\n",
       "  'We',\n",
       "  'formulate',\n",
       "  'model',\n",
       "  'extension',\n",
       "  'multi',\n",
       "  'class',\n",
       "  'Support',\n",
       "  'Vector',\n",
       "  'Machine',\n",
       "  'SVM',\n",
       "  'present',\n",
       "  'per',\n",
       "  ''],\n",
       " ['',\n",
       "  'Vast',\n",
       "  'quantities',\n",
       "  'text',\n",
       "  'becoming',\n",
       "  'available',\n",
       "  'elec',\n",
       "  'tronic',\n",
       "  'form',\n",
       "  'ranging',\n",
       "  'published',\n",
       "  'documents',\n",
       "  'e',\n",
       "  'g',\n",
       "  'electronic',\n",
       "  'dictionaries',\n",
       "  'encyclopedias',\n",
       "  'libraries',\n",
       "  'archives',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'services',\n",
       "  'private',\n",
       "  'databases',\n",
       "  'e',\n",
       "  'g',\n",
       "  'marketing',\n",
       "  'information',\n",
       "  'legal',\n",
       "  'records',\n",
       "  'medical',\n",
       "  'histories',\n",
       "  'per',\n",
       "  ''],\n",
       " ['',\n",
       "  'Over',\n",
       "  'last',\n",
       "  'years',\n",
       "  'number',\n",
       "  'areas',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'begun',\n",
       "  'applying',\n",
       "  'graph',\n",
       "  'based',\n",
       "  'techniques',\n",
       "  'These',\n",
       "  'include',\n",
       "  'among',\n",
       "  'others',\n",
       "  'text',\n",
       "  'summarization',\n",
       "  'syntactic',\n",
       "  'parsing',\n",
       "  'word',\n",
       "  'sense',\n",
       "  'disambiguation',\n",
       "  'ontology',\n",
       "  'construction',\n",
       "  'sentiment',\n",
       "  'subjectivity',\n",
       "  'analysis',\n",
       "  'text',\n",
       "  'clustering',\n",
       "  'In',\n",
       "  'pa',\n",
       "  ''],\n",
       " ['',\n",
       "  'In',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'research',\n",
       "  'results',\n",
       "  'software',\n",
       "  'engineering',\n",
       "  'software',\n",
       "  'technology',\n",
       "  'often',\n",
       "  'neglected',\n",
       "  ''],\n",
       " ['',\n",
       "  'Kernelized',\n",
       "  'sorting',\n",
       "  'approach',\n",
       "  'matching',\n",
       "  'objects',\n",
       "  'two',\n",
       "  'sources',\n",
       "  'domains',\n",
       "  'require',\n",
       "  'prior',\n",
       "  'notion',\n",
       "  'similarity',\n",
       "  'objects',\n",
       "  'across',\n",
       "  'two',\n",
       "  'sources',\n",
       "  'Unfortunately',\n",
       "  'technique',\n",
       "  'highly',\n",
       "  'sensitive',\n",
       "  'initialization',\n",
       "  'high',\n",
       "  'dimensional',\n",
       "  'data',\n",
       "  'We',\n",
       "  'present',\n",
       "  'variants',\n",
       "  'kern',\n",
       "  ''],\n",
       " ['',\n",
       "  'Natural',\n",
       "  'language',\n",
       "  'complex',\n",
       "  'compound',\n",
       "  'organization',\n",
       "  'structures',\n",
       "  'basic',\n",
       "  'linguistic',\n",
       "  'elements',\n",
       "  'represent',\n",
       "  'various',\n",
       "  'meanings',\n",
       "  'Therefore',\n",
       "  'understand',\n",
       "  'nature',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'need',\n",
       "  'sophisticated',\n",
       "  'treatment',\n",
       "  'basic',\n",
       "  'elements',\n",
       "  'well',\n",
       "  'insights',\n",
       "  'elements',\n",
       "  ''],\n",
       " ['',\n",
       "  'In',\n",
       "  'paper',\n",
       "  'describe',\n",
       "  'framework',\n",
       "  'developing',\n",
       "  'probabilistic',\n",
       "  'classifiers',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'Our',\n",
       "  'focus',\n",
       "  'formulating',\n",
       "  'models',\n",
       "  'capture',\n",
       "  'important',\n",
       "  'interdependencies',\n",
       "  'among',\n",
       "  'features',\n",
       "  'avoid',\n",
       "  'overfitting',\n",
       "  'data',\n",
       "  'also',\n",
       "  'characterizing',\n",
       "  'data',\n",
       "  'well',\n",
       "  'The',\n",
       "  'class',\n",
       "  'pro',\n",
       "  ''],\n",
       " ['',\n",
       "  'Many',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'techniques',\n",
       "  'used',\n",
       "  'Information',\n",
       "  'Retrieval',\n",
       "  'The',\n",
       "  'results',\n",
       "  'encouraging',\n",
       "  'Simple',\n",
       "  'methods',\n",
       "  'stopwording',\n",
       "  'porter',\n",
       "  'style',\n",
       "  'stemming',\n",
       "  'etc',\n",
       "  'usually',\n",
       "  'yield',\n",
       "  'significant',\n",
       "  'improvements',\n",
       "  'higher',\n",
       "  'level',\n",
       "  'processing',\n",
       "  'chunking',\n",
       "  'parsing',\n",
       "  'word',\n",
       "  'sense',\n",
       "  'disambiguation',\n",
       "  'e',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'explains',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'using',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'Malayalam',\n",
       "  'language',\n",
       "  'basic',\n",
       "  ''],\n",
       " ['',\n",
       "  'The',\n",
       "  'research',\n",
       "  'areas',\n",
       "  'plan',\n",
       "  'recognition',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'parsing',\n",
       "  'share',\n",
       "  'many',\n",
       "  'common',\n",
       "  'features',\n",
       "  'even',\n",
       "  'algorithms',\n",
       "  'However',\n",
       "  'dialog',\n",
       "  'two',\n",
       "  'disciplines',\n",
       "  'effective',\n",
       "  'Specifically',\n",
       "  'significant',\n",
       "  'recent',\n",
       "  'results',\n",
       "  'parsing',\n",
       "  'mildly',\n",
       "  'context',\n",
       "  'sensitive',\n",
       "  'grammars',\n",
       "  'leveraged',\n",
       "  ''],\n",
       " ['',\n",
       "  'The',\n",
       "  'research',\n",
       "  'areas',\n",
       "  'plan',\n",
       "  'recognition',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'parsing',\n",
       "  'share',\n",
       "  'many',\n",
       "  'common',\n",
       "  'features',\n",
       "  'even',\n",
       "  'algorithms',\n",
       "  'However',\n",
       "  'dialog',\n",
       "  'two',\n",
       "  'disciplines',\n",
       "  'effective',\n",
       "  'Specifically',\n",
       "  'significant',\n",
       "  'recent',\n",
       "  'results',\n",
       "  'parsing',\n",
       "  'mildly',\n",
       "  'context',\n",
       "  'sensitive',\n",
       "  'grammars',\n",
       "  'leveraged',\n",
       "  ''],\n",
       " ['',\n",
       "  'Information',\n",
       "  'retrieval',\n",
       "  'process',\n",
       "  'finding',\n",
       "  'documents',\n",
       "  'document',\n",
       "  'collection',\n",
       "  'satisfies',\n",
       "  'information',\n",
       "  'need',\n",
       "  'user',\n",
       "  'The',\n",
       "  'documents',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'constructs',\n",
       "  'motivation',\n",
       "  'work',\n",
       "  'investigate',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'used',\n",
       "  'improve',\n",
       "  'performa',\n",
       "  ''],\n",
       " ['',\n",
       "  'While',\n",
       "  'computational',\n",
       "  'logic',\n",
       "  'become',\n",
       "  'widely',\n",
       "  'used',\n",
       "  'representing',\n",
       "  'reasoning',\n",
       "  'linguistic',\n",
       "  'knowledge',\n",
       "  'cross',\n",
       "  'fertilization',\n",
       "  'logic',\n",
       "  'programming',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'given',\n",
       "  'rise',\n",
       "  'new',\n",
       "  'discipline',\n",
       "  'known',\n",
       "  'inductive',\n",
       "  'logic',\n",
       "  'programming',\n",
       "  'Inspired',\n",
       "  'building',\n",
       "  'achievements',\n",
       "  ''],\n",
       " ['',\n",
       "  'What',\n",
       "  'statistical',\n",
       "  'method',\n",
       "  'used',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'NLP',\n",
       "  'In',\n",
       "  'paper',\n",
       "  'start',\n",
       "  'definition',\n",
       "  'NLP',\n",
       "  'concerned',\n",
       "  'design',\n",
       "  'implementation',\n",
       "  'effective',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'input',\n",
       "  'output',\n",
       "  'components',\n",
       "  'computational',\n",
       "  'systems',\n",
       "  'We',\n",
       "  'distinguish',\n",
       "  'three',\n",
       "  'kind',\n",
       "  ''],\n",
       " ['',\n",
       "  'In',\n",
       "  'report',\n",
       "  'collaborative',\n",
       "  'work',\n",
       "  'fields',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  'ML',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'presented',\n",
       "  'The',\n",
       "  'document',\n",
       "  'structured',\n",
       "  'two',\n",
       "  'parts',\n",
       "  'The',\n",
       "  'first',\n",
       "  'part',\n",
       "  'includes',\n",
       "  'superficial',\n",
       "  'comprehensive',\n",
       "  'survey',\n",
       "  'covering',\n",
       "  'state',\n",
       "  'art',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'techniq',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'This',\n",
       "  'thesis',\n",
       "  'examines',\n",
       "  'use',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'techniques',\n",
       "  'various',\n",
       "  'tasks',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'mainly',\n",
       "  'task',\n",
       "  'information',\n",
       "  'extraction',\n",
       "  'texts',\n",
       "  'The',\n",
       "  'objectives',\n",
       "  'improvement',\n",
       "  'adaptability',\n",
       "  'information',\n",
       "  'extraction',\n",
       "  'systems',\n",
       "  'new',\n",
       "  'thematic',\n",
       "  'mains',\n",
       "  'even',\n",
       "  'lang',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'chapter',\n",
       "  'examines',\n",
       "  'application',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'computerassisted',\n",
       "  'language',\n",
       "  'learning',\n",
       "  'including',\n",
       "  'history',\n",
       "  'work',\n",
       "  'field',\n",
       "  'last',\n",
       "  'thirtyfive',\n",
       "  'years',\n",
       "  'focus',\n",
       "  'current',\n",
       "  'developments',\n",
       "  'opportunities',\n",
       "  '36',\n",
       "  '1',\n",
       "  ''],\n",
       " ['',\n",
       "  'Traditional',\n",
       "  'approaches',\n",
       "  'tointerpretation',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'typically',\n",
       "  'fall',\n",
       "  'one',\n",
       "  'three',\n",
       "  'classes',\n",
       "  'syntax',\n",
       "  'driven',\n",
       "  'semantics',\n",
       "  'driven',\n",
       "  'frame',\n",
       "  'task',\n",
       "  'based',\n",
       "  'Syntax',\n",
       "  'driven',\n",
       "  'approaches',\n",
       "  'use',\n",
       "  'domain',\n",
       "  'independent',\n",
       "  'grammar',\n",
       "  'drive',\n",
       "  'interpretation',\n",
       "  'process',\n",
       "  'produce',\n",
       "  'global',\n",
       "  'parse',\n",
       "  'input',\n",
       "  ''],\n",
       " ['',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'large',\n",
       "  'diverse',\n",
       "  'subtopic',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'As',\n",
       "  'result',\n",
       "  'NLP',\n",
       "  'many',\n",
       "  'subtopics',\n",
       "  'including',\n",
       "  'optical',\n",
       "  'character',\n",
       "  'recognition',\n",
       "  'text',\n",
       "  'speech',\n",
       "  'translators',\n",
       "  'foreign',\n",
       "  'language',\n",
       "  'reading',\n",
       "  'writing',\n",
       "  'aids',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  'speech',\n",
       "  'recognition',\n",
       "  'W',\n",
       "  ''],\n",
       " ['',\n",
       "  'Probabilistic',\n",
       "  'finite',\n",
       "  'state',\n",
       "  'string',\n",
       "  'transducers',\n",
       "  'FSTs',\n",
       "  'extremely',\n",
       "  'popular',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'due',\n",
       "  'powerful',\n",
       "  'generic',\n",
       "  'methods',\n",
       "  'applying',\n",
       "  'composing',\n",
       "  'learning',\n",
       "  'Unfortunately',\n",
       "  'FSTs',\n",
       "  'good',\n",
       "  'fit',\n",
       "  'much',\n",
       "  'current',\n",
       "  'work',\n",
       "  'probabilistic',\n",
       "  'modeling',\n",
       "  'machine',\n",
       "  'translati',\n",
       "  ''],\n",
       " ['',\n",
       "  'ABSTRACT',\n",
       "  'In',\n",
       "  'special',\n",
       "  'issue',\n",
       "  'TAL',\n",
       "  'look',\n",
       "  'fundamental',\n",
       "  'principles',\n",
       "  'underlying',\n",
       "  'evaluation',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'We',\n",
       "  'adopt',\n",
       "  'global',\n",
       "  'point',\n",
       "  'view',\n",
       "  'goes',\n",
       "  'beyond',\n",
       "  'horizon',\n",
       "  'single',\n",
       "  'evaluation',\n",
       "  'campaign',\n",
       "  'particular',\n",
       "  'protocol',\n",
       "  'After',\n",
       "  'brief',\n",
       "  'review',\n",
       "  'history',\n",
       "  'terminology',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'NLP',\n",
       "  'extract',\n",
       "  'clinical',\n",
       "  'information',\n",
       "  'textual',\n",
       "  'reports',\n",
       "  'shown',\n",
       "  'effective',\n",
       "  'limited',\n",
       "  'domains',\n",
       "  'particular',\n",
       "  'applications',\n",
       "  'Because',\n",
       "  'NLP',\n",
       "  'system',\n",
       "  'typically',\n",
       "  'requires',\n",
       "  'substantial',\n",
       "  'resources',\n",
       "  'develop',\n",
       "  'beneficial',\n",
       "  'designed',\n",
       "  'easily',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'propose',\n",
       "  'bifurcated',\n",
       "  'paradigm',\n",
       "  'construction',\n",
       "  'Prolog',\n",
       "  'knowl',\n",
       "  'edge',\n",
       "  'base',\n",
       "  'body',\n",
       "  'documents',\n",
       "  'first',\n",
       "  'information',\n",
       "  'extraction',\n",
       "  'IE',\n",
       "  'ap',\n",
       "  'plication',\n",
       "  'annotate',\n",
       "  'corpus',\n",
       "  'output',\n",
       "  'annotated',\n",
       "  'documents',\n",
       "  'second',\n",
       "  'Prolog',\n",
       "  'knowledge',\n",
       "  'base',\n",
       "  'KB',\n",
       "  'application',\n",
       "  'transform',\n",
       "  'th',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'describe',\n",
       "  'single',\n",
       "  'convolutional',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'architecture',\n",
       "  'given',\n",
       "  'sentence',\n",
       "  'outputs',\n",
       "  'host',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'predictions',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'tags',\n",
       "  'chunks',\n",
       "  'named',\n",
       "  'entity',\n",
       "  'tags',\n",
       "  'semantic',\n",
       "  'roles',\n",
       "  'semantically',\n",
       "  'similar',\n",
       "  'words',\n",
       "  'likelihood',\n",
       "  'sentence',\n",
       "  'makes',\n",
       "  'sense',\n",
       "  'grammatically',\n",
       "  'sem',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'developed',\n",
       "  'prototype',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'system',\n",
       "  'uses',\n",
       "  'advanced',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'techniques',\n",
       "  'enhance',\n",
       "  'effectiveness',\n",
       "  'traditional',\n",
       "  'key',\n",
       "  'word',\n",
       "  'based',\n",
       "  'document',\n",
       "  'retrieval',\n",
       "  'The',\n",
       "  'backbone',\n",
       "  'system',\n",
       "  'statistical',\n",
       "  'retrieval',\n",
       "  'engine',\n",
       "  'performs',\n",
       "  'automated',\n",
       "  'indexing',\n",
       "  'docum',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'In',\n",
       "  'paper',\n",
       "  'discuss',\n",
       "  'several',\n",
       "  'issues',\n",
       "  'requirements',\n",
       "  'enabling',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'become',\n",
       "  'context',\n",
       "  'adaptive',\n",
       "  'Given',\n",
       "  'fact',\n",
       "  'emerging',\n",
       "  'systems',\n",
       "  'feature',\n",
       "  'speaker',\n",
       "  'independent',\n",
       "  'continuous',\n",
       "  'speech',\n",
       "  'recognition',\n",
       "  'restricted',\n",
       "  'individual',\n",
       "  'domains',\n",
       "  'equipped',\n",
       "  'syntactic',\n",
       "  ''],\n",
       " ['',\n",
       "  'In',\n",
       "  'Fall',\n",
       "  '2004',\n",
       "  'I',\n",
       "  'introduced',\n",
       "  'new',\n",
       "  'course',\n",
       "  'called',\n",
       "  'Applied',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'students',\n",
       "  'acquire',\n",
       "  'understanding',\n",
       "  'text',\n",
       "  'analysis',\n",
       "  'techniques',\n",
       "  'currently',\n",
       "  'feasible',\n",
       "  'practical',\n",
       "  'applications',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'study',\n",
       "  'mathematical',\n",
       "  'computational',\n",
       "  'modelling',\n",
       "  'various',\n",
       "  'aspects',\n",
       "  'language',\n",
       "  'improvement',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'systems',\n",
       "  'Natural',\n",
       "  'language',\n",
       "  'language',\n",
       "  'arises',\n",
       "  'innate',\n",
       "  'facility',\n",
       "  'language',\n",
       "  'possessed',\n",
       "  'human',\n",
       "  'intellect',\n",
       "  'may',\n",
       "  ''],\n",
       " ['',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'branch',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'includes',\n",
       "  'speech',\n",
       "  'synthesis',\n",
       "  'Speech',\n",
       "  'recognition',\n",
       "  'Machine',\n",
       "  'translation',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'applications',\n",
       "  'Indian',\n",
       "  'context',\n",
       "  'Most',\n",
       "  'rural',\n",
       "  'Indian',\n",
       "  'community',\n",
       "  'unable',\n",
       "  'make',\n",
       "  'use',\n",
       "  'th',\n",
       "  ''],\n",
       " ['',\n",
       "  'An',\n",
       "  'Evaluation',\n",
       "  'LOLITA',\n",
       "  'related',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'Systems',\n",
       "  'Paul',\n",
       "  'Callaghan',\n",
       "  'Submitted',\n",
       "  'University',\n",
       "  'Durham',\n",
       "  'degree',\n",
       "  'Ph',\n",
       "  'D',\n",
       "  'August',\n",
       "  '1997',\n",
       "  'This',\n",
       "  'research',\n",
       "  'addresses',\n",
       "  'question',\n",
       "  'evaluate',\n",
       "  'systems',\n",
       "  'like',\n",
       "  'LOLITA',\n",
       "  'LOLITA',\n",
       "  'Natural',\n",
       "  ''],\n",
       " ['',\n",
       "  'Previous',\n",
       "  'work',\n",
       "  'demonstrated',\n",
       "  'Web',\n",
       "  'counts',\n",
       "  'used',\n",
       "  'approximate',\n",
       "  'bigram',\n",
       "  'counts',\n",
       "  'suggesting',\n",
       "  'Web',\n",
       "  'based',\n",
       "  'frequencies',\n",
       "  'useful',\n",
       "  'wide',\n",
       "  'variety',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'tasks',\n",
       "  'However',\n",
       "  'limited',\n",
       "  'number',\n",
       "  'tasks',\n",
       "  'far',\n",
       "  'tested',\n",
       "  'using',\n",
       "  'Web',\n",
       "  'scale',\n",
       "  'data',\n",
       "  'sets',\n",
       "  'The',\n",
       "  'pr',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'chapter',\n",
       "  'examines',\n",
       "  'application',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'computerassisted',\n",
       "  'language',\n",
       "  'learning',\n",
       "  'including',\n",
       "  'history',\n",
       "  'work',\n",
       "  'field',\n",
       "  'last',\n",
       "  'thirtyfive',\n",
       "  'years',\n",
       "  'focus',\n",
       "  'current',\n",
       "  'developments',\n",
       "  'opportunities',\n",
       "  '16',\n",
       "  '1',\n",
       "  'Introduction',\n",
       "  'This',\n",
       "  'chapter',\n",
       "  'focuses',\n",
       "  'applications',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'describes',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'system',\n",
       "  'improves',\n",
       "  'performance',\n",
       "  'learning',\n",
       "  'The',\n",
       "  'system',\n",
       "  'processes',\n",
       "  'short',\n",
       "  'English',\n",
       "  'narratives',\n",
       "  'able',\n",
       "  'acquire',\n",
       "  'single',\n",
       "  'narrative',\n",
       "  'new',\n",
       "  'schema',\n",
       "  'stereotypical',\n",
       "  'set',\n",
       "  'actions',\n",
       "  'During',\n",
       "  'understanding',\n",
       "  'process',\n",
       "  'system',\n",
       "  'attempts',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'classify',\n",
       "  'review',\n",
       "  'current',\n",
       "  'approaches',\n",
       "  'software',\n",
       "  'infrastructure',\n",
       "  'research',\n",
       "  'development',\n",
       "  'delivery',\n",
       "  'NLP',\n",
       "  'systems',\n",
       "  'The',\n",
       "  'task',\n",
       "  ''],\n",
       " ['',\n",
       "  'Confidence',\n",
       "  'measures',\n",
       "  'practical',\n",
       "  'solution',\n",
       "  'improving',\n",
       "  'usefulness',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'applications',\n",
       "  'Confidence',\n",
       "  'estimation',\n",
       "  'generic',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'approach',\n",
       "  'deriving',\n",
       "  'confidence',\n",
       "  'measures',\n",
       "  'We',\n",
       "  'give',\n",
       "  'overview',\n",
       "  'application',\n",
       "  'confidence',\n",
       "  'estimation',\n",
       "  'various',\n",
       "  'fields',\n",
       "  'N',\n",
       "  ''],\n",
       " ['',\n",
       "  'lex',\n",
       "  'sign',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'dictionary',\n",
       "  'LDOCE',\n",
       "  'lex',\n",
       "  'sign',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'ldb',\n",
       "  'entry',\n",
       "  '12364',\n",
       "  'lex',\n",
       "  'sign',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'sense',\n",
       "  '0',\n",
       "  'When',\n",
       "  'loaded',\n",
       "  'LKB',\n",
       "  '9',\n",
       "  'expanded',\n",
       "  'fully',\n",
       "  'fledged',\n",
       "  'representation',\n",
       "  'transitive',\n",
       "  'use',\n",
       "  'e',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'describe',\n",
       "  'design',\n",
       "  'use',\n",
       "  'Stanford',\n",
       "  'CoreNLP',\n",
       "  'toolkit',\n",
       "  'extensible',\n",
       "  'pipeline',\n",
       "  'provides',\n",
       "  'core',\n",
       "  'natural',\n",
       "  'lan',\n",
       "  'guage',\n",
       "  'analysis',\n",
       "  'This',\n",
       "  'toolkit',\n",
       "  'quite',\n",
       "  'widely',\n",
       "  'used',\n",
       "  'research',\n",
       "  'NLP',\n",
       "  'community',\n",
       "  'also',\n",
       "  'among',\n",
       "  'commercial',\n",
       "  'govern',\n",
       "  'ment',\n",
       "  'users',\n",
       "  'open',\n",
       "  'source',\n",
       "  'NLP',\n",
       "  'technol',\n",
       "  'ogy',\n",
       "  'We',\n",
       "  'suggest',\n",
       "  ''],\n",
       " ['',\n",
       "  'Gaussian',\n",
       "  'Processes',\n",
       "  'GPs',\n",
       "  'powerful',\n",
       "  'mod',\n",
       "  'elling',\n",
       "  'framework',\n",
       "  'incorporating',\n",
       "  'kernels',\n",
       "  'Bayesian',\n",
       "  'inference',\n",
       "  'recognised',\n",
       "  'state',\n",
       "  'art',\n",
       "  'many',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'tasks',\n",
       "  ''],\n",
       " ['',\n",
       "  'A',\n",
       "  'fundamental',\n",
       "  'issue',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'prerequisite',\n",
       "  'enormous',\n",
       "  'quantity',\n",
       "  'preprogrammed',\n",
       "  'knowledge',\n",
       "  'concerning',\n",
       "  'language',\n",
       "  'domain',\n",
       "  'examination',\n",
       "  'Manual',\n",
       "  'acquisition',\n",
       "  'knowledge',\n",
       "  'tedious',\n",
       "  'error',\n",
       "  'prone',\n",
       "  'Development',\n",
       "  'automated',\n",
       "  'acquisition',\n",
       "  'process',\n",
       "  ''],\n",
       " ['',\n",
       "  'A',\n",
       "  'general',\n",
       "  'reusable',\n",
       "  'computational',\n",
       "  'resource',\n",
       "  'de',\n",
       "  'veloped',\n",
       "  'within',\n",
       "  'Penman',\n",
       "  'text',\n",
       "  'generation',\n",
       "  'project',\n",
       "  'organizing',\n",
       "  'domain',\n",
       "  'knowledge',\n",
       "  'appropriately',\n",
       "  'linguistic',\n",
       "  'realization',\n",
       "  'This',\n",
       "  'resource',\n",
       "  'called',\n",
       "  'upper',\n",
       "  'model',\n",
       "  'provides',\n",
       "  'domain',\n",
       "  'task',\n",
       "  'independent',\n",
       "  'classification',\n",
       "  'system',\n",
       "  'supports',\n",
       "  ''],\n",
       " ['',\n",
       "  'Kohonen',\n",
       "  'Self',\n",
       "  'Organizing',\n",
       "  'Map',\n",
       "  'SOM',\n",
       "  'one',\n",
       "  'popular',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'algorithms',\n",
       "  'Word',\n",
       "  'category',\n",
       "  'maps',\n",
       "  'SOMs',\n",
       "  'organized',\n",
       "  'according',\n",
       "  'word',\n",
       "  'similarities',\n",
       "  'measured',\n",
       "  'similarity',\n",
       "  'short',\n",
       "  'contexts',\n",
       "  'words',\n",
       "  'Conceptually',\n",
       "  'interrelated',\n",
       "  'words',\n",
       "  'tend',\n",
       "  'fall',\n",
       "  ''],\n",
       " ['',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'presents',\n",
       "  'workbench',\n",
       "  'built',\n",
       "  'Priberam',\n",
       "  'Informática',\n",
       "  'development',\n",
       "  'company',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'technology',\n",
       "  'This',\n",
       "  'workbench',\n",
       "  'includes',\n",
       "  'set',\n",
       "  'linguistic',\n",
       "  'resources',\n",
       "  'software',\n",
       "  'tools',\n",
       "  'applied',\n",
       "  'considerable',\n",
       "  'number',\n",
       "  'practical',\n",
       "  'purposes',\n",
       "  'covering',\n",
       "  'proofing',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'effective',\n",
       "  'approach',\n",
       "  'bringing',\n",
       "  'improvement',\n",
       "  'educational',\n",
       "  'setting',\n",
       "  'Implementing',\n",
       "  'NLP',\n",
       "  'involves',\n",
       "  'initiating',\n",
       "  'process',\n",
       "  'learning',\n",
       "  'natural',\n",
       "  'acquisition',\n",
       "  'educational',\n",
       "  'systems',\n",
       "  'It',\n",
       "  'based',\n",
       "  'effective',\n",
       "  'approaches',\n",
       "  'providing',\n",
       "  'solution',\n",
       "  'f',\n",
       "  ''],\n",
       " ['',\n",
       "  'ABSTRACT',\n",
       "  'After',\n",
       "  'twenty',\n",
       "  'years',\n",
       "  'disfavor',\n",
       "  'technology',\n",
       "  'returned',\n",
       "  'imitates',\n",
       "  'processes',\n",
       "  'brain',\n",
       "  'Natural',\n",
       "  'language',\n",
       "  'experiments',\n",
       "  'Sejnowski',\n",
       "  'Rosenberg',\n",
       "  '1986',\n",
       "  'demonstrate',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'computing',\n",
       "  'architecture',\n",
       "  'learn',\n",
       "  'actual',\n",
       "  'spoken',\n",
       "  'language',\n",
       "  'observe',\n",
       "  'rules',\n",
       "  'pronunciation',\n",
       "  ''],\n",
       " ['',\n",
       "  'Text',\n",
       "  'statistics',\n",
       "  'frequently',\n",
       "  'used',\n",
       "  'stylometry',\n",
       "  'cryptography',\n",
       "  'studies',\n",
       "  'In',\n",
       "  'paper',\n",
       "  'text',\n",
       "  'statistics',\n",
       "  'tools',\n",
       "  'developed',\n",
       "  'ISO',\n",
       "  'Prolog',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'Details',\n",
       "  'given',\n",
       "  'usage',\n",
       "  '21',\n",
       "  'user',\n",
       "  'callable',\n",
       "  'predicates',\n",
       "  'Logic',\n",
       "  'limitations',\n",
       "  'program',\n",
       "  'also',\n",
       "  'discussed',\n",
       "  '1',\n",
       "  ''],\n",
       " ['',\n",
       "  'We',\n",
       "  'summarize',\n",
       "  'experience',\n",
       "  'using',\n",
       "  'FrameNet',\n",
       "  'two',\n",
       "  'rather',\n",
       "  'different',\n",
       "  'projects',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'NLP',\n",
       "  'We',\n",
       "  'conclude',\n",
       "  'NLP',\n",
       "  'benefit',\n",
       "  'FrameNet',\n",
       "  'different',\n",
       "  'ways',\n",
       "  'sketch',\n",
       "  'problems',\n",
       "  'need',\n",
       "  'overcome',\n",
       "  '1',\n",
       "  ''],\n",
       " ['',\n",
       "  'Research',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'NLP',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'benefited',\n",
       "  'enormous',\n",
       "  'amount',\n",
       "  'raw',\n",
       "  'textual',\n",
       "  'data',\n",
       "  'available',\n",
       "  'World',\n",
       "  'Wide',\n",
       "  'Web',\n",
       "  'The',\n",
       "  'presence',\n",
       "  'standard',\n",
       "  'search',\n",
       "  'engines',\n",
       "  'made',\n",
       "  'data',\n",
       "  'accessible',\n",
       "  'computational',\n",
       "  'linguists',\n",
       "  'corpus',\n",
       "  'size',\n",
       "  'never',\n",
       "  'existed',\n",
       "  'befo',\n",
       "  ''],\n",
       " ['',\n",
       "  'Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'NLP',\n",
       "  'programs',\n",
       "  'confronted',\n",
       "  'various',\n",
       "  'di',\n",
       "  'culties',\n",
       "  'processing',\n",
       "  'HTML',\n",
       "  'XML',\n",
       "  'documents',\n",
       "  'potential',\n",
       "  'produce',\n",
       "  'better',\n",
       "  'results',\n",
       "  'linguistic',\n",
       "  'information',\n",
       "  'annotated',\n",
       "  'source',\n",
       "  'texts',\n",
       "  'Wehave',\n",
       "  'therefore',\n",
       "  'developed',\n",
       "  'Linguistic',\n",
       "  'Annotation',\n",
       "  'Language',\n",
       "  'LAL',\n",
       "  ''],\n",
       " ['',\n",
       "  'Introduction',\n",
       "  'Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'appears',\n",
       "  'surface',\n",
       "  'strongly',\n",
       "  'symbolic',\n",
       "  'activity',\n",
       "  'Words',\n",
       "  'symbols',\n",
       "  'stand',\n",
       "  'objects',\n",
       "  'concepts',\n",
       "  'real',\n",
       "  'world',\n",
       "  'put',\n",
       "  'together',\n",
       "  'sentences',\n",
       "  'obey',\n",
       "  'well',\n",
       "  'specified',\n",
       "  'grammar',\n",
       "  'rules',\n",
       "  'It',\n",
       "  'surprise',\n",
       "  'several',\n",
       "  'decades',\n",
       "  'na',\n",
       "  ''],\n",
       " ['',\n",
       "  'Abstract',\n",
       "  'Diff',\n",
       "  'software',\n",
       "  'program',\n",
       "  'detects',\n",
       "  'differences',\n",
       "  'two',\n",
       "  'data',\n",
       "  'sets',\n",
       "  'useful',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'shows',\n",
       "  'several',\n",
       "  'examples',\n",
       "  'application',\n",
       "  'diff',\n",
       "  'They',\n",
       "  'include',\n",
       "  'detection',\n",
       "  'differences',\n",
       "  'two',\n",
       "  'different',\n",
       "  'datasets',\n",
       "  'extraction',\n",
       "  'rewriting',\n",
       "  'rules',\n",
       "  'mer',\n",
       "  ''],\n",
       " ['',\n",
       "  'In',\n",
       "  'paper',\n",
       "  'present',\n",
       "  'compare',\n",
       "  'automatically',\n",
       "  'generated',\n",
       "  'titles',\n",
       "  'machine',\n",
       "  'translated',\n",
       "  'documents',\n",
       "  'using',\n",
       "  'several',\n",
       "  'different',\n",
       "  'statistics',\n",
       "  'based',\n",
       "  'methods',\n",
       "  'A',\n",
       "  'Naïve',\n",
       "  'Bayesian',\n",
       "  'K',\n",
       "  'Nearest',\n",
       "  'Neighbour',\n",
       "  'TF',\n",
       "  'IDF',\n",
       "  'erative',\n",
       "  'Expectation',\n",
       "  'Maximization',\n",
       "  'method',\n",
       "  'title',\n",
       "  'gen',\n",
       "  'eration',\n",
       "  'applied',\n",
       "  '1000',\n",
       "  'origi',\n",
       "  ''],\n",
       " ['', '9', 'Bibliography', ''],\n",
       " ['',\n",
       "  'Applying',\n",
       "  'Natural',\n",
       "  'Language',\n",
       "  'Processing',\n",
       "  'techniques',\n",
       "  'biomedical',\n",
       "  'text',\n",
       "  'potential',\n",
       "  'aid',\n",
       "  'curation',\n",
       "  'become',\n",
       "  'focus',\n",
       "  'intensive',\n",
       "  'research',\n",
       "  'However',\n",
       "  'developing',\n",
       "  'integrated',\n",
       "  'systems',\n",
       "  'address',\n",
       "  'curators',\n",
       "  'real',\n",
       "  'world',\n",
       "  'needs',\n",
       "  'studied',\n",
       "  'less',\n",
       "  'rigorously',\n",
       "  'This',\n",
       "  'paper',\n",
       "  'addresses',\n",
       "  'question',\n",
       "  ''],\n",
       " ['',\n",
       "  'Examples',\n",
       "  'natural',\n",
       "  'languages',\n",
       "  'Chinese',\n",
       "  'English',\n",
       "  'Italian',\n",
       "  'They',\n",
       "  'called',\n",
       "  'natural',\n",
       "  'evolved',\n",
       "  'less',\n",
       "  'natural',\n",
       "  'way',\n",
       "  'without',\n",
       "  'many',\n",
       "  'deliberate',\n",
       "  'considerations',\n",
       "  'This',\n",
       "  'sets',\n",
       "  'apart',\n",
       "  'formal',\n",
       "  'languages',\n",
       "  'amongst',\n",
       "  'programming',\n",
       "  'languages',\n",
       "  'designed',\n",
       "  ''],\n",
       " ['',\n",
       "  'A',\n",
       "  'number',\n",
       "  'powerful',\n",
       "  'modelling',\n",
       "  'techniques',\n",
       "  'developed',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'compress',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'text',\n",
       "  'The',\n",
       "  'best',\n",
       "  'adaptive',\n",
       "  'models',\n",
       "  'operating',\n",
       "  'character',\n",
       "  'word',\n",
       "  'level',\n",
       "  'able',\n",
       "  'perform',\n",
       "  'almost',\n",
       "  'well',\n",
       "  'humans',\n",
       "  'predicting',\n",
       "  'text',\n",
       "  'We',\n",
       "  'show',\n",
       "  'apply',\n",
       "  'character',\n",
       "  'based',\n",
       "  ''],\n",
       " ['',\n",
       "  'A',\n",
       "  'semi',\n",
       "  'automated',\n",
       "  'approach',\n",
       "  'design',\n",
       "  'databases',\n",
       "  'enhanced',\n",
       "  'ERD',\n",
       "  'notation',\n",
       "  'presented',\n",
       "  'It',\n",
       "  'focuses',\n",
       "  'early',\n",
       "  'stage',\n",
       "  'database',\n",
       "  'development',\n",
       "  'stage',\n",
       "  'user',\n",
       "  'requirement',\n",
       "  'analysis',\n",
       "  'It',\n",
       "  'supposed',\n",
       "  'used',\n",
       "  'requirements',\n",
       "  'determination',\n",
       "  'stage',\n",
       "  'analysis',\n",
       "  'The',\n",
       "  'approa',\n",
       "  '']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\racha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\racha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "f1=[]\n",
    "for i in n:\n",
    "   filtered_words = [word for word in i if word not in stopwords.words('english')]\n",
    "   f1.append(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['',\n",
       "  'introduction',\n",
       "  'statistical',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'snlp',\n",
       "  'field',\n",
       "  'lying',\n",
       "  'intersection',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'snlp',\n",
       "  'di',\n",
       "  'ers',\n",
       "  'traditional',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'instead',\n",
       "  'linguist',\n",
       "  'manually',\n",
       "  'construct',\n",
       "  'model',\n",
       "  'given',\n",
       "  'linguistic',\n",
       "  ''],\n",
       " ['',\n",
       "  'the',\n",
       "  'paper',\n",
       "  'summarizes',\n",
       "  'essential',\n",
       "  'properties',\n",
       "  'document',\n",
       "  'retrieval',\n",
       "  'reviews',\n",
       "  'conventional',\n",
       "  'practice',\n",
       "  'research',\n",
       "  'findings',\n",
       "  'latter',\n",
       "  'suggesting',\n",
       "  'simple',\n",
       "  'statistical',\n",
       "  'techniques',\n",
       "  'effective',\n",
       "  'it',\n",
       "  'considers',\n",
       "  'new',\n",
       "  'opportunities',\n",
       "  'challenges',\n",
       "  'presented',\n",
       "  'ability',\n",
       "  'search',\n",
       "  'full',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'language',\n",
       "  'way',\n",
       "  'communicating',\n",
       "  'words',\n",
       "  'language',\n",
       "  'helps',\n",
       "  'understanding',\n",
       "  'world',\n",
       "  'get',\n",
       "  'better',\n",
       "  'insight',\n",
       "  'world',\n",
       "  'language',\n",
       "  'helps',\n",
       "  'speakers',\n",
       "  'vague',\n",
       "  'precise',\n",
       "  'like',\n",
       "  'nlp',\n",
       "  'stands',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'natural',\n",
       "  'languages',\n",
       "  'languages',\n",
       "  'spoken',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'report',\n",
       "  'experiments',\n",
       "  'use',\n",
       "  'standard',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'tools',\n",
       "  'analysis',\n",
       "  'music',\n",
       "  'lyrics',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'amount',\n",
       "  'music',\n",
       "  'audio',\n",
       "  'lyrics',\n",
       "  'lyrics',\n",
       "  'encode',\n",
       "  'important',\n",
       "  'part',\n",
       "  'semantics',\n",
       "  'song',\n",
       "  'therefore',\n",
       "  'analysis',\n",
       "  'complements',\n",
       "  'acoustic',\n",
       "  'cultural',\n",
       "  'metada',\n",
       "  ''],\n",
       " ['',\n",
       "  'paper',\n",
       "  'describe',\n",
       "  'simple',\n",
       "  'rule',\n",
       "  'based',\n",
       "  'approach',\n",
       "  'automated',\n",
       "  'learning',\n",
       "  'linguistic',\n",
       "  'knowledge',\n",
       "  'this',\n",
       "  'approach',\n",
       "  'shown',\n",
       "  'number',\n",
       "  'tasks',\n",
       "  'capture',\n",
       "  'information',\n",
       "  'clearer',\n",
       "  'direct',\n",
       "  'fashion',\n",
       "  'without',\n",
       "  'compromise',\n",
       "  'performance',\n",
       "  'we',\n",
       "  'present',\n",
       "  'detailed',\n",
       "  'case',\n",
       "  'study',\n",
       "  'learni',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'focuses',\n",
       "  'connectionist',\n",
       "  'models',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'we',\n",
       "  'briefly',\n",
       "  'present',\n",
       "  'discuss',\n",
       "  'several',\n",
       "  'aspects',\n",
       "  'high',\n",
       "  'level',\n",
       "  'tasks',\n",
       "  'recently',\n",
       "  'approached',\n",
       "  'connectionism',\n",
       "  'either',\n",
       "  'localist',\n",
       "  'parallel',\n",
       "  'distributed',\n",
       "  'processing',\n",
       "  'models',\n",
       "  'several',\n",
       "  'interesting',\n",
       "  'architectures',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'the',\n",
       "  'article',\n",
       "  'explores',\n",
       "  'possibility',\n",
       "  'construct',\n",
       "  'unified',\n",
       "  'word',\n",
       "  'feature',\n",
       "  'component',\n",
       "  'features',\n",
       "  'letters',\n",
       "  'each',\n",
       "  'letter',\n",
       "  'modeled',\n",
       "  'different',\n",
       "  'attractor',\n",
       "  'finally',\n",
       "  'embedded',\n",
       "  'quadratic',\n",
       "  'iterated',\n",
       "  'map',\n",
       "  'the',\n",
       "  'result',\n",
       "  'word',\n",
       "  'feature',\n",
       "  'account',\n",
       "  'meaning',\n",
       "  'extraction',\n",
       "  'pr',\n",
       "  ''],\n",
       " ['',\n",
       "  'paper',\n",
       "  'see',\n",
       "  'schank',\n",
       "  '86',\n",
       "  'theoretical',\n",
       "  'discussion',\n",
       "  'kass',\n",
       "  '86',\n",
       "  'leake',\n",
       "  'owens',\n",
       "  '86',\n",
       "  'brief',\n",
       "  'discussions',\n",
       "  'program',\n",
       "  'built',\n",
       "  'around',\n",
       "  'principles',\n",
       "  'goal',\n",
       "  'simply',\n",
       "  'point',\n",
       "  'interest',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'led',\n",
       "  'us',\n",
       "  'naturally',\n",
       "  'indeed',\n",
       "  'inevitably',\n",
       "  'de',\n",
       "  ''],\n",
       " ['',\n",
       "  'objectives',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'overview',\n",
       "  'tutorial',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'modern',\n",
       "  'nlp',\n",
       "  'system',\n",
       "  'design',\n",
       "  'target',\n",
       "  'audience',\n",
       "  'this',\n",
       "  'tutorial',\n",
       "  'targets',\n",
       "  'medical',\n",
       "  'informatics',\n",
       "  'generalist',\n",
       "  'limited',\n",
       "  'acquaintance',\n",
       "  'principles',\n",
       "  'behind',\n",
       "  'nlp',\n",
       "  'limited',\n",
       "  'knowledge',\n",
       "  'current',\n",
       "  'state',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'briefly',\n",
       "  'describes',\n",
       "  'current',\n",
       "  'implementation',\n",
       "  'status',\n",
       "  'intelligent',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'system',\n",
       "  'marie',\n",
       "  'employs',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'techniques',\n",
       "  'descriptive',\n",
       "  'captions',\n",
       "  'used',\n",
       "  'iden',\n",
       "  'tify',\n",
       "  'photographic',\n",
       "  'images',\n",
       "  'concerning',\n",
       "  'various',\n",
       "  'military',\n",
       "  'projects',\n",
       "  'the',\n",
       "  'captions',\n",
       "  'parsed',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'metabolism',\n",
       "  'machinery',\n",
       "  'life',\n",
       "  'signal',\n",
       "  'transduction',\n",
       "  'provides',\n",
       "  'regulatory',\n",
       "  'mechanisms',\n",
       "  'control',\n",
       "  'machinery',\n",
       "  'due',\n",
       "  'complexity',\n",
       "  'signal',\n",
       "  'transduction',\n",
       "  'pathways',\n",
       "  'computational',\n",
       "  'approaches',\n",
       "  'needed',\n",
       "  'aid',\n",
       "  'biologist',\n",
       "  'integrating',\n",
       "  'available',\n",
       "  'knowledge',\n",
       "  'formulatio',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'report',\n",
       "  'presents',\n",
       "  'detailed',\n",
       "  'analysis',\n",
       "  'review',\n",
       "  'nlp',\n",
       "  'evaluation',\n",
       "  'principle',\n",
       "  'practice',\n",
       "  'part',\n",
       "  '1',\n",
       "  'examines',\n",
       "  'evaluation',\n",
       "  'concepts',\n",
       "  'establishes',\n",
       "  'framework',\n",
       "  'nlp',\n",
       "  'system',\n",
       "  'evaluation',\n",
       "  'this',\n",
       "  'makes',\n",
       "  'use',\n",
       "  'experience',\n",
       "  'related',\n",
       "  'area',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'analysis',\n",
       "  'also',\n",
       "  'refers',\n",
       "  'ev',\n",
       "  ''],\n",
       " ['',\n",
       "  'web',\n",
       "  'emerged',\n",
       "  'important',\n",
       "  'source',\n",
       "  'information',\n",
       "  'world',\n",
       "  'this',\n",
       "  'resulted',\n",
       "  'need',\n",
       "  'automated',\n",
       "  'software',\n",
       "  'components',\n",
       "  'analyze',\n",
       "  'web',\n",
       "  'pages',\n",
       "  'harvest',\n",
       "  'useful',\n",
       "  'information',\n",
       "  'however',\n",
       "  'typical',\n",
       "  'web',\n",
       "  'pages',\n",
       "  'informative',\n",
       "  'content',\n",
       "  'surrounded',\n",
       "  'high',\n",
       "  'degree',\n",
       "  'noise',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'theoretically',\n",
       "  'motivated',\n",
       "  'range',\n",
       "  'computational',\n",
       "  'techniques',\n",
       "  'analysing',\n",
       "  'representing',\n",
       "  'naturally',\n",
       "  'occurring',\n",
       "  'texts',\n",
       "  'one',\n",
       "  'levels',\n",
       "  'linguistic',\n",
       "  'analysis',\n",
       "  'purpose',\n",
       "  'achieving',\n",
       "  'human',\n",
       "  'like',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'range',\n",
       "  'tasks',\n",
       "  'applications',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'reviews',\n",
       "  'processes',\n",
       "  'involved',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'it',\n",
       "  'demonstrates',\n",
       "  'various',\n",
       "  'kinds',\n",
       "  'choices',\n",
       "  'need',\n",
       "  'taken',\n",
       "  'execution',\n",
       "  'word',\n",
       "  'morphology',\n",
       "  'syntactic',\n",
       "  'text',\n",
       "  'analysis',\n",
       "  'text',\n",
       "  'generation',\n",
       "  'components',\n",
       "  'it',\n",
       "  'compares',\n",
       "  'time',\n",
       "  'complexity',\n",
       "  'traditional',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'article',\n",
       "  'focusses',\n",
       "  'derivation',\n",
       "  'large',\n",
       "  'lexicons',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'we',\n",
       "  'describe',\n",
       "  'development',\n",
       "  'dictionary',\n",
       "  'support',\n",
       "  'environment',\n",
       "  'linking',\n",
       "  'restructured',\n",
       "  'version',\n",
       "  'longman',\n",
       "  'dictionary',\n",
       "  'contemporary',\n",
       "  'english',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'the',\n",
       "  'process',\n",
       "  'restruc',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'introduce',\n",
       "  'method',\n",
       "  'analyzing',\n",
       "  'complexity',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'tasks',\n",
       "  'predicting',\n",
       "  'difficulty',\n",
       "  'new',\n",
       "  'nlp',\n",
       "  'tasks',\n",
       "  'our',\n",
       "  'complexity',\n",
       "  'measures',\n",
       "  'derived',\n",
       "  'kolmogorov',\n",
       "  'complexity',\n",
       "  'class',\n",
       "  'automata',\n",
       "  'meaning',\n",
       "  'automata',\n",
       "  'whose',\n",
       "  'purpose',\n",
       "  'extract',\n",
       "  'relevant',\n",
       "  'pieces',\n",
       "  'infor',\n",
       "  ''],\n",
       " ['',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'emerged',\n",
       "  'new',\n",
       "  'area',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'research',\n",
       "  'it',\n",
       "  'tries',\n",
       "  'mimic',\n",
       "  'human',\n",
       "  'brain',\n",
       "  'capable',\n",
       "  'processing',\n",
       "  'learning',\n",
       "  'complex',\n",
       "  'input',\n",
       "  'data',\n",
       "  'solving',\n",
       "  'different',\n",
       "  'kinds',\n",
       "  'complicated',\n",
       "  'tasks',\n",
       "  'well',\n",
       "  'it',\n",
       "  'successfully',\n",
       "  'applied',\n",
       "  'several',\n",
       "  'fields',\n",
       "  'images',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'author',\n",
       "  'produced',\n",
       "  'version',\n",
       "  'paper',\n",
       "  'published',\n",
       "  'the',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'application',\n",
       "  'automated',\n",
       "  'parsing',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'techniques',\n",
       "  'analyze',\n",
       "  'standard',\n",
       "  'text',\n",
       "  'applications',\n",
       "  'nlp',\n",
       "  'requirements',\n",
       "  'engineering',\n",
       "  'include',\n",
       "  'extraction',\n",
       "  'ontologies',\n",
       "  'requirements',\n",
       "  'specification',\n",
       "  'use',\n",
       "  'nlp',\n",
       "  'verify',\n",
       "  'consistency',\n",
       "  ''],\n",
       " ['',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'addresses',\n",
       "  'problem',\n",
       "  'finding',\n",
       "  'documents',\n",
       "  'whose',\n",
       "  'content',\n",
       "  'matches',\n",
       "  'user',\n",
       "  'request',\n",
       "  'among',\n",
       "  'large',\n",
       "  'collection',\n",
       "  'documents',\n",
       "  'currently',\n",
       "  'successful',\n",
       "  'general',\n",
       "  'purpose',\n",
       "  'retrieval',\n",
       "  'methods',\n",
       "  'statistical',\n",
       "  'methods',\n",
       "  'treat',\n",
       "  'text',\n",
       "  'little',\n",
       "  'bag',\n",
       "  'w',\n",
       "  ''],\n",
       " ['',\n",
       "  'work',\n",
       "  'computational',\n",
       "  'linguistics',\n",
       "  'began',\n",
       "  'soon',\n",
       "  'development',\n",
       "  'first',\n",
       "  'computers',\n",
       "  'booth',\n",
       "  'brandwood',\n",
       "  'cleave',\n",
       "  '1958',\n",
       "  'yet',\n",
       "  'intervening',\n",
       "  'four',\n",
       "  'decades',\n",
       "  'pervasive',\n",
       "  'feeling',\n",
       "  'progress',\n",
       "  'computer',\n",
       "  'understanding',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'commensurate',\n",
       "  'progres',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'a',\n",
       "  'system',\n",
       "  'recognizes',\n",
       "  'authenticates',\n",
       "  'voice',\n",
       "  'user',\n",
       "  'extracting',\n",
       "  'distinct',\n",
       "  'features',\n",
       "  'voice',\n",
       "  'samples',\n",
       "  'usually',\n",
       "  'termed',\n",
       "  'voice',\n",
       "  'recognition',\n",
       "  'system',\n",
       "  'voice',\n",
       "  'identification',\n",
       "  'carried',\n",
       "  'converting',\n",
       "  'human',\n",
       "  'voice',\n",
       "  'digital',\n",
       "  'data',\n",
       "  'the',\n",
       "  'digitized',\n",
       "  'audio',\n",
       "  'samples',\n",
       "  'unde',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'testing',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'requirements',\n",
       "  'standard',\n",
       "  'approach',\n",
       "  'system',\n",
       "  'acceptance',\n",
       "  'testing',\n",
       "  'this',\n",
       "  'test',\n",
       "  'often',\n",
       "  'performed',\n",
       "  'independent',\n",
       "  'test',\n",
       "  'organization',\n",
       "  'unfamiliar',\n",
       "  'application',\n",
       "  'area',\n",
       "  'the',\n",
       "  'things',\n",
       "  'testers',\n",
       "  'go',\n",
       "  'written',\n",
       "  'requirements',\n",
       "  'so',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'algorithms',\n",
       "  'allow',\n",
       "  'understanding',\n",
       "  'generation',\n",
       "  'humor',\n",
       "  'there',\n",
       "  'general',\n",
       "  'aim',\n",
       "  'modeling',\n",
       "  'humor',\n",
       "  'provide',\n",
       "  'us',\n",
       "  'lots',\n",
       "  'information',\n",
       "  'cognitive',\n",
       "  'abilities',\n",
       "  'general',\n",
       "  'reasoning',\n",
       "  'remembering',\n",
       "  'understanding',\n",
       "  'situations',\n",
       "  'understanding',\n",
       "  'conversati',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'in',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'ml',\n",
       "  'used',\n",
       "  'solve',\n",
       "  'complex',\n",
       "  'tasks',\n",
       "  'different',\n",
       "  'disciplines',\n",
       "  'ranging',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'information',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'argue',\n",
       "  'manual',\n",
       "  'automatic',\n",
       "  'thesauruses',\n",
       "  'alternative',\n",
       "  'resources',\n",
       "  'nlp',\n",
       "  'tasks',\n",
       "  'this',\n",
       "  'involves',\n",
       "  'radical',\n",
       "  'step',\n",
       "  'interpreting',\n",
       "  'manual',\n",
       "  'thesauruses',\n",
       "  'classifications',\n",
       "  'words',\n",
       "  'rather',\n",
       "  'word',\n",
       "  'senses',\n",
       "  'case',\n",
       "  'made',\n",
       "  'the',\n",
       "  'range',\n",
       "  'roles',\n",
       "  'thesauruses',\n",
       "  'within',\n",
       "  'nlp',\n",
       "  'briefly',\n",
       "  ''],\n",
       " ['',\n",
       "  'introduction',\n",
       "  'patterns',\n",
       "  'music',\n",
       "  'object',\n",
       "  'intensive',\n",
       "  'studies',\n",
       "  'past',\n",
       "  'years',\n",
       "  'one',\n",
       "  'purposes',\n",
       "  'analyzing',\n",
       "  'musical',\n",
       "  'structure',\n",
       "  'form',\n",
       "  'discover',\n",
       "  'patterns',\n",
       "  'explicit',\n",
       "  'implicit',\n",
       "  'musical',\n",
       "  'works',\n",
       "  'simon',\n",
       "  '13',\n",
       "  'patterns',\n",
       "  'comprise',\n",
       "  'periodicity',\n",
       "  'make',\n",
       "  'use',\n",
       "  'alphabets',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'many',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'ir',\n",
       "  'systems',\n",
       "  'retrieve',\n",
       "  'relevant',\n",
       "  'documents',\n",
       "  'based',\n",
       "  'exact',\n",
       "  'matching',\n",
       "  'keywords',\n",
       "  'query',\n",
       "  'documents',\n",
       "  'this',\n",
       "  'method',\n",
       "  'degrades',\n",
       "  'precision',\n",
       "  'rate',\n",
       "  'in',\n",
       "  'order',\n",
       "  'solve',\n",
       "  'problem',\n",
       "  'collected',\n",
       "  'semantically',\n",
       "  'related',\n",
       "  'words',\n",
       "  'assigned',\n",
       "  'semantic',\n",
       "  'relationships',\n",
       "  'used',\n",
       "  'gener',\n",
       "  ''],\n",
       " ['',\n",
       "  'paper',\n",
       "  'argue',\n",
       "  'questionanswering',\n",
       "  'qa',\n",
       "  'technical',\n",
       "  'domains',\n",
       "  'distinctly',\n",
       "  'different',\n",
       "  'trec',\n",
       "  'based',\n",
       "  'qa',\n",
       "  'web',\n",
       "  'based',\n",
       "  'qa',\n",
       "  'cannot',\n",
       "  'benefit',\n",
       "  'lom',\n",
       "  'data',\n",
       "  'intensive',\n",
       "  'approaches',\n",
       "  ''],\n",
       " ['', 'universit', 'quot', 'des', 'saarlandes', ''],\n",
       " ['', 'proceedings', 'workshop', ''],\n",
       " ['', 'uni', 'hamburg', 'de', ''],\n",
       " ['', ''],\n",
       " ['', '2', '6', ''],\n",
       " ['',\n",
       "  'sri',\n",
       "  'developed',\n",
       "  'new',\n",
       "  'architecture',\n",
       "  'integrating',\n",
       "  'speech',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'applies',\n",
       "  'linguistic',\n",
       "  'constraints',\n",
       "  'recognition',\n",
       "  'incrementally',\n",
       "  'expanding',\n",
       "  'state',\n",
       "  'transition',\n",
       "  'network',\n",
       "  'embodied',\n",
       "  'unification',\n",
       "  'grammar',\n",
       "  'we',\n",
       "  'compare',\n",
       "  'dynamic',\n",
       "  'gralnlnar',\n",
       "  'network',\n",
       "  'dgn',\n",
       "  'approach',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'chapter',\n",
       "  'considers',\n",
       "  'revolution',\n",
       "  'taken',\n",
       "  'place',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'research',\n",
       "  'last',\n",
       "  'five',\n",
       "  'years',\n",
       "  'it',\n",
       "  'begins',\n",
       "  'providing',\n",
       "  'brief',\n",
       "  'guide',\n",
       "  'structure',\n",
       "  'field',\n",
       "  'presents',\n",
       "  'caricature',\n",
       "  'two',\n",
       "  'competing',\n",
       "  'paradigms',\n",
       "  '1980s',\n",
       "  'nlp',\n",
       "  'research',\n",
       "  'indicates',\n",
       "  'reasons',\n",
       "  'wh',\n",
       "  ''],\n",
       " ['',\n",
       "  'visual',\n",
       "  'development',\n",
       "  'environment',\n",
       "  'support',\n",
       "  'visual',\n",
       "  'assembly',\n",
       "  'execution',\n",
       "  'analysis',\n",
       "  'modular',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'the',\n",
       "  'visual',\n",
       "  'model',\n",
       "  'executable',\n",
       "  'data',\n",
       "  'flow',\n",
       "  'program',\n",
       "  'graph',\n",
       "  'automatically',\n",
       "  'synthesised',\n",
       "  'data',\n",
       "  'dependency',\n",
       "  'declarations',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'modules',\n",
       "  'the',\n",
       "  'graph',\n",
       "  'th',\n",
       "  ''],\n",
       " ['',\n",
       "  'in',\n",
       "  'chapter',\n",
       "  'basic',\n",
       "  'uses',\n",
       "  'description',\n",
       "  'logics',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'analysed',\n",
       "  'together',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'history',\n",
       "  'role',\n",
       "  'description',\n",
       "  'logics',\n",
       "  'current',\n",
       "  'state',\n",
       "  'art',\n",
       "  'computational',\n",
       "  'linguistics',\n",
       "  'pointed',\n",
       "  '18',\n",
       "  '1',\n",
       "  'introduction',\n",
       "  'since',\n",
       "  'early',\n",
       "  'days',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'applied',\n",
       "  'structure',\n",
       "  'learning',\n",
       "  'model',\n",
       "  'max',\n",
       "  'margin',\n",
       "  'structure',\n",
       "  'mms',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'tasks',\n",
       "  'aim',\n",
       "  'capture',\n",
       "  'latent',\n",
       "  'relationships',\n",
       "  'within',\n",
       "  'output',\n",
       "  'language',\n",
       "  'domain',\n",
       "  'we',\n",
       "  'formulate',\n",
       "  'model',\n",
       "  'extension',\n",
       "  'multi',\n",
       "  'class',\n",
       "  'support',\n",
       "  'vector',\n",
       "  'machine',\n",
       "  'svm',\n",
       "  'present',\n",
       "  'per',\n",
       "  ''],\n",
       " ['',\n",
       "  'vast',\n",
       "  'quantities',\n",
       "  'text',\n",
       "  'becoming',\n",
       "  'available',\n",
       "  'elec',\n",
       "  'tronic',\n",
       "  'form',\n",
       "  'ranging',\n",
       "  'published',\n",
       "  'documents',\n",
       "  'e',\n",
       "  'g',\n",
       "  'electronic',\n",
       "  'dictionaries',\n",
       "  'encyclopedias',\n",
       "  'libraries',\n",
       "  'archives',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'services',\n",
       "  'private',\n",
       "  'databases',\n",
       "  'e',\n",
       "  'g',\n",
       "  'marketing',\n",
       "  'information',\n",
       "  'legal',\n",
       "  'records',\n",
       "  'medical',\n",
       "  'histories',\n",
       "  'per',\n",
       "  ''],\n",
       " ['',\n",
       "  'over',\n",
       "  'last',\n",
       "  'years',\n",
       "  'number',\n",
       "  'areas',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'begun',\n",
       "  'applying',\n",
       "  'graph',\n",
       "  'based',\n",
       "  'techniques',\n",
       "  'these',\n",
       "  'include',\n",
       "  'among',\n",
       "  'others',\n",
       "  'text',\n",
       "  'summarization',\n",
       "  'syntactic',\n",
       "  'parsing',\n",
       "  'word',\n",
       "  'sense',\n",
       "  'disambiguation',\n",
       "  'ontology',\n",
       "  'construction',\n",
       "  'sentiment',\n",
       "  'subjectivity',\n",
       "  'analysis',\n",
       "  'text',\n",
       "  'clustering',\n",
       "  'in',\n",
       "  'pa',\n",
       "  ''],\n",
       " ['',\n",
       "  'in',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'research',\n",
       "  'results',\n",
       "  'software',\n",
       "  'engineering',\n",
       "  'software',\n",
       "  'technology',\n",
       "  'often',\n",
       "  'neglected',\n",
       "  ''],\n",
       " ['',\n",
       "  'kernelized',\n",
       "  'sorting',\n",
       "  'approach',\n",
       "  'matching',\n",
       "  'objects',\n",
       "  'two',\n",
       "  'sources',\n",
       "  'domains',\n",
       "  'require',\n",
       "  'prior',\n",
       "  'notion',\n",
       "  'similarity',\n",
       "  'objects',\n",
       "  'across',\n",
       "  'two',\n",
       "  'sources',\n",
       "  'unfortunately',\n",
       "  'technique',\n",
       "  'highly',\n",
       "  'sensitive',\n",
       "  'initialization',\n",
       "  'high',\n",
       "  'dimensional',\n",
       "  'data',\n",
       "  'we',\n",
       "  'present',\n",
       "  'variants',\n",
       "  'kern',\n",
       "  ''],\n",
       " ['',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'complex',\n",
       "  'compound',\n",
       "  'organization',\n",
       "  'structures',\n",
       "  'basic',\n",
       "  'linguistic',\n",
       "  'elements',\n",
       "  'represent',\n",
       "  'various',\n",
       "  'meanings',\n",
       "  'therefore',\n",
       "  'understand',\n",
       "  'nature',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'need',\n",
       "  'sophisticated',\n",
       "  'treatment',\n",
       "  'basic',\n",
       "  'elements',\n",
       "  'well',\n",
       "  'insights',\n",
       "  'elements',\n",
       "  ''],\n",
       " ['',\n",
       "  'in',\n",
       "  'paper',\n",
       "  'describe',\n",
       "  'framework',\n",
       "  'developing',\n",
       "  'probabilistic',\n",
       "  'classifiers',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'our',\n",
       "  'focus',\n",
       "  'formulating',\n",
       "  'models',\n",
       "  'capture',\n",
       "  'important',\n",
       "  'interdependencies',\n",
       "  'among',\n",
       "  'features',\n",
       "  'avoid',\n",
       "  'overfitting',\n",
       "  'data',\n",
       "  'also',\n",
       "  'characterizing',\n",
       "  'data',\n",
       "  'well',\n",
       "  'the',\n",
       "  'class',\n",
       "  'pro',\n",
       "  ''],\n",
       " ['',\n",
       "  'many',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'techniques',\n",
       "  'used',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'the',\n",
       "  'results',\n",
       "  'encouraging',\n",
       "  'simple',\n",
       "  'methods',\n",
       "  'stopwording',\n",
       "  'porter',\n",
       "  'style',\n",
       "  'stemming',\n",
       "  'etc',\n",
       "  'usually',\n",
       "  'yield',\n",
       "  'significant',\n",
       "  'improvements',\n",
       "  'higher',\n",
       "  'level',\n",
       "  'processing',\n",
       "  'chunking',\n",
       "  'parsing',\n",
       "  'word',\n",
       "  'sense',\n",
       "  'disambiguation',\n",
       "  'e',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'explains',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'using',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'malayalam',\n",
       "  'language',\n",
       "  'basic',\n",
       "  ''],\n",
       " ['',\n",
       "  'the',\n",
       "  'research',\n",
       "  'areas',\n",
       "  'plan',\n",
       "  'recognition',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'parsing',\n",
       "  'share',\n",
       "  'many',\n",
       "  'common',\n",
       "  'features',\n",
       "  'even',\n",
       "  'algorithms',\n",
       "  'however',\n",
       "  'dialog',\n",
       "  'two',\n",
       "  'disciplines',\n",
       "  'effective',\n",
       "  'specifically',\n",
       "  'significant',\n",
       "  'recent',\n",
       "  'results',\n",
       "  'parsing',\n",
       "  'mildly',\n",
       "  'context',\n",
       "  'sensitive',\n",
       "  'grammars',\n",
       "  'leveraged',\n",
       "  ''],\n",
       " ['',\n",
       "  'the',\n",
       "  'research',\n",
       "  'areas',\n",
       "  'plan',\n",
       "  'recognition',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'parsing',\n",
       "  'share',\n",
       "  'many',\n",
       "  'common',\n",
       "  'features',\n",
       "  'even',\n",
       "  'algorithms',\n",
       "  'however',\n",
       "  'dialog',\n",
       "  'two',\n",
       "  'disciplines',\n",
       "  'effective',\n",
       "  'specifically',\n",
       "  'significant',\n",
       "  'recent',\n",
       "  'results',\n",
       "  'parsing',\n",
       "  'mildly',\n",
       "  'context',\n",
       "  'sensitive',\n",
       "  'grammars',\n",
       "  'leveraged',\n",
       "  ''],\n",
       " ['',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'process',\n",
       "  'finding',\n",
       "  'documents',\n",
       "  'document',\n",
       "  'collection',\n",
       "  'satisfies',\n",
       "  'information',\n",
       "  'need',\n",
       "  'user',\n",
       "  'the',\n",
       "  'documents',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'constructs',\n",
       "  'motivation',\n",
       "  'work',\n",
       "  'investigate',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'used',\n",
       "  'improve',\n",
       "  'performa',\n",
       "  ''],\n",
       " ['',\n",
       "  'while',\n",
       "  'computational',\n",
       "  'logic',\n",
       "  'become',\n",
       "  'widely',\n",
       "  'used',\n",
       "  'representing',\n",
       "  'reasoning',\n",
       "  'linguistic',\n",
       "  'knowledge',\n",
       "  'cross',\n",
       "  'fertilization',\n",
       "  'logic',\n",
       "  'programming',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'given',\n",
       "  'rise',\n",
       "  'new',\n",
       "  'discipline',\n",
       "  'known',\n",
       "  'inductive',\n",
       "  'logic',\n",
       "  'programming',\n",
       "  'inspired',\n",
       "  'building',\n",
       "  'achievements',\n",
       "  ''],\n",
       " ['',\n",
       "  'what',\n",
       "  'statistical',\n",
       "  'method',\n",
       "  'used',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'in',\n",
       "  'paper',\n",
       "  'start',\n",
       "  'definition',\n",
       "  'nlp',\n",
       "  'concerned',\n",
       "  'design',\n",
       "  'implementation',\n",
       "  'effective',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'input',\n",
       "  'output',\n",
       "  'components',\n",
       "  'computational',\n",
       "  'systems',\n",
       "  'we',\n",
       "  'distinguish',\n",
       "  'three',\n",
       "  'kind',\n",
       "  ''],\n",
       " ['',\n",
       "  'in',\n",
       "  'report',\n",
       "  'collaborative',\n",
       "  'work',\n",
       "  'fields',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'ml',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'presented',\n",
       "  'the',\n",
       "  'document',\n",
       "  'structured',\n",
       "  'two',\n",
       "  'parts',\n",
       "  'the',\n",
       "  'first',\n",
       "  'part',\n",
       "  'includes',\n",
       "  'superficial',\n",
       "  'comprehensive',\n",
       "  'survey',\n",
       "  'covering',\n",
       "  'state',\n",
       "  'art',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'techniq',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'this',\n",
       "  'thesis',\n",
       "  'examines',\n",
       "  'use',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'techniques',\n",
       "  'various',\n",
       "  'tasks',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'mainly',\n",
       "  'task',\n",
       "  'information',\n",
       "  'extraction',\n",
       "  'texts',\n",
       "  'the',\n",
       "  'objectives',\n",
       "  'improvement',\n",
       "  'adaptability',\n",
       "  'information',\n",
       "  'extraction',\n",
       "  'systems',\n",
       "  'new',\n",
       "  'thematic',\n",
       "  'mains',\n",
       "  'even',\n",
       "  'lang',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'chapter',\n",
       "  'examines',\n",
       "  'application',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'computerassisted',\n",
       "  'language',\n",
       "  'learning',\n",
       "  'including',\n",
       "  'history',\n",
       "  'work',\n",
       "  'field',\n",
       "  'last',\n",
       "  'thirtyfive',\n",
       "  'years',\n",
       "  'focus',\n",
       "  'current',\n",
       "  'developments',\n",
       "  'opportunities',\n",
       "  '36',\n",
       "  '1',\n",
       "  ''],\n",
       " ['',\n",
       "  'traditional',\n",
       "  'approaches',\n",
       "  'tointerpretation',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'typically',\n",
       "  'fall',\n",
       "  'one',\n",
       "  'three',\n",
       "  'classes',\n",
       "  'syntax',\n",
       "  'driven',\n",
       "  'semantics',\n",
       "  'driven',\n",
       "  'frame',\n",
       "  'task',\n",
       "  'based',\n",
       "  'syntax',\n",
       "  'driven',\n",
       "  'approaches',\n",
       "  'use',\n",
       "  'domain',\n",
       "  'independent',\n",
       "  'grammar',\n",
       "  'drive',\n",
       "  'interpretation',\n",
       "  'process',\n",
       "  'produce',\n",
       "  'global',\n",
       "  'parse',\n",
       "  'input',\n",
       "  ''],\n",
       " ['',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'large',\n",
       "  'diverse',\n",
       "  'subtopic',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'as',\n",
       "  'result',\n",
       "  'nlp',\n",
       "  'many',\n",
       "  'subtopics',\n",
       "  'including',\n",
       "  'optical',\n",
       "  'character',\n",
       "  'recognition',\n",
       "  'text',\n",
       "  'speech',\n",
       "  'translators',\n",
       "  'foreign',\n",
       "  'language',\n",
       "  'reading',\n",
       "  'writing',\n",
       "  'aids',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  'speech',\n",
       "  'recognition',\n",
       "  'w',\n",
       "  ''],\n",
       " ['',\n",
       "  'probabilistic',\n",
       "  'finite',\n",
       "  'state',\n",
       "  'string',\n",
       "  'transducers',\n",
       "  'fsts',\n",
       "  'extremely',\n",
       "  'popular',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'due',\n",
       "  'powerful',\n",
       "  'generic',\n",
       "  'methods',\n",
       "  'applying',\n",
       "  'composing',\n",
       "  'learning',\n",
       "  'unfortunately',\n",
       "  'fsts',\n",
       "  'good',\n",
       "  'fit',\n",
       "  'much',\n",
       "  'current',\n",
       "  'work',\n",
       "  'probabilistic',\n",
       "  'modeling',\n",
       "  'machine',\n",
       "  'translati',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'in',\n",
       "  'special',\n",
       "  'issue',\n",
       "  'tal',\n",
       "  'look',\n",
       "  'fundamental',\n",
       "  'principles',\n",
       "  'underlying',\n",
       "  'evaluation',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'we',\n",
       "  'adopt',\n",
       "  'global',\n",
       "  'point',\n",
       "  'view',\n",
       "  'goes',\n",
       "  'beyond',\n",
       "  'horizon',\n",
       "  'single',\n",
       "  'evaluation',\n",
       "  'campaign',\n",
       "  'particular',\n",
       "  'protocol',\n",
       "  'after',\n",
       "  'brief',\n",
       "  'review',\n",
       "  'history',\n",
       "  'terminology',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'nlp',\n",
       "  'extract',\n",
       "  'clinical',\n",
       "  'information',\n",
       "  'textual',\n",
       "  'reports',\n",
       "  'shown',\n",
       "  'effective',\n",
       "  'limited',\n",
       "  'domains',\n",
       "  'particular',\n",
       "  'applications',\n",
       "  'because',\n",
       "  'nlp',\n",
       "  'system',\n",
       "  'typically',\n",
       "  'requires',\n",
       "  'substantial',\n",
       "  'resources',\n",
       "  'develop',\n",
       "  'beneficial',\n",
       "  'designed',\n",
       "  'easily',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'propose',\n",
       "  'bifurcated',\n",
       "  'paradigm',\n",
       "  'construction',\n",
       "  'prolog',\n",
       "  'knowl',\n",
       "  'edge',\n",
       "  'base',\n",
       "  'body',\n",
       "  'documents',\n",
       "  'first',\n",
       "  'information',\n",
       "  'extraction',\n",
       "  'ie',\n",
       "  'ap',\n",
       "  'plication',\n",
       "  'annotate',\n",
       "  'corpus',\n",
       "  'output',\n",
       "  'annotated',\n",
       "  'documents',\n",
       "  'second',\n",
       "  'prolog',\n",
       "  'knowledge',\n",
       "  'base',\n",
       "  'kb',\n",
       "  'application',\n",
       "  'transform',\n",
       "  'th',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'describe',\n",
       "  'single',\n",
       "  'convolutional',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'architecture',\n",
       "  'given',\n",
       "  'sentence',\n",
       "  'outputs',\n",
       "  'host',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'predictions',\n",
       "  'part',\n",
       "  'speech',\n",
       "  'tags',\n",
       "  'chunks',\n",
       "  'named',\n",
       "  'entity',\n",
       "  'tags',\n",
       "  'semantic',\n",
       "  'roles',\n",
       "  'semantically',\n",
       "  'similar',\n",
       "  'words',\n",
       "  'likelihood',\n",
       "  'sentence',\n",
       "  'makes',\n",
       "  'sense',\n",
       "  'grammatically',\n",
       "  'sem',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'developed',\n",
       "  'prototype',\n",
       "  'information',\n",
       "  'retrieval',\n",
       "  'system',\n",
       "  'uses',\n",
       "  'advanced',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'techniques',\n",
       "  'enhance',\n",
       "  'effectiveness',\n",
       "  'traditional',\n",
       "  'key',\n",
       "  'word',\n",
       "  'based',\n",
       "  'document',\n",
       "  'retrieval',\n",
       "  'the',\n",
       "  'backbone',\n",
       "  'system',\n",
       "  'statistical',\n",
       "  'retrieval',\n",
       "  'engine',\n",
       "  'performs',\n",
       "  'automated',\n",
       "  'indexing',\n",
       "  'docum',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'in',\n",
       "  'paper',\n",
       "  'discuss',\n",
       "  'several',\n",
       "  'issues',\n",
       "  'requirements',\n",
       "  'enabling',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'become',\n",
       "  'context',\n",
       "  'adaptive',\n",
       "  'given',\n",
       "  'fact',\n",
       "  'emerging',\n",
       "  'systems',\n",
       "  'feature',\n",
       "  'speaker',\n",
       "  'independent',\n",
       "  'continuous',\n",
       "  'speech',\n",
       "  'recognition',\n",
       "  'restricted',\n",
       "  'individual',\n",
       "  'domains',\n",
       "  'equipped',\n",
       "  'syntactic',\n",
       "  ''],\n",
       " ['',\n",
       "  'in',\n",
       "  'fall',\n",
       "  '2004',\n",
       "  'i',\n",
       "  'introduced',\n",
       "  'new',\n",
       "  'course',\n",
       "  'called',\n",
       "  'applied',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'students',\n",
       "  'acquire',\n",
       "  'understanding',\n",
       "  'text',\n",
       "  'analysis',\n",
       "  'techniques',\n",
       "  'currently',\n",
       "  'feasible',\n",
       "  'practical',\n",
       "  'applications',\n",
       "  ''],\n",
       " ['', ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'study',\n",
       "  'mathematical',\n",
       "  'computational',\n",
       "  'modelling',\n",
       "  'various',\n",
       "  'aspects',\n",
       "  'language',\n",
       "  'improvement',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'systems',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'language',\n",
       "  'arises',\n",
       "  'innate',\n",
       "  'facility',\n",
       "  'language',\n",
       "  'possessed',\n",
       "  'human',\n",
       "  'intellect',\n",
       "  'may',\n",
       "  ''],\n",
       " ['',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'branch',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'includes',\n",
       "  'speech',\n",
       "  'synthesis',\n",
       "  'speech',\n",
       "  'recognition',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'wide',\n",
       "  'range',\n",
       "  'applications',\n",
       "  'indian',\n",
       "  'context',\n",
       "  'most',\n",
       "  'rural',\n",
       "  'indian',\n",
       "  'community',\n",
       "  'unable',\n",
       "  'make',\n",
       "  'use',\n",
       "  'th',\n",
       "  ''],\n",
       " ['',\n",
       "  'an',\n",
       "  'evaluation',\n",
       "  'lolita',\n",
       "  'related',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'systems',\n",
       "  'paul',\n",
       "  'callaghan',\n",
       "  'submitted',\n",
       "  'university',\n",
       "  'durham',\n",
       "  'degree',\n",
       "  'ph',\n",
       "  'd',\n",
       "  'august',\n",
       "  '1997',\n",
       "  'this',\n",
       "  'research',\n",
       "  'addresses',\n",
       "  'question',\n",
       "  'evaluate',\n",
       "  'systems',\n",
       "  'like',\n",
       "  'lolita',\n",
       "  'lolita',\n",
       "  'natural',\n",
       "  ''],\n",
       " ['',\n",
       "  'previous',\n",
       "  'work',\n",
       "  'demonstrated',\n",
       "  'web',\n",
       "  'counts',\n",
       "  'used',\n",
       "  'approximate',\n",
       "  'bigram',\n",
       "  'counts',\n",
       "  'suggesting',\n",
       "  'web',\n",
       "  'based',\n",
       "  'frequencies',\n",
       "  'useful',\n",
       "  'wide',\n",
       "  'variety',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'tasks',\n",
       "  'however',\n",
       "  'limited',\n",
       "  'number',\n",
       "  'tasks',\n",
       "  'far',\n",
       "  'tested',\n",
       "  'using',\n",
       "  'web',\n",
       "  'scale',\n",
       "  'data',\n",
       "  'sets',\n",
       "  'the',\n",
       "  'pr',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'chapter',\n",
       "  'examines',\n",
       "  'application',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'computerassisted',\n",
       "  'language',\n",
       "  'learning',\n",
       "  'including',\n",
       "  'history',\n",
       "  'work',\n",
       "  'field',\n",
       "  'last',\n",
       "  'thirtyfive',\n",
       "  'years',\n",
       "  'focus',\n",
       "  'current',\n",
       "  'developments',\n",
       "  'opportunities',\n",
       "  '16',\n",
       "  '1',\n",
       "  'introduction',\n",
       "  'this',\n",
       "  'chapter',\n",
       "  'focuses',\n",
       "  'applications',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'describes',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'system',\n",
       "  'improves',\n",
       "  'performance',\n",
       "  'learning',\n",
       "  'the',\n",
       "  'system',\n",
       "  'processes',\n",
       "  'short',\n",
       "  'english',\n",
       "  'narratives',\n",
       "  'able',\n",
       "  'acquire',\n",
       "  'single',\n",
       "  'narrative',\n",
       "  'new',\n",
       "  'schema',\n",
       "  'stereotypical',\n",
       "  'set',\n",
       "  'actions',\n",
       "  'during',\n",
       "  'understanding',\n",
       "  'process',\n",
       "  'system',\n",
       "  'attempts',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'classify',\n",
       "  'review',\n",
       "  'current',\n",
       "  'approaches',\n",
       "  'software',\n",
       "  'infrastructure',\n",
       "  'research',\n",
       "  'development',\n",
       "  'delivery',\n",
       "  'nlp',\n",
       "  'systems',\n",
       "  'the',\n",
       "  'task',\n",
       "  ''],\n",
       " ['',\n",
       "  'confidence',\n",
       "  'measures',\n",
       "  'practical',\n",
       "  'solution',\n",
       "  'improving',\n",
       "  'usefulness',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'applications',\n",
       "  'confidence',\n",
       "  'estimation',\n",
       "  'generic',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'approach',\n",
       "  'deriving',\n",
       "  'confidence',\n",
       "  'measures',\n",
       "  'we',\n",
       "  'give',\n",
       "  'overview',\n",
       "  'application',\n",
       "  'confidence',\n",
       "  'estimation',\n",
       "  'various',\n",
       "  'fields',\n",
       "  'n',\n",
       "  ''],\n",
       " ['',\n",
       "  'lex',\n",
       "  'sign',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'dictionary',\n",
       "  'ldoce',\n",
       "  'lex',\n",
       "  'sign',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'ldb',\n",
       "  'entry',\n",
       "  '12364',\n",
       "  'lex',\n",
       "  'sign',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'sense',\n",
       "  'id',\n",
       "  'sense',\n",
       "  '0',\n",
       "  'when',\n",
       "  'loaded',\n",
       "  'lkb',\n",
       "  '9',\n",
       "  'expanded',\n",
       "  'fully',\n",
       "  'fledged',\n",
       "  'representation',\n",
       "  'transitive',\n",
       "  'use',\n",
       "  'e',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'describe',\n",
       "  'design',\n",
       "  'use',\n",
       "  'stanford',\n",
       "  'corenlp',\n",
       "  'toolkit',\n",
       "  'extensible',\n",
       "  'pipeline',\n",
       "  'provides',\n",
       "  'core',\n",
       "  'natural',\n",
       "  'lan',\n",
       "  'guage',\n",
       "  'analysis',\n",
       "  'this',\n",
       "  'toolkit',\n",
       "  'quite',\n",
       "  'widely',\n",
       "  'used',\n",
       "  'research',\n",
       "  'nlp',\n",
       "  'community',\n",
       "  'also',\n",
       "  'among',\n",
       "  'commercial',\n",
       "  'govern',\n",
       "  'ment',\n",
       "  'users',\n",
       "  'open',\n",
       "  'source',\n",
       "  'nlp',\n",
       "  'technol',\n",
       "  'ogy',\n",
       "  'we',\n",
       "  'suggest',\n",
       "  ''],\n",
       " ['',\n",
       "  'gaussian',\n",
       "  'processes',\n",
       "  'gps',\n",
       "  'powerful',\n",
       "  'mod',\n",
       "  'elling',\n",
       "  'framework',\n",
       "  'incorporating',\n",
       "  'kernels',\n",
       "  'bayesian',\n",
       "  'inference',\n",
       "  'recognised',\n",
       "  'state',\n",
       "  'art',\n",
       "  'many',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'tasks',\n",
       "  ''],\n",
       " ['',\n",
       "  'a',\n",
       "  'fundamental',\n",
       "  'issue',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'prerequisite',\n",
       "  'enormous',\n",
       "  'quantity',\n",
       "  'preprogrammed',\n",
       "  'knowledge',\n",
       "  'concerning',\n",
       "  'language',\n",
       "  'domain',\n",
       "  'examination',\n",
       "  'manual',\n",
       "  'acquisition',\n",
       "  'knowledge',\n",
       "  'tedious',\n",
       "  'error',\n",
       "  'prone',\n",
       "  'development',\n",
       "  'automated',\n",
       "  'acquisition',\n",
       "  'process',\n",
       "  ''],\n",
       " ['',\n",
       "  'a',\n",
       "  'general',\n",
       "  'reusable',\n",
       "  'computational',\n",
       "  'resource',\n",
       "  'de',\n",
       "  'veloped',\n",
       "  'within',\n",
       "  'penman',\n",
       "  'text',\n",
       "  'generation',\n",
       "  'project',\n",
       "  'organizing',\n",
       "  'domain',\n",
       "  'knowledge',\n",
       "  'appropriately',\n",
       "  'linguistic',\n",
       "  'realization',\n",
       "  'this',\n",
       "  'resource',\n",
       "  'called',\n",
       "  'upper',\n",
       "  'model',\n",
       "  'provides',\n",
       "  'domain',\n",
       "  'task',\n",
       "  'independent',\n",
       "  'classification',\n",
       "  'system',\n",
       "  'supports',\n",
       "  ''],\n",
       " ['',\n",
       "  'kohonen',\n",
       "  'self',\n",
       "  'organizing',\n",
       "  'map',\n",
       "  'som',\n",
       "  'one',\n",
       "  'popular',\n",
       "  'artificial',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'algorithms',\n",
       "  'word',\n",
       "  'category',\n",
       "  'maps',\n",
       "  'soms',\n",
       "  'organized',\n",
       "  'according',\n",
       "  'word',\n",
       "  'similarities',\n",
       "  'measured',\n",
       "  'similarity',\n",
       "  'short',\n",
       "  'contexts',\n",
       "  'words',\n",
       "  'conceptually',\n",
       "  'interrelated',\n",
       "  'words',\n",
       "  'tend',\n",
       "  'fall',\n",
       "  ''],\n",
       " ['',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'presents',\n",
       "  'workbench',\n",
       "  'built',\n",
       "  'priberam',\n",
       "  'informática',\n",
       "  'development',\n",
       "  'company',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'technology',\n",
       "  'this',\n",
       "  'workbench',\n",
       "  'includes',\n",
       "  'set',\n",
       "  'linguistic',\n",
       "  'resources',\n",
       "  'software',\n",
       "  'tools',\n",
       "  'applied',\n",
       "  'considerable',\n",
       "  'number',\n",
       "  'practical',\n",
       "  'purposes',\n",
       "  'covering',\n",
       "  'proofing',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'effective',\n",
       "  'approach',\n",
       "  'bringing',\n",
       "  'improvement',\n",
       "  'educational',\n",
       "  'setting',\n",
       "  'implementing',\n",
       "  'nlp',\n",
       "  'involves',\n",
       "  'initiating',\n",
       "  'process',\n",
       "  'learning',\n",
       "  'natural',\n",
       "  'acquisition',\n",
       "  'educational',\n",
       "  'systems',\n",
       "  'it',\n",
       "  'based',\n",
       "  'effective',\n",
       "  'approaches',\n",
       "  'providing',\n",
       "  'solution',\n",
       "  'f',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'after',\n",
       "  'twenty',\n",
       "  'years',\n",
       "  'disfavor',\n",
       "  'technology',\n",
       "  'returned',\n",
       "  'imitates',\n",
       "  'processes',\n",
       "  'brain',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'experiments',\n",
       "  'sejnowski',\n",
       "  'rosenberg',\n",
       "  '1986',\n",
       "  'demonstrate',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'computing',\n",
       "  'architecture',\n",
       "  'learn',\n",
       "  'actual',\n",
       "  'spoken',\n",
       "  'language',\n",
       "  'observe',\n",
       "  'rules',\n",
       "  'pronunciation',\n",
       "  ''],\n",
       " ['',\n",
       "  'text',\n",
       "  'statistics',\n",
       "  'frequently',\n",
       "  'used',\n",
       "  'stylometry',\n",
       "  'cryptography',\n",
       "  'studies',\n",
       "  'in',\n",
       "  'paper',\n",
       "  'text',\n",
       "  'statistics',\n",
       "  'tools',\n",
       "  'developed',\n",
       "  'iso',\n",
       "  'prolog',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'details',\n",
       "  'given',\n",
       "  'usage',\n",
       "  '21',\n",
       "  'user',\n",
       "  'callable',\n",
       "  'predicates',\n",
       "  'logic',\n",
       "  'limitations',\n",
       "  'program',\n",
       "  'also',\n",
       "  'discussed',\n",
       "  '1',\n",
       "  ''],\n",
       " ['',\n",
       "  'we',\n",
       "  'summarize',\n",
       "  'experience',\n",
       "  'using',\n",
       "  'framenet',\n",
       "  'two',\n",
       "  'rather',\n",
       "  'different',\n",
       "  'projects',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'we',\n",
       "  'conclude',\n",
       "  'nlp',\n",
       "  'benefit',\n",
       "  'framenet',\n",
       "  'different',\n",
       "  'ways',\n",
       "  'sketch',\n",
       "  'problems',\n",
       "  'need',\n",
       "  'overcome',\n",
       "  '1',\n",
       "  ''],\n",
       " ['',\n",
       "  'research',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'benefited',\n",
       "  'enormous',\n",
       "  'amount',\n",
       "  'raw',\n",
       "  'textual',\n",
       "  'data',\n",
       "  'available',\n",
       "  'world',\n",
       "  'wide',\n",
       "  'web',\n",
       "  'the',\n",
       "  'presence',\n",
       "  'standard',\n",
       "  'search',\n",
       "  'engines',\n",
       "  'made',\n",
       "  'data',\n",
       "  'accessible',\n",
       "  'computational',\n",
       "  'linguists',\n",
       "  'corpus',\n",
       "  'size',\n",
       "  'never',\n",
       "  'existed',\n",
       "  'befo',\n",
       "  ''],\n",
       " ['',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'programs',\n",
       "  'confronted',\n",
       "  'various',\n",
       "  'di',\n",
       "  'culties',\n",
       "  'processing',\n",
       "  'html',\n",
       "  'xml',\n",
       "  'documents',\n",
       "  'potential',\n",
       "  'produce',\n",
       "  'better',\n",
       "  'results',\n",
       "  'linguistic',\n",
       "  'information',\n",
       "  'annotated',\n",
       "  'source',\n",
       "  'texts',\n",
       "  'wehave',\n",
       "  'therefore',\n",
       "  'developed',\n",
       "  'linguistic',\n",
       "  'annotation',\n",
       "  'language',\n",
       "  'lal',\n",
       "  ''],\n",
       " ['',\n",
       "  'introduction',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'appears',\n",
       "  'surface',\n",
       "  'strongly',\n",
       "  'symbolic',\n",
       "  'activity',\n",
       "  'words',\n",
       "  'symbols',\n",
       "  'stand',\n",
       "  'objects',\n",
       "  'concepts',\n",
       "  'real',\n",
       "  'world',\n",
       "  'put',\n",
       "  'together',\n",
       "  'sentences',\n",
       "  'obey',\n",
       "  'well',\n",
       "  'specified',\n",
       "  'grammar',\n",
       "  'rules',\n",
       "  'it',\n",
       "  'surprise',\n",
       "  'several',\n",
       "  'decades',\n",
       "  'na',\n",
       "  ''],\n",
       " ['',\n",
       "  'abstract',\n",
       "  'diff',\n",
       "  'software',\n",
       "  'program',\n",
       "  'detects',\n",
       "  'differences',\n",
       "  'two',\n",
       "  'data',\n",
       "  'sets',\n",
       "  'useful',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'shows',\n",
       "  'several',\n",
       "  'examples',\n",
       "  'application',\n",
       "  'diff',\n",
       "  'they',\n",
       "  'include',\n",
       "  'detection',\n",
       "  'differences',\n",
       "  'two',\n",
       "  'different',\n",
       "  'datasets',\n",
       "  'extraction',\n",
       "  'rewriting',\n",
       "  'rules',\n",
       "  'mer',\n",
       "  ''],\n",
       " ['',\n",
       "  'in',\n",
       "  'paper',\n",
       "  'present',\n",
       "  'compare',\n",
       "  'automatically',\n",
       "  'generated',\n",
       "  'titles',\n",
       "  'machine',\n",
       "  'translated',\n",
       "  'documents',\n",
       "  'using',\n",
       "  'several',\n",
       "  'different',\n",
       "  'statistics',\n",
       "  'based',\n",
       "  'methods',\n",
       "  'a',\n",
       "  'naïve',\n",
       "  'bayesian',\n",
       "  'k',\n",
       "  'nearest',\n",
       "  'neighbour',\n",
       "  'tf',\n",
       "  'idf',\n",
       "  'erative',\n",
       "  'expectation',\n",
       "  'maximization',\n",
       "  'method',\n",
       "  'title',\n",
       "  'gen',\n",
       "  'eration',\n",
       "  'applied',\n",
       "  '1000',\n",
       "  'origi',\n",
       "  ''],\n",
       " ['', '9', 'bibliography', ''],\n",
       " ['',\n",
       "  'applying',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'techniques',\n",
       "  'biomedical',\n",
       "  'text',\n",
       "  'potential',\n",
       "  'aid',\n",
       "  'curation',\n",
       "  'become',\n",
       "  'focus',\n",
       "  'intensive',\n",
       "  'research',\n",
       "  'however',\n",
       "  'developing',\n",
       "  'integrated',\n",
       "  'systems',\n",
       "  'address',\n",
       "  'curators',\n",
       "  'real',\n",
       "  'world',\n",
       "  'needs',\n",
       "  'studied',\n",
       "  'less',\n",
       "  'rigorously',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'addresses',\n",
       "  'question',\n",
       "  ''],\n",
       " ['',\n",
       "  'examples',\n",
       "  'natural',\n",
       "  'languages',\n",
       "  'chinese',\n",
       "  'english',\n",
       "  'italian',\n",
       "  'they',\n",
       "  'called',\n",
       "  'natural',\n",
       "  'evolved',\n",
       "  'less',\n",
       "  'natural',\n",
       "  'way',\n",
       "  'without',\n",
       "  'many',\n",
       "  'deliberate',\n",
       "  'considerations',\n",
       "  'this',\n",
       "  'sets',\n",
       "  'apart',\n",
       "  'formal',\n",
       "  'languages',\n",
       "  'amongst',\n",
       "  'programming',\n",
       "  'languages',\n",
       "  'designed',\n",
       "  ''],\n",
       " ['',\n",
       "  'a',\n",
       "  'number',\n",
       "  'powerful',\n",
       "  'modelling',\n",
       "  'techniques',\n",
       "  'developed',\n",
       "  'recent',\n",
       "  'years',\n",
       "  'compress',\n",
       "  'natural',\n",
       "  'language',\n",
       "  'text',\n",
       "  'the',\n",
       "  'best',\n",
       "  'adaptive',\n",
       "  'models',\n",
       "  'operating',\n",
       "  'character',\n",
       "  'word',\n",
       "  'level',\n",
       "  'able',\n",
       "  'perform',\n",
       "  'almost',\n",
       "  'well',\n",
       "  'humans',\n",
       "  'predicting',\n",
       "  'text',\n",
       "  'we',\n",
       "  'show',\n",
       "  'apply',\n",
       "  'character',\n",
       "  'based',\n",
       "  ''],\n",
       " ['',\n",
       "  'a',\n",
       "  'semi',\n",
       "  'automated',\n",
       "  'approach',\n",
       "  'design',\n",
       "  'databases',\n",
       "  'enhanced',\n",
       "  'erd',\n",
       "  'notation',\n",
       "  'presented',\n",
       "  'it',\n",
       "  'focuses',\n",
       "  'early',\n",
       "  'stage',\n",
       "  'database',\n",
       "  'development',\n",
       "  'stage',\n",
       "  'user',\n",
       "  'requirement',\n",
       "  'analysis',\n",
       "  'it',\n",
       "  'supposed',\n",
       "  'used',\n",
       "  'requirements',\n",
       "  'determination',\n",
       "  'stage',\n",
       "  'analysis',\n",
       "  'the',\n",
       "  'approa',\n",
       "  '']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=[]\n",
    "q1=[]\n",
    "for i in f1:\n",
    "  q=[]\n",
    "  for j in i:\n",
    "    q.append(j.lower())\n",
    "  q1.append(q)\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  :  \n",
      "introduction  :  introduct\n",
      "statistical  :  statist\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "snlp  :  snlp\n",
      "field  :  field\n",
      "lying  :  lie\n",
      "intersection  :  intersect\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "snlp  :  snlp\n",
      "di  :  di\n",
      "ers  :  er\n",
      "traditional  :  tradit\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "instead  :  instead\n",
      "linguist  :  linguist\n",
      "manually  :  manual\n",
      "construct  :  construct\n",
      "model  :  model\n",
      "given  :  given\n",
      "linguistic  :  linguist\n",
      "  :  \n",
      "  :  \n",
      "the  :  the\n",
      "paper  :  paper\n",
      "summarizes  :  summar\n",
      "essential  :  essenti\n",
      "properties  :  properti\n",
      "document  :  document\n",
      "retrieval  :  retriev\n",
      "reviews  :  review\n",
      "conventional  :  convent\n",
      "practice  :  practic\n",
      "research  :  research\n",
      "findings  :  find\n",
      "latter  :  latter\n",
      "suggesting  :  suggest\n",
      "simple  :  simpl\n",
      "statistical  :  statist\n",
      "techniques  :  techniqu\n",
      "effective  :  effect\n",
      "it  :  it\n",
      "considers  :  consid\n",
      "new  :  new\n",
      "opportunities  :  opportun\n",
      "challenges  :  challeng\n",
      "presented  :  present\n",
      "ability  :  abil\n",
      "search  :  search\n",
      "full  :  full\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "language  :  languag\n",
      "way  :  way\n",
      "communicating  :  commun\n",
      "words  :  word\n",
      "language  :  languag\n",
      "helps  :  help\n",
      "understanding  :  understand\n",
      "world  :  world\n",
      "get  :  get\n",
      "better  :  better\n",
      "insight  :  insight\n",
      "world  :  world\n",
      "language  :  languag\n",
      "helps  :  help\n",
      "speakers  :  speaker\n",
      "vague  :  vagu\n",
      "precise  :  precis\n",
      "like  :  like\n",
      "nlp  :  nlp\n",
      "stands  :  stand\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "natural  :  natur\n",
      "languages  :  languag\n",
      "languages  :  languag\n",
      "spoken  :  spoken\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "report  :  report\n",
      "experiments  :  experi\n",
      "use  :  use\n",
      "standard  :  standard\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "tools  :  tool\n",
      "analysis  :  analysi\n",
      "music  :  music\n",
      "lyrics  :  lyric\n",
      "a  :  a\n",
      "significant  :  signific\n",
      "amount  :  amount\n",
      "music  :  music\n",
      "audio  :  audio\n",
      "lyrics  :  lyric\n",
      "lyrics  :  lyric\n",
      "encode  :  encod\n",
      "important  :  import\n",
      "part  :  part\n",
      "semantics  :  semant\n",
      "song  :  song\n",
      "therefore  :  therefor\n",
      "analysis  :  analysi\n",
      "complements  :  complement\n",
      "acoustic  :  acoust\n",
      "cultural  :  cultur\n",
      "metada  :  metada\n",
      "  :  \n",
      "  :  \n",
      "paper  :  paper\n",
      "describe  :  describ\n",
      "simple  :  simpl\n",
      "rule  :  rule\n",
      "based  :  base\n",
      "approach  :  approach\n",
      "automated  :  autom\n",
      "learning  :  learn\n",
      "linguistic  :  linguist\n",
      "knowledge  :  knowledg\n",
      "this  :  thi\n",
      "approach  :  approach\n",
      "shown  :  shown\n",
      "number  :  number\n",
      "tasks  :  task\n",
      "capture  :  captur\n",
      "information  :  inform\n",
      "clearer  :  clearer\n",
      "direct  :  direct\n",
      "fashion  :  fashion\n",
      "without  :  without\n",
      "compromise  :  compromis\n",
      "performance  :  perform\n",
      "we  :  we\n",
      "present  :  present\n",
      "detailed  :  detail\n",
      "case  :  case\n",
      "study  :  studi\n",
      "learni  :  learni\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "paper  :  paper\n",
      "focuses  :  focus\n",
      "connectionist  :  connectionist\n",
      "models  :  model\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "we  :  we\n",
      "briefly  :  briefli\n",
      "present  :  present\n",
      "discuss  :  discuss\n",
      "several  :  sever\n",
      "aspects  :  aspect\n",
      "high  :  high\n",
      "level  :  level\n",
      "tasks  :  task\n",
      "recently  :  recent\n",
      "approached  :  approach\n",
      "connectionism  :  connection\n",
      "either  :  either\n",
      "localist  :  localist\n",
      "parallel  :  parallel\n",
      "distributed  :  distribut\n",
      "processing  :  process\n",
      "models  :  model\n",
      "several  :  sever\n",
      "interesting  :  interest\n",
      "architectures  :  architectur\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "the  :  the\n",
      "article  :  articl\n",
      "explores  :  explor\n",
      "possibility  :  possibl\n",
      "construct  :  construct\n",
      "unified  :  unifi\n",
      "word  :  word\n",
      "feature  :  featur\n",
      "component  :  compon\n",
      "features  :  featur\n",
      "letters  :  letter\n",
      "each  :  each\n",
      "letter  :  letter\n",
      "modeled  :  model\n",
      "different  :  differ\n",
      "attractor  :  attractor\n",
      "finally  :  final\n",
      "embedded  :  embed\n",
      "quadratic  :  quadrat\n",
      "iterated  :  iter\n",
      "map  :  map\n",
      "the  :  the\n",
      "result  :  result\n",
      "word  :  word\n",
      "feature  :  featur\n",
      "account  :  account\n",
      "meaning  :  mean\n",
      "extraction  :  extract\n",
      "pr  :  pr\n",
      "  :  \n",
      "  :  \n",
      "paper  :  paper\n",
      "see  :  see\n",
      "schank  :  schank\n",
      "86  :  86\n",
      "theoretical  :  theoret\n",
      "discussion  :  discuss\n",
      "kass  :  kass\n",
      "86  :  86\n",
      "leake  :  leak\n",
      "owens  :  owen\n",
      "86  :  86\n",
      "brief  :  brief\n",
      "discussions  :  discuss\n",
      "program  :  program\n",
      "built  :  built\n",
      "around  :  around\n",
      "principles  :  principl\n",
      "goal  :  goal\n",
      "simply  :  simpli\n",
      "point  :  point\n",
      "interest  :  interest\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "led  :  led\n",
      "us  :  us\n",
      "naturally  :  natur\n",
      "indeed  :  inde\n",
      "inevitably  :  inevit\n",
      "de  :  de\n",
      "  :  \n",
      "  :  \n",
      "objectives  :  object\n",
      "to  :  to\n",
      "provide  :  provid\n",
      "overview  :  overview\n",
      "tutorial  :  tutori\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "modern  :  modern\n",
      "nlp  :  nlp\n",
      "system  :  system\n",
      "design  :  design\n",
      "target  :  target\n",
      "audience  :  audienc\n",
      "this  :  thi\n",
      "tutorial  :  tutori\n",
      "targets  :  target\n",
      "medical  :  medic\n",
      "informatics  :  informat\n",
      "generalist  :  generalist\n",
      "limited  :  limit\n",
      "acquaintance  :  acquaint\n",
      "principles  :  principl\n",
      "behind  :  behind\n",
      "nlp  :  nlp\n",
      "limited  :  limit\n",
      "knowledge  :  knowledg\n",
      "current  :  current\n",
      "state  :  state\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "paper  :  paper\n",
      "briefly  :  briefli\n",
      "describes  :  describ\n",
      "current  :  current\n",
      "implementation  :  implement\n",
      "status  :  statu\n",
      "intelligent  :  intellig\n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "system  :  system\n",
      "marie  :  mari\n",
      "employs  :  employ\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "techniques  :  techniqu\n",
      "descriptive  :  descript\n",
      "captions  :  caption\n",
      "used  :  use\n",
      "iden  :  iden\n",
      "tify  :  tifi\n",
      "photographic  :  photograph\n",
      "images  :  imag\n",
      "concerning  :  concern\n",
      "various  :  variou\n",
      "military  :  militari\n",
      "projects  :  project\n",
      "the  :  the\n",
      "captions  :  caption\n",
      "parsed  :  pars\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "metabolism  :  metabol\n",
      "machinery  :  machineri\n",
      "life  :  life\n",
      "signal  :  signal\n",
      "transduction  :  transduct\n",
      "provides  :  provid\n",
      "regulatory  :  regulatori\n",
      "mechanisms  :  mechan\n",
      "control  :  control\n",
      "machinery  :  machineri\n",
      "due  :  due\n",
      "complexity  :  complex\n",
      "signal  :  signal\n",
      "transduction  :  transduct\n",
      "pathways  :  pathway\n",
      "computational  :  comput\n",
      "approaches  :  approach\n",
      "needed  :  need\n",
      "aid  :  aid\n",
      "biologist  :  biologist\n",
      "integrating  :  integr\n",
      "available  :  avail\n",
      "knowledge  :  knowledg\n",
      "formulatio  :  formulatio\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "report  :  report\n",
      "presents  :  present\n",
      "detailed  :  detail\n",
      "analysis  :  analysi\n",
      "review  :  review\n",
      "nlp  :  nlp\n",
      "evaluation  :  evalu\n",
      "principle  :  principl\n",
      "practice  :  practic\n",
      "part  :  part\n",
      "1  :  1\n",
      "examines  :  examin\n",
      "evaluation  :  evalu\n",
      "concepts  :  concept\n",
      "establishes  :  establish\n",
      "framework  :  framework\n",
      "nlp  :  nlp\n",
      "system  :  system\n",
      "evaluation  :  evalu\n",
      "this  :  thi\n",
      "makes  :  make\n",
      "use  :  use\n",
      "experience  :  experi\n",
      "related  :  relat\n",
      "area  :  area\n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "analysis  :  analysi\n",
      "also  :  also\n",
      "refers  :  refer\n",
      "ev  :  ev\n",
      "  :  \n",
      "  :  \n",
      "web  :  web\n",
      "emerged  :  emerg\n",
      "important  :  import\n",
      "source  :  sourc\n",
      "information  :  inform\n",
      "world  :  world\n",
      "this  :  thi\n",
      "resulted  :  result\n",
      "need  :  need\n",
      "automated  :  autom\n",
      "software  :  softwar\n",
      "components  :  compon\n",
      "analyze  :  analyz\n",
      "web  :  web\n",
      "pages  :  page\n",
      "harvest  :  harvest\n",
      "useful  :  use\n",
      "information  :  inform\n",
      "however  :  howev\n",
      "typical  :  typic\n",
      "web  :  web\n",
      "pages  :  page\n",
      "informative  :  inform\n",
      "content  :  content\n",
      "surrounded  :  surround\n",
      "high  :  high\n",
      "degree  :  degre\n",
      "noise  :  nois\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "theoretically  :  theoret\n",
      "motivated  :  motiv\n",
      "range  :  rang\n",
      "computational  :  comput\n",
      "techniques  :  techniqu\n",
      "analysing  :  analys\n",
      "representing  :  repres\n",
      "naturally  :  natur\n",
      "occurring  :  occur\n",
      "texts  :  text\n",
      "one  :  one\n",
      "levels  :  level\n",
      "linguistic  :  linguist\n",
      "analysis  :  analysi\n",
      "purpose  :  purpos\n",
      "achieving  :  achiev\n",
      "human  :  human\n",
      "like  :  like\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "range  :  rang\n",
      "tasks  :  task\n",
      "applications  :  applic\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "paper  :  paper\n",
      "reviews  :  review\n",
      "processes  :  process\n",
      "involved  :  involv\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "it  :  it\n",
      "demonstrates  :  demonstr\n",
      "various  :  variou\n",
      "kinds  :  kind\n",
      "choices  :  choic\n",
      "need  :  need\n",
      "taken  :  taken\n",
      "execution  :  execut\n",
      "word  :  word\n",
      "morphology  :  morpholog\n",
      "syntactic  :  syntact\n",
      "text  :  text\n",
      "analysis  :  analysi\n",
      "text  :  text\n",
      "generation  :  gener\n",
      "components  :  compon\n",
      "it  :  it\n",
      "compares  :  compar\n",
      "time  :  time\n",
      "complexity  :  complex\n",
      "traditional  :  tradit\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "article  :  articl\n",
      "focusses  :  focuss\n",
      "derivation  :  deriv\n",
      "large  :  larg\n",
      "lexicons  :  lexicon\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "we  :  we\n",
      "describe  :  describ\n",
      "development  :  develop\n",
      "dictionary  :  dictionari\n",
      "support  :  support\n",
      "environment  :  environ\n",
      "linking  :  link\n",
      "restructured  :  restructur\n",
      "version  :  version\n",
      "longman  :  longman\n",
      "dictionary  :  dictionari\n",
      "contemporary  :  contemporari\n",
      "english  :  english\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "systems  :  system\n",
      "the  :  the\n",
      "process  :  process\n",
      "restruc  :  restruc\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "introduce  :  introduc\n",
      "method  :  method\n",
      "analyzing  :  analyz\n",
      "complexity  :  complex\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "tasks  :  task\n",
      "predicting  :  predict\n",
      "difficulty  :  difficulti\n",
      "new  :  new\n",
      "nlp  :  nlp\n",
      "tasks  :  task\n",
      "our  :  our\n",
      "complexity  :  complex\n",
      "measures  :  measur\n",
      "derived  :  deriv\n",
      "kolmogorov  :  kolmogorov\n",
      "complexity  :  complex\n",
      "class  :  class\n",
      "automata  :  automata\n",
      "meaning  :  mean\n",
      "automata  :  automata\n",
      "whose  :  whose\n",
      "purpose  :  purpos\n",
      "extract  :  extract\n",
      "relevant  :  relev\n",
      "pieces  :  piec\n",
      "infor  :  infor\n",
      "  :  \n",
      "  :  \n",
      "deep  :  deep\n",
      "learning  :  learn\n",
      "emerged  :  emerg\n",
      "new  :  new\n",
      "area  :  area\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "research  :  research\n",
      "it  :  it\n",
      "tries  :  tri\n",
      "mimic  :  mimic\n",
      "human  :  human\n",
      "brain  :  brain\n",
      "capable  :  capabl\n",
      "processing  :  process\n",
      "learning  :  learn\n",
      "complex  :  complex\n",
      "input  :  input\n",
      "data  :  data\n",
      "solving  :  solv\n",
      "different  :  differ\n",
      "kinds  :  kind\n",
      "complicated  :  complic\n",
      "tasks  :  task\n",
      "well  :  well\n",
      "it  :  it\n",
      "successfully  :  success\n",
      "applied  :  appli\n",
      "several  :  sever\n",
      "fields  :  field\n",
      "images  :  imag\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "author  :  author\n",
      "produced  :  produc\n",
      "version  :  version\n",
      "paper  :  paper\n",
      "published  :  publish\n",
      "the  :  the\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "application  :  applic\n",
      "automated  :  autom\n",
      "parsing  :  pars\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "techniques  :  techniqu\n",
      "analyze  :  analyz\n",
      "standard  :  standard\n",
      "text  :  text\n",
      "applications  :  applic\n",
      "nlp  :  nlp\n",
      "requirements  :  requir\n",
      "engineering  :  engin\n",
      "include  :  includ\n",
      "extraction  :  extract\n",
      "ontologies  :  ontolog\n",
      "requirements  :  requir\n",
      "specification  :  specif\n",
      "use  :  use\n",
      "nlp  :  nlp\n",
      "verify  :  verifi\n",
      "consistency  :  consist\n",
      "  :  \n",
      "  :  \n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "addresses  :  address\n",
      "problem  :  problem\n",
      "finding  :  find\n",
      "documents  :  document\n",
      "whose  :  whose\n",
      "content  :  content\n",
      "matches  :  match\n",
      "user  :  user\n",
      "request  :  request\n",
      "among  :  among\n",
      "large  :  larg\n",
      "collection  :  collect\n",
      "documents  :  document\n",
      "currently  :  current\n",
      "successful  :  success\n",
      "general  :  gener\n",
      "purpose  :  purpos\n",
      "retrieval  :  retriev\n",
      "methods  :  method\n",
      "statistical  :  statist\n",
      "methods  :  method\n",
      "treat  :  treat\n",
      "text  :  text\n",
      "little  :  littl\n",
      "bag  :  bag\n",
      "w  :  w\n",
      "  :  \n",
      "  :  \n",
      "work  :  work\n",
      "computational  :  comput\n",
      "linguistics  :  linguist\n",
      "began  :  began\n",
      "soon  :  soon\n",
      "development  :  develop\n",
      "first  :  first\n",
      "computers  :  comput\n",
      "booth  :  booth\n",
      "brandwood  :  brandwood\n",
      "cleave  :  cleav\n",
      "1958  :  1958\n",
      "yet  :  yet\n",
      "intervening  :  interven\n",
      "four  :  four\n",
      "decades  :  decad\n",
      "pervasive  :  pervas\n",
      "feeling  :  feel\n",
      "progress  :  progress\n",
      "computer  :  comput\n",
      "understanding  :  understand\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "commensurate  :  commensur\n",
      "progres  :  progr\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "a  :  a\n",
      "system  :  system\n",
      "recognizes  :  recogn\n",
      "authenticates  :  authent\n",
      "voice  :  voic\n",
      "user  :  user\n",
      "extracting  :  extract\n",
      "distinct  :  distinct\n",
      "features  :  featur\n",
      "voice  :  voic\n",
      "samples  :  sampl\n",
      "usually  :  usual\n",
      "termed  :  term\n",
      "voice  :  voic\n",
      "recognition  :  recognit\n",
      "system  :  system\n",
      "voice  :  voic\n",
      "identification  :  identif\n",
      "carried  :  carri\n",
      "converting  :  convert\n",
      "human  :  human\n",
      "voice  :  voic\n",
      "digital  :  digit\n",
      "data  :  data\n",
      "the  :  the\n",
      "digitized  :  digit\n",
      "audio  :  audio\n",
      "samples  :  sampl\n",
      "unde  :  und\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "testing  :  test\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "requirements  :  requir\n",
      "standard  :  standard\n",
      "approach  :  approach\n",
      "system  :  system\n",
      "acceptance  :  accept\n",
      "testing  :  test\n",
      "this  :  thi\n",
      "test  :  test\n",
      "often  :  often\n",
      "performed  :  perform\n",
      "independent  :  independ\n",
      "test  :  test\n",
      "organization  :  organ\n",
      "unfamiliar  :  unfamiliar\n",
      "application  :  applic\n",
      "area  :  area\n",
      "the  :  the\n",
      "things  :  thing\n",
      "testers  :  tester\n",
      "go  :  go\n",
      "written  :  written\n",
      "requirements  :  requir\n",
      "so  :  so\n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "algorithms  :  algorithm\n",
      "allow  :  allow\n",
      "understanding  :  understand\n",
      "generation  :  gener\n",
      "humor  :  humor\n",
      "there  :  there\n",
      "general  :  gener\n",
      "aim  :  aim\n",
      "modeling  :  model\n",
      "humor  :  humor\n",
      "provide  :  provid\n",
      "us  :  us\n",
      "lots  :  lot\n",
      "information  :  inform\n",
      "cognitive  :  cognit\n",
      "abilities  :  abil\n",
      "general  :  gener\n",
      "reasoning  :  reason\n",
      "remembering  :  rememb\n",
      "understanding  :  understand\n",
      "situations  :  situat\n",
      "understanding  :  understand\n",
      "conversati  :  conversati\n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "in  :  in\n",
      "recent  :  recent\n",
      "years  :  year\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "ml  :  ml\n",
      "used  :  use\n",
      "solve  :  solv\n",
      "complex  :  complex\n",
      "tasks  :  task\n",
      "different  :  differ\n",
      "disciplines  :  disciplin\n",
      "ranging  :  rang\n",
      "data  :  data\n",
      "mining  :  mine\n",
      "information  :  inform\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "argue  :  argu\n",
      "manual  :  manual\n",
      "automatic  :  automat\n",
      "thesauruses  :  thesaurus\n",
      "alternative  :  altern\n",
      "resources  :  resourc\n",
      "nlp  :  nlp\n",
      "tasks  :  task\n",
      "this  :  thi\n",
      "involves  :  involv\n",
      "radical  :  radic\n",
      "step  :  step\n",
      "interpreting  :  interpret\n",
      "manual  :  manual\n",
      "thesauruses  :  thesaurus\n",
      "classifications  :  classif\n",
      "words  :  word\n",
      "rather  :  rather\n",
      "word  :  word\n",
      "senses  :  sens\n",
      "case  :  case\n",
      "made  :  made\n",
      "the  :  the\n",
      "range  :  rang\n",
      "roles  :  role\n",
      "thesauruses  :  thesaurus\n",
      "within  :  within\n",
      "nlp  :  nlp\n",
      "briefly  :  briefli\n",
      "  :  \n",
      "  :  \n",
      "introduction  :  introduct\n",
      "patterns  :  pattern\n",
      "music  :  music\n",
      "object  :  object\n",
      "intensive  :  intens\n",
      "studies  :  studi\n",
      "past  :  past\n",
      "years  :  year\n",
      "one  :  one\n",
      "purposes  :  purpos\n",
      "analyzing  :  analyz\n",
      "musical  :  music\n",
      "structure  :  structur\n",
      "form  :  form\n",
      "discover  :  discov\n",
      "patterns  :  pattern\n",
      "explicit  :  explicit\n",
      "implicit  :  implicit\n",
      "musical  :  music\n",
      "works  :  work\n",
      "simon  :  simon\n",
      "13  :  13\n",
      "patterns  :  pattern\n",
      "comprise  :  compris\n",
      "periodicity  :  period\n",
      "make  :  make\n",
      "use  :  use\n",
      "alphabets  :  alphabet\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "many  :  mani\n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "ir  :  ir\n",
      "systems  :  system\n",
      "retrieve  :  retriev\n",
      "relevant  :  relev\n",
      "documents  :  document\n",
      "based  :  base\n",
      "exact  :  exact\n",
      "matching  :  match\n",
      "keywords  :  keyword\n",
      "query  :  queri\n",
      "documents  :  document\n",
      "this  :  thi\n",
      "method  :  method\n",
      "degrades  :  degrad\n",
      "precision  :  precis\n",
      "rate  :  rate\n",
      "in  :  in\n",
      "order  :  order\n",
      "solve  :  solv\n",
      "problem  :  problem\n",
      "collected  :  collect\n",
      "semantically  :  semant\n",
      "related  :  relat\n",
      "words  :  word\n",
      "assigned  :  assign\n",
      "semantic  :  semant\n",
      "relationships  :  relationship\n",
      "used  :  use\n",
      "gener  :  gener\n",
      "  :  \n",
      "  :  \n",
      "paper  :  paper\n",
      "argue  :  argu\n",
      "questionanswering  :  questionansw\n",
      "qa  :  qa\n",
      "technical  :  technic\n",
      "domains  :  domain\n",
      "distinctly  :  distinctli\n",
      "different  :  differ\n",
      "trec  :  trec\n",
      "based  :  base\n",
      "qa  :  qa\n",
      "web  :  web\n",
      "based  :  base\n",
      "qa  :  qa\n",
      "cannot  :  cannot\n",
      "benefit  :  benefit\n",
      "lom  :  lom\n",
      "data  :  data\n",
      "intensive  :  intens\n",
      "approaches  :  approach\n",
      "  :  \n",
      "  :  \n",
      "universit  :  universit\n",
      "quot  :  quot\n",
      "des  :  de\n",
      "saarlandes  :  saarland\n",
      "  :  \n",
      "  :  \n",
      "proceedings  :  proceed\n",
      "workshop  :  workshop\n",
      "  :  \n",
      "  :  \n",
      "uni  :  uni\n",
      "hamburg  :  hamburg\n",
      "de  :  de\n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "2  :  2\n",
      "6  :  6\n",
      "  :  \n",
      "  :  \n",
      "sri  :  sri\n",
      "developed  :  develop\n",
      "new  :  new\n",
      "architecture  :  architectur\n",
      "integrating  :  integr\n",
      "speech  :  speech\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "applies  :  appli\n",
      "linguistic  :  linguist\n",
      "constraints  :  constraint\n",
      "recognition  :  recognit\n",
      "incrementally  :  increment\n",
      "expanding  :  expand\n",
      "state  :  state\n",
      "transition  :  transit\n",
      "network  :  network\n",
      "embodied  :  embodi\n",
      "unification  :  unif\n",
      "grammar  :  grammar\n",
      "we  :  we\n",
      "compare  :  compar\n",
      "dynamic  :  dynam\n",
      "gralnlnar  :  gralnlnar\n",
      "network  :  network\n",
      "dgn  :  dgn\n",
      "approach  :  approach\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "chapter  :  chapter\n",
      "considers  :  consid\n",
      "revolution  :  revolut\n",
      "taken  :  taken\n",
      "place  :  place\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "research  :  research\n",
      "last  :  last\n",
      "five  :  five\n",
      "years  :  year\n",
      "it  :  it\n",
      "begins  :  begin\n",
      "providing  :  provid\n",
      "brief  :  brief\n",
      "guide  :  guid\n",
      "structure  :  structur\n",
      "field  :  field\n",
      "presents  :  present\n",
      "caricature  :  caricatur\n",
      "two  :  two\n",
      "competing  :  compet\n",
      "paradigms  :  paradigm\n",
      "1980s  :  1980\n",
      "nlp  :  nlp\n",
      "research  :  research\n",
      "indicates  :  indic\n",
      "reasons  :  reason\n",
      "wh  :  wh\n",
      "  :  \n",
      "  :  \n",
      "visual  :  visual\n",
      "development  :  develop\n",
      "environment  :  environ\n",
      "support  :  support\n",
      "visual  :  visual\n",
      "assembly  :  assembl\n",
      "execution  :  execut\n",
      "analysis  :  analysi\n",
      "modular  :  modular\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "systems  :  system\n",
      "the  :  the\n",
      "visual  :  visual\n",
      "model  :  model\n",
      "executable  :  execut\n",
      "data  :  data\n",
      "flow  :  flow\n",
      "program  :  program\n",
      "graph  :  graph\n",
      "automatically  :  automat\n",
      "synthesised  :  synthesis\n",
      "data  :  data\n",
      "dependency  :  depend\n",
      "declarations  :  declar\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "modules  :  modul\n",
      "the  :  the\n",
      "graph  :  graph\n",
      "th  :  th\n",
      "  :  \n",
      "  :  \n",
      "in  :  in\n",
      "chapter  :  chapter\n",
      "basic  :  basic\n",
      "uses  :  use\n",
      "description  :  descript\n",
      "logics  :  logic\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "analysed  :  analys\n",
      "together  :  togeth\n",
      "little  :  littl\n",
      "bit  :  bit\n",
      "history  :  histori\n",
      "role  :  role\n",
      "description  :  descript\n",
      "logics  :  logic\n",
      "current  :  current\n",
      "state  :  state\n",
      "art  :  art\n",
      "computational  :  comput\n",
      "linguistics  :  linguist\n",
      "pointed  :  point\n",
      "18  :  18\n",
      "1  :  1\n",
      "introduction  :  introduct\n",
      "since  :  sinc\n",
      "early  :  earli\n",
      "days  :  day\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "applied  :  appli\n",
      "structure  :  structur\n",
      "learning  :  learn\n",
      "model  :  model\n",
      "max  :  max\n",
      "margin  :  margin\n",
      "structure  :  structur\n",
      "mms  :  mm\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "tasks  :  task\n",
      "aim  :  aim\n",
      "capture  :  captur\n",
      "latent  :  latent\n",
      "relationships  :  relationship\n",
      "within  :  within\n",
      "output  :  output\n",
      "language  :  languag\n",
      "domain  :  domain\n",
      "we  :  we\n",
      "formulate  :  formul\n",
      "model  :  model\n",
      "extension  :  extens\n",
      "multi  :  multi\n",
      "class  :  class\n",
      "support  :  support\n",
      "vector  :  vector\n",
      "machine  :  machin\n",
      "svm  :  svm\n",
      "present  :  present\n",
      "per  :  per\n",
      "  :  \n",
      "  :  \n",
      "vast  :  vast\n",
      "quantities  :  quantiti\n",
      "text  :  text\n",
      "becoming  :  becom\n",
      "available  :  avail\n",
      "elec  :  elec\n",
      "tronic  :  tronic\n",
      "form  :  form\n",
      "ranging  :  rang\n",
      "published  :  publish\n",
      "documents  :  document\n",
      "e  :  e\n",
      "g  :  g\n",
      "electronic  :  electron\n",
      "dictionaries  :  dictionari\n",
      "encyclopedias  :  encyclopedia\n",
      "libraries  :  librari\n",
      "archives  :  archiv\n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "services  :  servic\n",
      "private  :  privat\n",
      "databases  :  databas\n",
      "e  :  e\n",
      "g  :  g\n",
      "marketing  :  market\n",
      "information  :  inform\n",
      "legal  :  legal\n",
      "records  :  record\n",
      "medical  :  medic\n",
      "histories  :  histori\n",
      "per  :  per\n",
      "  :  \n",
      "  :  \n",
      "over  :  over\n",
      "last  :  last\n",
      "years  :  year\n",
      "number  :  number\n",
      "areas  :  area\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "begun  :  begun\n",
      "applying  :  appli\n",
      "graph  :  graph\n",
      "based  :  base\n",
      "techniques  :  techniqu\n",
      "these  :  these\n",
      "include  :  includ\n",
      "among  :  among\n",
      "others  :  other\n",
      "text  :  text\n",
      "summarization  :  summar\n",
      "syntactic  :  syntact\n",
      "parsing  :  pars\n",
      "word  :  word\n",
      "sense  :  sens\n",
      "disambiguation  :  disambigu\n",
      "ontology  :  ontolog\n",
      "construction  :  construct\n",
      "sentiment  :  sentiment\n",
      "subjectivity  :  subject\n",
      "analysis  :  analysi\n",
      "text  :  text\n",
      "clustering  :  cluster\n",
      "in  :  in\n",
      "pa  :  pa\n",
      "  :  \n",
      "  :  \n",
      "in  :  in\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "research  :  research\n",
      "results  :  result\n",
      "software  :  softwar\n",
      "engineering  :  engin\n",
      "software  :  softwar\n",
      "technology  :  technolog\n",
      "often  :  often\n",
      "neglected  :  neglect\n",
      "  :  \n",
      "  :  \n",
      "kernelized  :  kernel\n",
      "sorting  :  sort\n",
      "approach  :  approach\n",
      "matching  :  match\n",
      "objects  :  object\n",
      "two  :  two\n",
      "sources  :  sourc\n",
      "domains  :  domain\n",
      "require  :  requir\n",
      "prior  :  prior\n",
      "notion  :  notion\n",
      "similarity  :  similar\n",
      "objects  :  object\n",
      "across  :  across\n",
      "two  :  two\n",
      "sources  :  sourc\n",
      "unfortunately  :  unfortun\n",
      "technique  :  techniqu\n",
      "highly  :  highli\n",
      "sensitive  :  sensit\n",
      "initialization  :  initi\n",
      "high  :  high\n",
      "dimensional  :  dimension\n",
      "data  :  data\n",
      "we  :  we\n",
      "present  :  present\n",
      "variants  :  variant\n",
      "kern  :  kern\n",
      "  :  \n",
      "  :  \n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "complex  :  complex\n",
      "compound  :  compound\n",
      "organization  :  organ\n",
      "structures  :  structur\n",
      "basic  :  basic\n",
      "linguistic  :  linguist\n",
      "elements  :  element\n",
      "represent  :  repres\n",
      "various  :  variou\n",
      "meanings  :  mean\n",
      "therefore  :  therefor\n",
      "understand  :  understand\n",
      "nature  :  natur\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "need  :  need\n",
      "sophisticated  :  sophist\n",
      "treatment  :  treatment\n",
      "basic  :  basic\n",
      "elements  :  element\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well  :  well\n",
      "insights  :  insight\n",
      "elements  :  element\n",
      "  :  \n",
      "  :  \n",
      "in  :  in\n",
      "paper  :  paper\n",
      "describe  :  describ\n",
      "framework  :  framework\n",
      "developing  :  develop\n",
      "probabilistic  :  probabilist\n",
      "classifiers  :  classifi\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "our  :  our\n",
      "focus  :  focu\n",
      "formulating  :  formul\n",
      "models  :  model\n",
      "capture  :  captur\n",
      "important  :  import\n",
      "interdependencies  :  interdepend\n",
      "among  :  among\n",
      "features  :  featur\n",
      "avoid  :  avoid\n",
      "overfitting  :  overfit\n",
      "data  :  data\n",
      "also  :  also\n",
      "characterizing  :  character\n",
      "data  :  data\n",
      "well  :  well\n",
      "the  :  the\n",
      "class  :  class\n",
      "pro  :  pro\n",
      "  :  \n",
      "  :  \n",
      "many  :  mani\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "techniques  :  techniqu\n",
      "used  :  use\n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "the  :  the\n",
      "results  :  result\n",
      "encouraging  :  encourag\n",
      "simple  :  simpl\n",
      "methods  :  method\n",
      "stopwording  :  stopword\n",
      "porter  :  porter\n",
      "style  :  style\n",
      "stemming  :  stem\n",
      "etc  :  etc\n",
      "usually  :  usual\n",
      "yield  :  yield\n",
      "significant  :  signific\n",
      "improvements  :  improv\n",
      "higher  :  higher\n",
      "level  :  level\n",
      "processing  :  process\n",
      "chunking  :  chunk\n",
      "parsing  :  pars\n",
      "word  :  word\n",
      "sense  :  sens\n",
      "disambiguation  :  disambigu\n",
      "e  :  e\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "this  :  thi\n",
      "paper  :  paper\n",
      "explains  :  explain\n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "using  :  use\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "malayalam  :  malayalam\n",
      "language  :  languag\n",
      "basic  :  basic\n",
      "  :  \n",
      "  :  \n",
      "the  :  the\n",
      "research  :  research\n",
      "areas  :  area\n",
      "plan  :  plan\n",
      "recognition  :  recognit\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "parsing  :  pars\n",
      "share  :  share\n",
      "many  :  mani\n",
      "common  :  common\n",
      "features  :  featur\n",
      "even  :  even\n",
      "algorithms  :  algorithm\n",
      "however  :  howev\n",
      "dialog  :  dialog\n",
      "two  :  two\n",
      "disciplines  :  disciplin\n",
      "effective  :  effect\n",
      "specifically  :  specif\n",
      "significant  :  signific\n",
      "recent  :  recent\n",
      "results  :  result\n",
      "parsing  :  pars\n",
      "mildly  :  mildli\n",
      "context  :  context\n",
      "sensitive  :  sensit\n",
      "grammars  :  grammar\n",
      "leveraged  :  leverag\n",
      "  :  \n",
      "  :  \n",
      "the  :  the\n",
      "research  :  research\n",
      "areas  :  area\n",
      "plan  :  plan\n",
      "recognition  :  recognit\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "parsing  :  pars\n",
      "share  :  share\n",
      "many  :  mani\n",
      "common  :  common\n",
      "features  :  featur\n",
      "even  :  even\n",
      "algorithms  :  algorithm\n",
      "however  :  howev\n",
      "dialog  :  dialog\n",
      "two  :  two\n",
      "disciplines  :  disciplin\n",
      "effective  :  effect\n",
      "specifically  :  specif\n",
      "significant  :  signific\n",
      "recent  :  recent\n",
      "results  :  result\n",
      "parsing  :  pars\n",
      "mildly  :  mildli\n",
      "context  :  context\n",
      "sensitive  :  sensit\n",
      "grammars  :  grammar\n",
      "leveraged  :  leverag\n",
      "  :  \n",
      "  :  \n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "process  :  process\n",
      "finding  :  find\n",
      "documents  :  document\n",
      "document  :  document\n",
      "collection  :  collect\n",
      "satisfies  :  satisfi\n",
      "information  :  inform\n",
      "need  :  need\n",
      "user  :  user\n",
      "the  :  the\n",
      "documents  :  document\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "constructs  :  construct\n",
      "motivation  :  motiv\n",
      "work  :  work\n",
      "investigate  :  investig\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "used  :  use\n",
      "improve  :  improv\n",
      "performa  :  performa\n",
      "  :  \n",
      "  :  \n",
      "while  :  while\n",
      "computational  :  comput\n",
      "logic  :  logic\n",
      "become  :  becom\n",
      "widely  :  wide\n",
      "used  :  use\n",
      "representing  :  repres\n",
      "reasoning  :  reason\n",
      "linguistic  :  linguist\n",
      "knowledge  :  knowledg\n",
      "cross  :  cross\n",
      "fertilization  :  fertil\n",
      "logic  :  logic\n",
      "programming  :  program\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "given  :  given\n",
      "rise  :  rise\n",
      "new  :  new\n",
      "discipline  :  disciplin\n",
      "known  :  known\n",
      "inductive  :  induct\n",
      "logic  :  logic\n",
      "programming  :  program\n",
      "inspired  :  inspir\n",
      "building  :  build\n",
      "achievements  :  achiev\n",
      "  :  \n",
      "  :  \n",
      "what  :  what\n",
      "statistical  :  statist\n",
      "method  :  method\n",
      "used  :  use\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "in  :  in\n",
      "paper  :  paper\n",
      "start  :  start\n",
      "definition  :  definit\n",
      "nlp  :  nlp\n",
      "concerned  :  concern\n",
      "design  :  design\n",
      "implementation  :  implement\n",
      "effective  :  effect\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "input  :  input\n",
      "output  :  output\n",
      "components  :  compon\n",
      "computational  :  comput\n",
      "systems  :  system\n",
      "we  :  we\n",
      "distinguish  :  distinguish\n",
      "three  :  three\n",
      "kind  :  kind\n",
      "  :  \n",
      "  :  \n",
      "in  :  in\n",
      "report  :  report\n",
      "collaborative  :  collabor\n",
      "work  :  work\n",
      "fields  :  field\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "ml  :  ml\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "presented  :  present\n",
      "the  :  the\n",
      "document  :  document\n",
      "structured  :  structur\n",
      "two  :  two\n",
      "parts  :  part\n",
      "the  :  the\n",
      "first  :  first\n",
      "part  :  part\n",
      "includes  :  includ\n",
      "superficial  :  superfici\n",
      "comprehensive  :  comprehens\n",
      "survey  :  survey\n",
      "covering  :  cover\n",
      "state  :  state\n",
      "art  :  art\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "techniq  :  techniq\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "this  :  thi\n",
      "thesis  :  thesi\n",
      "examines  :  examin\n",
      "use  :  use\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "techniques  :  techniqu\n",
      "various  :  variou\n",
      "tasks  :  task\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "mainly  :  mainli\n",
      "task  :  task\n",
      "information  :  inform\n",
      "extraction  :  extract\n",
      "texts  :  text\n",
      "the  :  the\n",
      "objectives  :  object\n",
      "improvement  :  improv\n",
      "adaptability  :  adapt\n",
      "information  :  inform\n",
      "extraction  :  extract\n",
      "systems  :  system\n",
      "new  :  new\n",
      "thematic  :  themat\n",
      "mains  :  main\n",
      "even  :  even\n",
      "lang  :  lang\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "chapter  :  chapter\n",
      "examines  :  examin\n",
      "application  :  applic\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "computerassisted  :  computerassist\n",
      "language  :  languag\n",
      "learning  :  learn\n",
      "including  :  includ\n",
      "history  :  histori\n",
      "work  :  work\n",
      "field  :  field\n",
      "last  :  last\n",
      "thirtyfive  :  thirtyf\n",
      "years  :  year\n",
      "focus  :  focu\n",
      "current  :  current\n",
      "developments  :  develop\n",
      "opportunities  :  opportun\n",
      "36  :  36\n",
      "1  :  1\n",
      "  :  \n",
      "  :  \n",
      "traditional  :  tradit\n",
      "approaches  :  approach\n",
      "tointerpretation  :  tointerpret\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "typically  :  typic\n",
      "fall  :  fall\n",
      "one  :  one\n",
      "three  :  three\n",
      "classes  :  class\n",
      "syntax  :  syntax\n",
      "driven  :  driven\n",
      "semantics  :  semant\n",
      "driven  :  driven\n",
      "frame  :  frame\n",
      "task  :  task\n",
      "based  :  base\n",
      "syntax  :  syntax\n",
      "driven  :  driven\n",
      "approaches  :  approach\n",
      "use  :  use\n",
      "domain  :  domain\n",
      "independent  :  independ\n",
      "grammar  :  grammar\n",
      "drive  :  drive\n",
      "interpretation  :  interpret\n",
      "process  :  process\n",
      "produce  :  produc\n",
      "global  :  global\n",
      "parse  :  pars\n",
      "input  :  input\n",
      "  :  \n",
      "  :  \n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "large  :  larg\n",
      "diverse  :  divers\n",
      "subtopic  :  subtop\n",
      "artificial  :  artifici\n",
      "intelligence  :  intellig\n",
      "as  :  as\n",
      "result  :  result\n",
      "nlp  :  nlp\n",
      "many  :  mani\n",
      "subtopics  :  subtop\n",
      "including  :  includ\n",
      "optical  :  optic\n",
      "character  :  charact\n",
      "recognition  :  recognit\n",
      "text  :  text\n",
      "speech  :  speech\n",
      "translators  :  translat\n",
      "foreign  :  foreign\n",
      "language  :  languag\n",
      "reading  :  read\n",
      "writing  :  write\n",
      "aids  :  aid\n",
      "machine  :  machin\n",
      "translation  :  translat\n",
      "speech  :  speech\n",
      "recognition  :  recognit\n",
      "w  :  w\n",
      "  :  \n",
      "  :  \n",
      "probabilistic  :  probabilist\n",
      "finite  :  finit\n",
      "state  :  state\n",
      "string  :  string\n",
      "transducers  :  transduc\n",
      "fsts  :  fst\n",
      "extremely  :  extrem\n",
      "popular  :  popular\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "due  :  due\n",
      "powerful  :  power\n",
      "generic  :  gener\n",
      "methods  :  method\n",
      "applying  :  appli\n",
      "composing  :  compos\n",
      "learning  :  learn\n",
      "unfortunately  :  unfortun\n",
      "fsts  :  fst\n",
      "good  :  good\n",
      "fit  :  fit\n",
      "much  :  much\n",
      "current  :  current\n",
      "work  :  work\n",
      "probabilistic  :  probabilist\n",
      "modeling  :  model\n",
      "machine  :  machin\n",
      "translati  :  translati\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "in  :  in\n",
      "special  :  special\n",
      "issue  :  issu\n",
      "tal  :  tal\n",
      "look  :  look\n",
      "fundamental  :  fundament\n",
      "principles  :  principl\n",
      "underlying  :  underli\n",
      "evaluation  :  evalu\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "we  :  we\n",
      "adopt  :  adopt\n",
      "global  :  global\n",
      "point  :  point\n",
      "view  :  view\n",
      "goes  :  goe\n",
      "beyond  :  beyond\n",
      "horizon  :  horizon\n",
      "single  :  singl\n",
      "evaluation  :  evalu\n",
      "campaign  :  campaign\n",
      "particular  :  particular\n",
      "protocol  :  protocol\n",
      "after  :  after\n",
      "brief  :  brief\n",
      "review  :  review\n",
      "history  :  histori\n",
      "terminology  :  terminolog\n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "systems  :  system\n",
      "nlp  :  nlp\n",
      "extract  :  extract\n",
      "clinical  :  clinic\n",
      "information  :  inform\n",
      "textual  :  textual\n",
      "reports  :  report\n",
      "shown  :  shown\n",
      "effective  :  effect\n",
      "limited  :  limit\n",
      "domains  :  domain\n",
      "particular  :  particular\n",
      "applications  :  applic\n",
      "because  :  becaus\n",
      "nlp  :  nlp\n",
      "system  :  system\n",
      "typically  :  typic\n",
      "requires  :  requir\n",
      "substantial  :  substanti\n",
      "resources  :  resourc\n",
      "develop  :  develop\n",
      "beneficial  :  benefici\n",
      "designed  :  design\n",
      "easily  :  easili\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "propose  :  propos\n",
      "bifurcated  :  bifurc\n",
      "paradigm  :  paradigm\n",
      "construction  :  construct\n",
      "prolog  :  prolog\n",
      "knowl  :  knowl\n",
      "edge  :  edg\n",
      "base  :  base\n",
      "body  :  bodi\n",
      "documents  :  document\n",
      "first  :  first\n",
      "information  :  inform\n",
      "extraction  :  extract\n",
      "ie  :  ie\n",
      "ap  :  ap\n",
      "plication  :  plicat\n",
      "annotate  :  annot\n",
      "corpus  :  corpu\n",
      "output  :  output\n",
      "annotated  :  annot\n",
      "documents  :  document\n",
      "second  :  second\n",
      "prolog  :  prolog\n",
      "knowledge  :  knowledg\n",
      "base  :  base\n",
      "kb  :  kb\n",
      "application  :  applic\n",
      "transform  :  transform\n",
      "th  :  th\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "describe  :  describ\n",
      "single  :  singl\n",
      "convolutional  :  convolut\n",
      "neural  :  neural\n",
      "network  :  network\n",
      "architecture  :  architectur\n",
      "given  :  given\n",
      "sentence  :  sentenc\n",
      "outputs  :  output\n",
      "host  :  host\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "predictions  :  predict\n",
      "part  :  part\n",
      "speech  :  speech\n",
      "tags  :  tag\n",
      "chunks  :  chunk\n",
      "named  :  name\n",
      "entity  :  entiti\n",
      "tags  :  tag\n",
      "semantic  :  semant\n",
      "roles  :  role\n",
      "semantically  :  semant\n",
      "similar  :  similar\n",
      "words  :  word\n",
      "likelihood  :  likelihood\n",
      "sentence  :  sentenc\n",
      "makes  :  make\n",
      "sense  :  sens\n",
      "grammatically  :  grammat\n",
      "sem  :  sem\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "developed  :  develop\n",
      "prototype  :  prototyp\n",
      "information  :  inform\n",
      "retrieval  :  retriev\n",
      "system  :  system\n",
      "uses  :  use\n",
      "advanced  :  advanc\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "techniques  :  techniqu\n",
      "enhance  :  enhanc\n",
      "effectiveness  :  effect\n",
      "traditional  :  tradit\n",
      "key  :  key\n",
      "word  :  word\n",
      "based  :  base\n",
      "document  :  document\n",
      "retrieval  :  retriev\n",
      "the  :  the\n",
      "backbone  :  backbon\n",
      "system  :  system\n",
      "statistical  :  statist\n",
      "retrieval  :  retriev\n",
      "engine  :  engin\n",
      "performs  :  perform\n",
      "automated  :  autom\n",
      "indexing  :  index\n",
      "docum  :  docum\n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "in  :  in\n",
      "paper  :  paper\n",
      "discuss  :  discuss\n",
      "several  :  sever\n",
      "issues  :  issu\n",
      "requirements  :  requir\n",
      "enabling  :  enabl\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "systems  :  system\n",
      "become  :  becom\n",
      "context  :  context\n",
      "adaptive  :  adapt\n",
      "given  :  given\n",
      "fact  :  fact\n",
      "emerging  :  emerg\n",
      "systems  :  system\n",
      "feature  :  featur\n",
      "speaker  :  speaker\n",
      "independent  :  independ\n",
      "continuous  :  continu\n",
      "speech  :  speech\n",
      "recognition  :  recognit\n",
      "restricted  :  restrict\n",
      "individual  :  individu\n",
      "domains  :  domain\n",
      "equipped  :  equip\n",
      "syntactic  :  syntact\n",
      "  :  \n",
      "  :  \n",
      "in  :  in\n",
      "fall  :  fall\n",
      "2004  :  2004\n",
      "i  :  i\n",
      "introduced  :  introduc\n",
      "new  :  new\n",
      "course  :  cours\n",
      "called  :  call\n",
      "applied  :  appli\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "students  :  student\n",
      "acquire  :  acquir\n",
      "understanding  :  understand\n",
      "text  :  text\n",
      "analysis  :  analysi\n",
      "techniques  :  techniqu\n",
      "currently  :  current\n",
      "feasible  :  feasibl\n",
      "practical  :  practic\n",
      "applications  :  applic\n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "study  :  studi\n",
      "mathematical  :  mathemat\n",
      "computational  :  comput\n",
      "modelling  :  model\n",
      "various  :  variou\n",
      "aspects  :  aspect\n",
      "language  :  languag\n",
      "improvement  :  improv\n",
      "wide  :  wide\n",
      "range  :  rang\n",
      "systems  :  system\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "language  :  languag\n",
      "arises  :  aris\n",
      "innate  :  innat\n",
      "facility  :  facil\n",
      "language  :  languag\n",
      "possessed  :  possess\n",
      "human  :  human\n",
      "intellect  :  intellect\n",
      "may  :  may\n",
      "  :  \n",
      "  :  \n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "branch  :  branch\n",
      "artificial  :  artifici\n",
      "intelligence  :  intellig\n",
      "includes  :  includ\n",
      "speech  :  speech\n",
      "synthesis  :  synthesi\n",
      "speech  :  speech\n",
      "recognition  :  recognit\n",
      "machine  :  machin\n",
      "translation  :  translat\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "wide  :  wide\n",
      "range  :  rang\n",
      "applications  :  applic\n",
      "indian  :  indian\n",
      "context  :  context\n",
      "most  :  most\n",
      "rural  :  rural\n",
      "indian  :  indian\n",
      "community  :  commun\n",
      "unable  :  unabl\n",
      "make  :  make\n",
      "use  :  use\n",
      "th  :  th\n",
      "  :  \n",
      "  :  \n",
      "an  :  an\n",
      "evaluation  :  evalu\n",
      "lolita  :  lolita\n",
      "related  :  relat\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "systems  :  system\n",
      "paul  :  paul\n",
      "callaghan  :  callaghan\n",
      "submitted  :  submit\n",
      "university  :  univers\n",
      "durham  :  durham\n",
      "degree  :  degre\n",
      "ph  :  ph\n",
      "d  :  d\n",
      "august  :  august\n",
      "1997  :  1997\n",
      "this  :  thi\n",
      "research  :  research\n",
      "addresses  :  address\n",
      "question  :  question\n",
      "evaluate  :  evalu\n",
      "systems  :  system\n",
      "like  :  like\n",
      "lolita  :  lolita\n",
      "lolita  :  lolita\n",
      "natural  :  natur\n",
      "  :  \n",
      "  :  \n",
      "previous  :  previou\n",
      "work  :  work\n",
      "demonstrated  :  demonstr\n",
      "web  :  web\n",
      "counts  :  count\n",
      "used  :  use\n",
      "approximate  :  approxim\n",
      "bigram  :  bigram\n",
      "counts  :  count\n",
      "suggesting  :  suggest\n",
      "web  :  web\n",
      "based  :  base\n",
      "frequencies  :  frequenc\n",
      "useful  :  use\n",
      "wide  :  wide\n",
      "variety  :  varieti\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "tasks  :  task\n",
      "however  :  howev\n",
      "limited  :  limit\n",
      "number  :  number\n",
      "tasks  :  task\n",
      "far  :  far\n",
      "tested  :  test\n",
      "using  :  use\n",
      "web  :  web\n",
      "scale  :  scale\n",
      "data  :  data\n",
      "sets  :  set\n",
      "the  :  the\n",
      "pr  :  pr\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "chapter  :  chapter\n",
      "examines  :  examin\n",
      "application  :  applic\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "computerassisted  :  computerassist\n",
      "language  :  languag\n",
      "learning  :  learn\n",
      "including  :  includ\n",
      "history  :  histori\n",
      "work  :  work\n",
      "field  :  field\n",
      "last  :  last\n",
      "thirtyfive  :  thirtyf\n",
      "years  :  year\n",
      "focus  :  focu\n",
      "current  :  current\n",
      "developments  :  develop\n",
      "opportunities  :  opportun\n",
      "16  :  16\n",
      "1  :  1\n",
      "introduction  :  introduct\n",
      "this  :  thi\n",
      "chapter  :  chapter\n",
      "focuses  :  focus\n",
      "applications  :  applic\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "paper  :  paper\n",
      "describes  :  describ\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "system  :  system\n",
      "improves  :  improv\n",
      "performance  :  perform\n",
      "learning  :  learn\n",
      "the  :  the\n",
      "system  :  system\n",
      "processes  :  process\n",
      "short  :  short\n",
      "english  :  english\n",
      "narratives  :  narr\n",
      "able  :  abl\n",
      "acquire  :  acquir\n",
      "single  :  singl\n",
      "narrative  :  narr\n",
      "new  :  new\n",
      "schema  :  schema\n",
      "stereotypical  :  stereotyp\n",
      "set  :  set\n",
      "actions  :  action\n",
      "during  :  dure\n",
      "understanding  :  understand\n",
      "process  :  process\n",
      "system  :  system\n",
      "attempts  :  attempt\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "classify  :  classifi\n",
      "review  :  review\n",
      "current  :  current\n",
      "approaches  :  approach\n",
      "software  :  softwar\n",
      "infrastructure  :  infrastructur\n",
      "research  :  research\n",
      "development  :  develop\n",
      "delivery  :  deliveri\n",
      "nlp  :  nlp\n",
      "systems  :  system\n",
      "the  :  the\n",
      "task  :  task\n",
      "  :  \n",
      "  :  \n",
      "confidence  :  confid\n",
      "measures  :  measur\n",
      "practical  :  practic\n",
      "solution  :  solut\n",
      "improving  :  improv\n",
      "usefulness  :  use\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "applications  :  applic\n",
      "confidence  :  confid\n",
      "estimation  :  estim\n",
      "generic  :  gener\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "approach  :  approach\n",
      "deriving  :  deriv\n",
      "confidence  :  confid\n",
      "measures  :  measur\n",
      "we  :  we\n",
      "give  :  give\n",
      "overview  :  overview\n",
      "application  :  applic\n",
      "confidence  :  confid\n",
      "estimation  :  estim\n",
      "various  :  variou\n",
      "fields  :  field\n",
      "n  :  n\n",
      "  :  \n",
      "  :  \n",
      "lex  :  lex\n",
      "sign  :  sign\n",
      "sense  :  sens\n",
      "id  :  id\n",
      "sense  :  sens\n",
      "id  :  id\n",
      "dictionary  :  dictionari\n",
      "ldoce  :  ldoce\n",
      "lex  :  lex\n",
      "sign  :  sign\n",
      "sense  :  sens\n",
      "id  :  id\n",
      "sense  :  sens\n",
      "id  :  id\n",
      "ldb  :  ldb\n",
      "entry  :  entri\n",
      "12364  :  12364\n",
      "lex  :  lex\n",
      "sign  :  sign\n",
      "sense  :  sens\n",
      "id  :  id\n",
      "sense  :  sens\n",
      "id  :  id\n",
      "sense  :  sens\n",
      "0  :  0\n",
      "when  :  when\n",
      "loaded  :  load\n",
      "lkb  :  lkb\n",
      "9  :  9\n",
      "expanded  :  expand\n",
      "fully  :  fulli\n",
      "fledged  :  fledg\n",
      "representation  :  represent\n",
      "transitive  :  transit\n",
      "use  :  use\n",
      "e  :  e\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "describe  :  describ\n",
      "design  :  design\n",
      "use  :  use\n",
      "stanford  :  stanford\n",
      "corenlp  :  corenlp\n",
      "toolkit  :  toolkit\n",
      "extensible  :  extens\n",
      "pipeline  :  pipelin\n",
      "provides  :  provid\n",
      "core  :  core\n",
      "natural  :  natur\n",
      "lan  :  lan\n",
      "guage  :  guag\n",
      "analysis  :  analysi\n",
      "this  :  thi\n",
      "toolkit  :  toolkit\n",
      "quite  :  quit\n",
      "widely  :  wide\n",
      "used  :  use\n",
      "research  :  research\n",
      "nlp  :  nlp\n",
      "community  :  commun\n",
      "also  :  also\n",
      "among  :  among\n",
      "commercial  :  commerci\n",
      "govern  :  govern\n",
      "ment  :  ment\n",
      "users  :  user\n",
      "open  :  open\n",
      "source  :  sourc\n",
      "nlp  :  nlp\n",
      "technol  :  technol\n",
      "ogy  :  ogi\n",
      "we  :  we\n",
      "suggest  :  suggest\n",
      "  :  \n",
      "  :  \n",
      "gaussian  :  gaussian\n",
      "processes  :  process\n",
      "gps  :  gp\n",
      "powerful  :  power\n",
      "mod  :  mod\n",
      "elling  :  ell\n",
      "framework  :  framework\n",
      "incorporating  :  incorpor\n",
      "kernels  :  kernel\n",
      "bayesian  :  bayesian\n",
      "inference  :  infer\n",
      "recognised  :  recognis\n",
      "state  :  state\n",
      "art  :  art\n",
      "many  :  mani\n",
      "machine  :  machin\n",
      "learning  :  learn\n",
      "tasks  :  task\n",
      "  :  \n",
      "  :  \n",
      "a  :  a\n",
      "fundamental  :  fundament\n",
      "issue  :  issu\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "prerequisite  :  prerequisit\n",
      "enormous  :  enorm\n",
      "quantity  :  quantiti\n",
      "preprogrammed  :  preprogram\n",
      "knowledge  :  knowledg\n",
      "concerning  :  concern\n",
      "language  :  languag\n",
      "domain  :  domain\n",
      "examination  :  examin\n",
      "manual  :  manual\n",
      "acquisition  :  acquisit\n",
      "knowledge  :  knowledg\n",
      "tedious  :  tediou\n",
      "error  :  error\n",
      "prone  :  prone\n",
      "development  :  develop\n",
      "automated  :  autom\n",
      "acquisition  :  acquisit\n",
      "process  :  process\n",
      "  :  \n",
      "  :  \n",
      "a  :  a\n",
      "general  :  gener\n",
      "reusable  :  reusabl\n",
      "computational  :  comput\n",
      "resource  :  resourc\n",
      "de  :  de\n",
      "veloped  :  velop\n",
      "within  :  within\n",
      "penman  :  penman\n",
      "text  :  text\n",
      "generation  :  gener\n",
      "project  :  project\n",
      "organizing  :  organ\n",
      "domain  :  domain\n",
      "knowledge  :  knowledg\n",
      "appropriately  :  appropri\n",
      "linguistic  :  linguist\n",
      "realization  :  realiz\n",
      "this  :  thi\n",
      "resource  :  resourc\n",
      "called  :  call\n",
      "upper  :  upper\n",
      "model  :  model\n",
      "provides  :  provid\n",
      "domain  :  domain\n",
      "task  :  task\n",
      "independent  :  independ\n",
      "classification  :  classif\n",
      "system  :  system\n",
      "supports  :  support\n",
      "  :  \n",
      "  :  \n",
      "kohonen  :  kohonen\n",
      "self  :  self\n",
      "organizing  :  organ\n",
      "map  :  map\n",
      "som  :  som\n",
      "one  :  one\n",
      "popular  :  popular\n",
      "artificial  :  artifici\n",
      "neural  :  neural\n",
      "network  :  network\n",
      "algorithms  :  algorithm\n",
      "word  :  word\n",
      "category  :  categori\n",
      "maps  :  map\n",
      "soms  :  som\n",
      "organized  :  organ\n",
      "according  :  accord\n",
      "word  :  word\n",
      "similarities  :  similar\n",
      "measured  :  measur\n",
      "similarity  :  similar\n",
      "short  :  short\n",
      "contexts  :  context\n",
      "words  :  word\n",
      "conceptually  :  conceptu\n",
      "interrelated  :  interrel\n",
      "words  :  word\n",
      "tend  :  tend\n",
      "fall  :  fall\n",
      "  :  \n",
      "  :  \n",
      "this  :  thi\n",
      "paper  :  paper\n",
      "presents  :  present\n",
      "workbench  :  workbench\n",
      "built  :  built\n",
      "priberam  :  priberam\n",
      "informática  :  informática\n",
      "development  :  develop\n",
      "company  :  compani\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "technology  :  technolog\n",
      "this  :  thi\n",
      "workbench  :  workbench\n",
      "includes  :  includ\n",
      "set  :  set\n",
      "linguistic  :  linguist\n",
      "resources  :  resourc\n",
      "software  :  softwar\n",
      "tools  :  tool\n",
      "applied  :  appli\n",
      "considerable  :  consider\n",
      "number  :  number\n",
      "practical  :  practic\n",
      "purposes  :  purpos\n",
      "covering  :  cover\n",
      "proofing  :  proof\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "effective  :  effect\n",
      "approach  :  approach\n",
      "bringing  :  bring\n",
      "improvement  :  improv\n",
      "educational  :  educ\n",
      "setting  :  set\n",
      "implementing  :  implement\n",
      "nlp  :  nlp\n",
      "involves  :  involv\n",
      "initiating  :  initi\n",
      "process  :  process\n",
      "learning  :  learn\n",
      "natural  :  natur\n",
      "acquisition  :  acquisit\n",
      "educational  :  educ\n",
      "systems  :  system\n",
      "it  :  it\n",
      "based  :  base\n",
      "effective  :  effect\n",
      "approaches  :  approach\n",
      "providing  :  provid\n",
      "solution  :  solut\n",
      "f  :  f\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "after  :  after\n",
      "twenty  :  twenti\n",
      "years  :  year\n",
      "disfavor  :  disfavor\n",
      "technology  :  technolog\n",
      "returned  :  return\n",
      "imitates  :  imit\n",
      "processes  :  process\n",
      "brain  :  brain\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "experiments  :  experi\n",
      "sejnowski  :  sejnowski\n",
      "rosenberg  :  rosenberg\n",
      "1986  :  1986\n",
      "demonstrate  :  demonstr\n",
      "neural  :  neural\n",
      "network  :  network\n",
      "computing  :  comput\n",
      "architecture  :  architectur\n",
      "learn  :  learn\n",
      "actual  :  actual\n",
      "spoken  :  spoken\n",
      "language  :  languag\n",
      "observe  :  observ\n",
      "rules  :  rule\n",
      "pronunciation  :  pronunci\n",
      "  :  \n",
      "  :  \n",
      "text  :  text\n",
      "statistics  :  statist\n",
      "frequently  :  frequent\n",
      "used  :  use\n",
      "stylometry  :  stylometri\n",
      "cryptography  :  cryptographi\n",
      "studies  :  studi\n",
      "in  :  in\n",
      "paper  :  paper\n",
      "text  :  text\n",
      "statistics  :  statist\n",
      "tools  :  tool\n",
      "developed  :  develop\n",
      "iso  :  iso\n",
      "prolog  :  prolog\n",
      "natural  :  natur\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language  :  languag\n",
      "processing  :  process\n",
      "details  :  detail\n",
      "given  :  given\n",
      "usage  :  usag\n",
      "21  :  21\n",
      "user  :  user\n",
      "callable  :  callabl\n",
      "predicates  :  predic\n",
      "logic  :  logic\n",
      "limitations  :  limit\n",
      "program  :  program\n",
      "also  :  also\n",
      "discussed  :  discuss\n",
      "1  :  1\n",
      "  :  \n",
      "  :  \n",
      "we  :  we\n",
      "summarize  :  summar\n",
      "experience  :  experi\n",
      "using  :  use\n",
      "framenet  :  framenet\n",
      "two  :  two\n",
      "rather  :  rather\n",
      "different  :  differ\n",
      "projects  :  project\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "we  :  we\n",
      "conclude  :  conclud\n",
      "nlp  :  nlp\n",
      "benefit  :  benefit\n",
      "framenet  :  framenet\n",
      "different  :  differ\n",
      "ways  :  way\n",
      "sketch  :  sketch\n",
      "problems  :  problem\n",
      "need  :  need\n",
      "overcome  :  overcom\n",
      "1  :  1\n",
      "  :  \n",
      "  :  \n",
      "research  :  research\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "recent  :  recent\n",
      "years  :  year\n",
      "benefited  :  benefit\n",
      "enormous  :  enorm\n",
      "amount  :  amount\n",
      "raw  :  raw\n",
      "textual  :  textual\n",
      "data  :  data\n",
      "available  :  avail\n",
      "world  :  world\n",
      "wide  :  wide\n",
      "web  :  web\n",
      "the  :  the\n",
      "presence  :  presenc\n",
      "standard  :  standard\n",
      "search  :  search\n",
      "engines  :  engin\n",
      "made  :  made\n",
      "data  :  data\n",
      "accessible  :  access\n",
      "computational  :  comput\n",
      "linguists  :  linguist\n",
      "corpus  :  corpu\n",
      "size  :  size\n",
      "never  :  never\n",
      "existed  :  exist\n",
      "befo  :  befo\n",
      "  :  \n",
      "  :  \n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "nlp  :  nlp\n",
      "programs  :  program\n",
      "confronted  :  confront\n",
      "various  :  variou\n",
      "di  :  di\n",
      "culties  :  culti\n",
      "processing  :  process\n",
      "html  :  html\n",
      "xml  :  xml\n",
      "documents  :  document\n",
      "potential  :  potenti\n",
      "produce  :  produc\n",
      "better  :  better\n",
      "results  :  result\n",
      "linguistic  :  linguist\n",
      "information  :  inform\n",
      "annotated  :  annot\n",
      "source  :  sourc\n",
      "texts  :  text\n",
      "wehave  :  wehav\n",
      "therefore  :  therefor\n",
      "developed  :  develop\n",
      "linguistic  :  linguist\n",
      "annotation  :  annot\n",
      "language  :  languag\n",
      "lal  :  lal\n",
      "  :  \n",
      "  :  \n",
      "introduction  :  introduct\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "appears  :  appear\n",
      "surface  :  surfac\n",
      "strongly  :  strongli\n",
      "symbolic  :  symbol\n",
      "activity  :  activ\n",
      "words  :  word\n",
      "symbols  :  symbol\n",
      "stand  :  stand\n",
      "objects  :  object\n",
      "concepts  :  concept\n",
      "real  :  real\n",
      "world  :  world\n",
      "put  :  put\n",
      "together  :  togeth\n",
      "sentences  :  sentenc\n",
      "obey  :  obey\n",
      "well  :  well\n",
      "specified  :  specifi\n",
      "grammar  :  grammar\n",
      "rules  :  rule\n",
      "it  :  it\n",
      "surprise  :  surpris\n",
      "several  :  sever\n",
      "decades  :  decad\n",
      "na  :  na\n",
      "  :  \n",
      "  :  \n",
      "abstract  :  abstract\n",
      "diff  :  diff\n",
      "software  :  softwar\n",
      "program  :  program\n",
      "detects  :  detect\n",
      "differences  :  differ\n",
      "two  :  two\n",
      "data  :  data\n",
      "sets  :  set\n",
      "useful  :  use\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "this  :  thi\n",
      "paper  :  paper\n",
      "shows  :  show\n",
      "several  :  sever\n",
      "examples  :  exampl\n",
      "application  :  applic\n",
      "diff  :  diff\n",
      "they  :  they\n",
      "include  :  includ\n",
      "detection  :  detect\n",
      "differences  :  differ\n",
      "two  :  two\n",
      "different  :  differ\n",
      "datasets  :  dataset\n",
      "extraction  :  extract\n",
      "rewriting  :  rewrit\n",
      "rules  :  rule\n",
      "mer  :  mer\n",
      "  :  \n",
      "  :  \n",
      "in  :  in\n",
      "paper  :  paper\n",
      "present  :  present\n",
      "compare  :  compar\n",
      "automatically  :  automat\n",
      "generated  :  gener\n",
      "titles  :  titl\n",
      "machine  :  machin\n",
      "translated  :  translat\n",
      "documents  :  document\n",
      "using  :  use\n",
      "several  :  sever\n",
      "different  :  differ\n",
      "statistics  :  statist\n",
      "based  :  base\n",
      "methods  :  method\n",
      "a  :  a\n",
      "naïve  :  naïv\n",
      "bayesian  :  bayesian\n",
      "k  :  k\n",
      "nearest  :  nearest\n",
      "neighbour  :  neighbour\n",
      "tf  :  tf\n",
      "idf  :  idf\n",
      "erative  :  er\n",
      "expectation  :  expect\n",
      "maximization  :  maxim\n",
      "method  :  method\n",
      "title  :  titl\n",
      "gen  :  gen\n",
      "eration  :  erat\n",
      "applied  :  appli\n",
      "1000  :  1000\n",
      "origi  :  origi\n",
      "  :  \n",
      "  :  \n",
      "9  :  9\n",
      "bibliography  :  bibliographi\n",
      "  :  \n",
      "  :  \n",
      "applying  :  appli\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "processing  :  process\n",
      "techniques  :  techniqu\n",
      "biomedical  :  biomed\n",
      "text  :  text\n",
      "potential  :  potenti\n",
      "aid  :  aid\n",
      "curation  :  curat\n",
      "become  :  becom\n",
      "focus  :  focu\n",
      "intensive  :  intens\n",
      "research  :  research\n",
      "however  :  howev\n",
      "developing  :  develop\n",
      "integrated  :  integr\n",
      "systems  :  system\n",
      "address  :  address\n",
      "curators  :  curat\n",
      "real  :  real\n",
      "world  :  world\n",
      "needs  :  need\n",
      "studied  :  studi\n",
      "less  :  less\n",
      "rigorously  :  rigor\n",
      "this  :  thi\n",
      "paper  :  paper\n",
      "addresses  :  address\n",
      "question  :  question\n",
      "  :  \n",
      "  :  \n",
      "examples  :  exampl\n",
      "natural  :  natur\n",
      "languages  :  languag\n",
      "chinese  :  chines\n",
      "english  :  english\n",
      "italian  :  italian\n",
      "they  :  they\n",
      "called  :  call\n",
      "natural  :  natur\n",
      "evolved  :  evolv\n",
      "less  :  less\n",
      "natural  :  natur\n",
      "way  :  way\n",
      "without  :  without\n",
      "many  :  mani\n",
      "deliberate  :  deliber\n",
      "considerations  :  consider\n",
      "this  :  thi\n",
      "sets  :  set\n",
      "apart  :  apart\n",
      "formal  :  formal\n",
      "languages  :  languag\n",
      "amongst  :  amongst\n",
      "programming  :  program\n",
      "languages  :  languag\n",
      "designed  :  design\n",
      "  :  \n",
      "  :  \n",
      "a  :  a\n",
      "number  :  number\n",
      "powerful  :  power\n",
      "modelling  :  model\n",
      "techniques  :  techniqu\n",
      "developed  :  develop\n",
      "recent  :  recent\n",
      "years  :  year\n",
      "compress  :  compress\n",
      "natural  :  natur\n",
      "language  :  languag\n",
      "text  :  text\n",
      "the  :  the\n",
      "best  :  best\n",
      "adaptive  :  adapt\n",
      "models  :  model\n",
      "operating  :  oper\n",
      "character  :  charact\n",
      "word  :  word\n",
      "level  :  level\n",
      "able  :  abl\n",
      "perform  :  perform\n",
      "almost  :  almost\n",
      "well  :  well\n",
      "humans  :  human\n",
      "predicting  :  predict\n",
      "text  :  text\n",
      "we  :  we\n",
      "show  :  show\n",
      "apply  :  appli\n",
      "character  :  charact\n",
      "based  :  base\n",
      "  :  \n",
      "  :  \n",
      "a  :  a\n",
      "semi  :  semi\n",
      "automated  :  autom\n",
      "approach  :  approach\n",
      "design  :  design\n",
      "databases  :  databas\n",
      "enhanced  :  enhanc\n",
      "erd  :  erd\n",
      "notation  :  notat\n",
      "presented  :  present\n",
      "it  :  it\n",
      "focuses  :  focus\n",
      "early  :  earli\n",
      "stage  :  stage\n",
      "database  :  databas\n",
      "development  :  develop\n",
      "stage  :  stage\n",
      "user  :  user\n",
      "requirement  :  requir\n",
      "analysis  :  analysi\n",
      "it  :  it\n",
      "supposed  :  suppos\n",
      "used  :  use\n",
      "requirements  :  requir\n",
      "determination  :  determin\n",
      "stage  :  stage\n",
      "analysis  :  analysi\n",
      "the  :  the\n",
      "approa  :  approa\n",
      "  :  \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "p = PorterStemmer() \n",
    "for i in q1:\n",
    "  for j in i: \n",
    "    print(j, \" : \", p.stem(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "introduction\n",
      "statistical\n",
      "natural\n",
      "language\n",
      "processing\n",
      "snlp\n",
      "field\n",
      "lying\n",
      "intersection\n",
      "natural\n",
      "language\n",
      "processing\n",
      "machine\n",
      "learning\n",
      "snlp\n",
      "di\n",
      "er\n",
      "traditional\n",
      "natural\n",
      "language\n",
      "processing\n",
      "instead\n",
      "linguist\n",
      "manually\n",
      "construct\n",
      "model\n",
      "given\n",
      "linguistic\n",
      "\n",
      "\n",
      "the\n",
      "paper\n",
      "summarizes\n",
      "essential\n",
      "property\n",
      "document\n",
      "retrieval\n",
      "review\n",
      "conventional\n",
      "practice\n",
      "research\n",
      "finding\n",
      "latter\n",
      "suggesting\n",
      "simple\n",
      "statistical\n",
      "technique\n",
      "effective\n",
      "it\n",
      "considers\n",
      "new\n",
      "opportunity\n",
      "challenge\n",
      "presented\n",
      "ability\n",
      "search\n",
      "full\n",
      "\n",
      "\n",
      "abstract\n",
      "language\n",
      "way\n",
      "communicating\n",
      "word\n",
      "language\n",
      "help\n",
      "understanding\n",
      "world\n",
      "get\n",
      "better\n",
      "insight\n",
      "world\n",
      "language\n",
      "help\n",
      "speaker\n",
      "vague\n",
      "precise\n",
      "like\n",
      "nlp\n",
      "stand\n",
      "natural\n",
      "language\n",
      "processing\n",
      "natural\n",
      "language\n",
      "language\n",
      "spoken\n",
      "\n",
      "\n",
      "we\n",
      "report\n",
      "experiment\n",
      "use\n",
      "standard\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "tool\n",
      "analysis\n",
      "music\n",
      "lyric\n",
      "a\n",
      "significant\n",
      "amount\n",
      "music\n",
      "audio\n",
      "lyric\n",
      "lyric\n",
      "encode\n",
      "important\n",
      "part\n",
      "semantics\n",
      "song\n",
      "therefore\n",
      "analysis\n",
      "complement\n",
      "acoustic\n",
      "cultural\n",
      "metada\n",
      "\n",
      "\n",
      "paper\n",
      "describe\n",
      "simple\n",
      "rule\n",
      "based\n",
      "approach\n",
      "automated\n",
      "learning\n",
      "linguistic\n",
      "knowledge\n",
      "this\n",
      "approach\n",
      "shown\n",
      "number\n",
      "task\n",
      "capture\n",
      "information\n",
      "clearer\n",
      "direct\n",
      "fashion\n",
      "without\n",
      "compromise\n",
      "performance\n",
      "we\n",
      "present\n",
      "detailed\n",
      "case\n",
      "study\n",
      "learni\n",
      "\n",
      "\n",
      "this\n",
      "paper\n",
      "focus\n",
      "connectionist\n",
      "model\n",
      "natural\n",
      "language\n",
      "processing\n",
      "we\n",
      "briefly\n",
      "present\n",
      "discus\n",
      "several\n",
      "aspect\n",
      "high\n",
      "level\n",
      "task\n",
      "recently\n",
      "approached\n",
      "connectionism\n",
      "either\n",
      "localist\n",
      "parallel\n",
      "distributed\n",
      "processing\n",
      "model\n",
      "several\n",
      "interesting\n",
      "architecture\n",
      "\n",
      "\n",
      "abstract\n",
      "the\n",
      "article\n",
      "explores\n",
      "possibility\n",
      "construct\n",
      "unified\n",
      "word\n",
      "feature\n",
      "component\n",
      "feature\n",
      "letter\n",
      "each\n",
      "letter\n",
      "modeled\n",
      "different\n",
      "attractor\n",
      "finally\n",
      "embedded\n",
      "quadratic\n",
      "iterated\n",
      "map\n",
      "the\n",
      "result\n",
      "word\n",
      "feature\n",
      "account\n",
      "meaning\n",
      "extraction\n",
      "pr\n",
      "\n",
      "\n",
      "paper\n",
      "see\n",
      "schank\n",
      "86\n",
      "theoretical\n",
      "discussion\n",
      "ka\n",
      "86\n",
      "leake\n",
      "owen\n",
      "86\n",
      "brief\n",
      "discussion\n",
      "program\n",
      "built\n",
      "around\n",
      "principle\n",
      "goal\n",
      "simply\n",
      "point\n",
      "interest\n",
      "natural\n",
      "language\n",
      "processing\n",
      "led\n",
      "u\n",
      "naturally\n",
      "indeed\n",
      "inevitably\n",
      "de\n",
      "\n",
      "\n",
      "objective\n",
      "to\n",
      "provide\n",
      "overview\n",
      "tutorial\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "modern\n",
      "nlp\n",
      "system\n",
      "design\n",
      "target\n",
      "audience\n",
      "this\n",
      "tutorial\n",
      "target\n",
      "medical\n",
      "informatics\n",
      "generalist\n",
      "limited\n",
      "acquaintance\n",
      "principle\n",
      "behind\n",
      "nlp\n",
      "limited\n",
      "knowledge\n",
      "current\n",
      "state\n",
      "\n",
      "\n",
      "this\n",
      "paper\n",
      "briefly\n",
      "describes\n",
      "current\n",
      "implementation\n",
      "status\n",
      "intelligent\n",
      "information\n",
      "retrieval\n",
      "system\n",
      "marie\n",
      "employ\n",
      "natural\n",
      "language\n",
      "processing\n",
      "technique\n",
      "descriptive\n",
      "caption\n",
      "used\n",
      "iden\n",
      "tify\n",
      "photographic\n",
      "image\n",
      "concerning\n",
      "various\n",
      "military\n",
      "project\n",
      "the\n",
      "caption\n",
      "parsed\n",
      "\n",
      "\n",
      "abstract\n",
      "metabolism\n",
      "machinery\n",
      "life\n",
      "signal\n",
      "transduction\n",
      "provides\n",
      "regulatory\n",
      "mechanism\n",
      "control\n",
      "machinery\n",
      "due\n",
      "complexity\n",
      "signal\n",
      "transduction\n",
      "pathway\n",
      "computational\n",
      "approach\n",
      "needed\n",
      "aid\n",
      "biologist\n",
      "integrating\n",
      "available\n",
      "knowledge\n",
      "formulatio\n",
      "\n",
      "\n",
      "this\n",
      "report\n",
      "present\n",
      "detailed\n",
      "analysis\n",
      "review\n",
      "nlp\n",
      "evaluation\n",
      "principle\n",
      "practice\n",
      "part\n",
      "1\n",
      "examines\n",
      "evaluation\n",
      "concept\n",
      "establishes\n",
      "framework\n",
      "nlp\n",
      "system\n",
      "evaluation\n",
      "this\n",
      "make\n",
      "use\n",
      "experience\n",
      "related\n",
      "area\n",
      "information\n",
      "retrieval\n",
      "analysis\n",
      "also\n",
      "refers\n",
      "ev\n",
      "\n",
      "\n",
      "web\n",
      "emerged\n",
      "important\n",
      "source\n",
      "information\n",
      "world\n",
      "this\n",
      "resulted\n",
      "need\n",
      "automated\n",
      "software\n",
      "component\n",
      "analyze\n",
      "web\n",
      "page\n",
      "harvest\n",
      "useful\n",
      "information\n",
      "however\n",
      "typical\n",
      "web\n",
      "page\n",
      "informative\n",
      "content\n",
      "surrounded\n",
      "high\n",
      "degree\n",
      "noise\n",
      "\n",
      "\n",
      "abstract\n",
      "natural\n",
      "language\n",
      "processing\n",
      "theoretically\n",
      "motivated\n",
      "range\n",
      "computational\n",
      "technique\n",
      "analysing\n",
      "representing\n",
      "naturally\n",
      "occurring\n",
      "text\n",
      "one\n",
      "level\n",
      "linguistic\n",
      "analysis\n",
      "purpose\n",
      "achieving\n",
      "human\n",
      "like\n",
      "language\n",
      "processing\n",
      "range\n",
      "task\n",
      "application\n",
      "\n",
      "\n",
      "this\n",
      "paper\n",
      "review\n",
      "process\n",
      "involved\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "it\n",
      "demonstrates\n",
      "various\n",
      "kind\n",
      "choice\n",
      "need\n",
      "taken\n",
      "execution\n",
      "word\n",
      "morphology\n",
      "syntactic\n",
      "text\n",
      "analysis\n",
      "text\n",
      "generation\n",
      "component\n",
      "it\n",
      "compare\n",
      "time\n",
      "complexity\n",
      "traditional\n",
      "\n",
      "\n",
      "this\n",
      "article\n",
      "focus\n",
      "derivation\n",
      "large\n",
      "lexicon\n",
      "natural\n",
      "language\n",
      "processing\n",
      "we\n",
      "describe\n",
      "development\n",
      "dictionary\n",
      "support\n",
      "environment\n",
      "linking\n",
      "restructured\n",
      "version\n",
      "longman\n",
      "dictionary\n",
      "contemporary\n",
      "english\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      "the\n",
      "process\n",
      "restruc\n",
      "\n",
      "\n",
      "we\n",
      "introduce\n",
      "method\n",
      "analyzing\n",
      "complexity\n",
      "natural\n",
      "language\n",
      "processing\n",
      "task\n",
      "predicting\n",
      "difficulty\n",
      "new\n",
      "nlp\n",
      "task\n",
      "our\n",
      "complexity\n",
      "measure\n",
      "derived\n",
      "kolmogorov\n",
      "complexity\n",
      "class\n",
      "automaton\n",
      "meaning\n",
      "automaton\n",
      "whose\n",
      "purpose\n",
      "extract\n",
      "relevant\n",
      "piece\n",
      "infor\n",
      "\n",
      "\n",
      "deep\n",
      "learning\n",
      "emerged\n",
      "new\n",
      "area\n",
      "machine\n",
      "learning\n",
      "research\n",
      "it\n",
      "try\n",
      "mimic\n",
      "human\n",
      "brain\n",
      "capable\n",
      "processing\n",
      "learning\n",
      "complex\n",
      "input\n",
      "data\n",
      "solving\n",
      "different\n",
      "kind\n",
      "complicated\n",
      "task\n",
      "well\n",
      "it\n",
      "successfully\n",
      "applied\n",
      "several\n",
      "field\n",
      "image\n",
      "\n",
      "\n",
      "this\n",
      "author\n",
      "produced\n",
      "version\n",
      "paper\n",
      "published\n",
      "the\n",
      "\n",
      "\n",
      "abstract\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "application\n",
      "automated\n",
      "parsing\n",
      "machine\n",
      "learning\n",
      "technique\n",
      "analyze\n",
      "standard\n",
      "text\n",
      "application\n",
      "nlp\n",
      "requirement\n",
      "engineering\n",
      "include\n",
      "extraction\n",
      "ontology\n",
      "requirement\n",
      "specification\n",
      "use\n",
      "nlp\n",
      "verify\n",
      "consistency\n",
      "\n",
      "\n",
      "information\n",
      "retrieval\n",
      "address\n",
      "problem\n",
      "finding\n",
      "document\n",
      "whose\n",
      "content\n",
      "match\n",
      "user\n",
      "request\n",
      "among\n",
      "large\n",
      "collection\n",
      "document\n",
      "currently\n",
      "successful\n",
      "general\n",
      "purpose\n",
      "retrieval\n",
      "method\n",
      "statistical\n",
      "method\n",
      "treat\n",
      "text\n",
      "little\n",
      "bag\n",
      "w\n",
      "\n",
      "\n",
      "work\n",
      "computational\n",
      "linguistics\n",
      "began\n",
      "soon\n",
      "development\n",
      "first\n",
      "computer\n",
      "booth\n",
      "brandwood\n",
      "cleave\n",
      "1958\n",
      "yet\n",
      "intervening\n",
      "four\n",
      "decade\n",
      "pervasive\n",
      "feeling\n",
      "progress\n",
      "computer\n",
      "understanding\n",
      "natural\n",
      "language\n",
      "commensurate\n",
      "progres\n",
      "\n",
      "\n",
      "abstract\n",
      "a\n",
      "system\n",
      "recognizes\n",
      "authenticates\n",
      "voice\n",
      "user\n",
      "extracting\n",
      "distinct\n",
      "feature\n",
      "voice\n",
      "sample\n",
      "usually\n",
      "termed\n",
      "voice\n",
      "recognition\n",
      "system\n",
      "voice\n",
      "identification\n",
      "carried\n",
      "converting\n",
      "human\n",
      "voice\n",
      "digital\n",
      "data\n",
      "the\n",
      "digitized\n",
      "audio\n",
      "sample\n",
      "unde\n",
      "\n",
      "\n",
      "abstract\n",
      "testing\n",
      "natural\n",
      "language\n",
      "requirement\n",
      "standard\n",
      "approach\n",
      "system\n",
      "acceptance\n",
      "testing\n",
      "this\n",
      "test\n",
      "often\n",
      "performed\n",
      "independent\n",
      "test\n",
      "organization\n",
      "unfamiliar\n",
      "application\n",
      "area\n",
      "the\n",
      "thing\n",
      "tester\n",
      "go\n",
      "written\n",
      "requirement\n",
      "so\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "algorithm\n",
      "allow\n",
      "understanding\n",
      "generation\n",
      "humor\n",
      "there\n",
      "general\n",
      "aim\n",
      "modeling\n",
      "humor\n",
      "provide\n",
      "u\n",
      "lot\n",
      "information\n",
      "cognitive\n",
      "ability\n",
      "general\n",
      "reasoning\n",
      "remembering\n",
      "understanding\n",
      "situation\n",
      "understanding\n",
      "conversati\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "in\n",
      "recent\n",
      "year\n",
      "machine\n",
      "learning\n",
      "ml\n",
      "used\n",
      "solve\n",
      "complex\n",
      "task\n",
      "different\n",
      "discipline\n",
      "ranging\n",
      "data\n",
      "mining\n",
      "information\n",
      "\n",
      "\n",
      "we\n",
      "argue\n",
      "manual\n",
      "automatic\n",
      "thesaurus\n",
      "alternative\n",
      "resource\n",
      "nlp\n",
      "task\n",
      "this\n",
      "involves\n",
      "radical\n",
      "step\n",
      "interpreting\n",
      "manual\n",
      "thesaurus\n",
      "classification\n",
      "word\n",
      "rather\n",
      "word\n",
      "sens\n",
      "case\n",
      "made\n",
      "the\n",
      "range\n",
      "role\n",
      "thesaurus\n",
      "within\n",
      "nlp\n",
      "briefly\n",
      "\n",
      "\n",
      "introduction\n",
      "pattern\n",
      "music\n",
      "object\n",
      "intensive\n",
      "study\n",
      "past\n",
      "year\n",
      "one\n",
      "purpose\n",
      "analyzing\n",
      "musical\n",
      "structure\n",
      "form\n",
      "discover\n",
      "pattern\n",
      "explicit\n",
      "implicit\n",
      "musical\n",
      "work\n",
      "simon\n",
      "13\n",
      "pattern\n",
      "comprise\n",
      "periodicity\n",
      "make\n",
      "use\n",
      "alphabet\n",
      "\n",
      "\n",
      "abstract\n",
      "many\n",
      "information\n",
      "retrieval\n",
      "ir\n",
      "system\n",
      "retrieve\n",
      "relevant\n",
      "document\n",
      "based\n",
      "exact\n",
      "matching\n",
      "keywords\n",
      "query\n",
      "document\n",
      "this\n",
      "method\n",
      "degrades\n",
      "precision\n",
      "rate\n",
      "in\n",
      "order\n",
      "solve\n",
      "problem\n",
      "collected\n",
      "semantically\n",
      "related\n",
      "word\n",
      "assigned\n",
      "semantic\n",
      "relationship\n",
      "used\n",
      "gener\n",
      "\n",
      "\n",
      "paper\n",
      "argue\n",
      "questionanswering\n",
      "qa\n",
      "technical\n",
      "domain\n",
      "distinctly\n",
      "different\n",
      "trec\n",
      "based\n",
      "qa\n",
      "web\n",
      "based\n",
      "qa\n",
      "cannot\n",
      "benefit\n",
      "lom\n",
      "data\n",
      "intensive\n",
      "approach\n",
      "\n",
      "\n",
      "universit\n",
      "quot\n",
      "de\n",
      "saarlandes\n",
      "\n",
      "\n",
      "proceeding\n",
      "workshop\n",
      "\n",
      "\n",
      "uni\n",
      "hamburg\n",
      "de\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "6\n",
      "\n",
      "\n",
      "sri\n",
      "developed\n",
      "new\n",
      "architecture\n",
      "integrating\n",
      "speech\n",
      "natural\n",
      "language\n",
      "processing\n",
      "applies\n",
      "linguistic\n",
      "constraint\n",
      "recognition\n",
      "incrementally\n",
      "expanding\n",
      "state\n",
      "transition\n",
      "network\n",
      "embodied\n",
      "unification\n",
      "grammar\n",
      "we\n",
      "compare\n",
      "dynamic\n",
      "gralnlnar\n",
      "network\n",
      "dgn\n",
      "approach\n",
      "\n",
      "\n",
      "this\n",
      "chapter\n",
      "considers\n",
      "revolution\n",
      "taken\n",
      "place\n",
      "natural\n",
      "language\n",
      "processing\n",
      "research\n",
      "last\n",
      "five\n",
      "year\n",
      "it\n",
      "begin\n",
      "providing\n",
      "brief\n",
      "guide\n",
      "structure\n",
      "field\n",
      "present\n",
      "caricature\n",
      "two\n",
      "competing\n",
      "paradigm\n",
      "1980s\n",
      "nlp\n",
      "research\n",
      "indicates\n",
      "reason\n",
      "wh\n",
      "\n",
      "\n",
      "visual\n",
      "development\n",
      "environment\n",
      "support\n",
      "visual\n",
      "assembly\n",
      "execution\n",
      "analysis\n",
      "modular\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      "the\n",
      "visual\n",
      "model\n",
      "executable\n",
      "data\n",
      "flow\n",
      "program\n",
      "graph\n",
      "automatically\n",
      "synthesised\n",
      "data\n",
      "dependency\n",
      "declaration\n",
      "language\n",
      "processing\n",
      "module\n",
      "the\n",
      "graph\n",
      "th\n",
      "\n",
      "\n",
      "in\n",
      "chapter\n",
      "basic\n",
      "us\n",
      "description\n",
      "logic\n",
      "natural\n",
      "language\n",
      "processing\n",
      "analysed\n",
      "together\n",
      "little\n",
      "bit\n",
      "history\n",
      "role\n",
      "description\n",
      "logic\n",
      "current\n",
      "state\n",
      "art\n",
      "computational\n",
      "linguistics\n",
      "pointed\n",
      "18\n",
      "1\n",
      "introduction\n",
      "since\n",
      "early\n",
      "day\n",
      "\n",
      "\n",
      "we\n",
      "applied\n",
      "structure\n",
      "learning\n",
      "model\n",
      "max\n",
      "margin\n",
      "structure\n",
      "mm\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "task\n",
      "aim\n",
      "capture\n",
      "latent\n",
      "relationship\n",
      "within\n",
      "output\n",
      "language\n",
      "domain\n",
      "we\n",
      "formulate\n",
      "model\n",
      "extension\n",
      "multi\n",
      "class\n",
      "support\n",
      "vector\n",
      "machine\n",
      "svm\n",
      "present\n",
      "per\n",
      "\n",
      "\n",
      "vast\n",
      "quantity\n",
      "text\n",
      "becoming\n",
      "available\n",
      "elec\n",
      "tronic\n",
      "form\n",
      "ranging\n",
      "published\n",
      "document\n",
      "e\n",
      "g\n",
      "electronic\n",
      "dictionary\n",
      "encyclopedia\n",
      "library\n",
      "archive\n",
      "information\n",
      "retrieval\n",
      "service\n",
      "private\n",
      "database\n",
      "e\n",
      "g\n",
      "marketing\n",
      "information\n",
      "legal\n",
      "record\n",
      "medical\n",
      "history\n",
      "per\n",
      "\n",
      "\n",
      "over\n",
      "last\n",
      "year\n",
      "number\n",
      "area\n",
      "natural\n",
      "language\n",
      "processing\n",
      "begun\n",
      "applying\n",
      "graph\n",
      "based\n",
      "technique\n",
      "these\n",
      "include\n",
      "among\n",
      "others\n",
      "text\n",
      "summarization\n",
      "syntactic\n",
      "parsing\n",
      "word\n",
      "sense\n",
      "disambiguation\n",
      "ontology\n",
      "construction\n",
      "sentiment\n",
      "subjectivity\n",
      "analysis\n",
      "text\n",
      "clustering\n",
      "in\n",
      "pa\n",
      "\n",
      "\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "research\n",
      "result\n",
      "software\n",
      "engineering\n",
      "software\n",
      "technology\n",
      "often\n",
      "neglected\n",
      "\n",
      "\n",
      "kernelized\n",
      "sorting\n",
      "approach\n",
      "matching\n",
      "object\n",
      "two\n",
      "source\n",
      "domain\n",
      "require\n",
      "prior\n",
      "notion\n",
      "similarity\n",
      "object\n",
      "across\n",
      "two\n",
      "source\n",
      "unfortunately\n",
      "technique\n",
      "highly\n",
      "sensitive\n",
      "initialization\n",
      "high\n",
      "dimensional\n",
      "data\n",
      "we\n",
      "present\n",
      "variant\n",
      "kern\n",
      "\n",
      "\n",
      "natural\n",
      "language\n",
      "complex\n",
      "compound\n",
      "organization\n",
      "structure\n",
      "basic\n",
      "linguistic\n",
      "element\n",
      "represent\n",
      "various\n",
      "meaning\n",
      "therefore\n",
      "understand\n",
      "nature\n",
      "natural\n",
      "language\n",
      "need\n",
      "sophisticated\n",
      "treatment\n",
      "basic\n",
      "element\n",
      "well\n",
      "insight\n",
      "element\n",
      "\n",
      "\n",
      "in\n",
      "paper\n",
      "describe\n",
      "framework\n",
      "developing\n",
      "probabilistic\n",
      "classifier\n",
      "natural\n",
      "language\n",
      "processing\n",
      "our\n",
      "focus\n",
      "formulating\n",
      "model\n",
      "capture\n",
      "important\n",
      "interdependency\n",
      "among\n",
      "feature\n",
      "avoid\n",
      "overfitting\n",
      "data\n",
      "also\n",
      "characterizing\n",
      "data\n",
      "well\n",
      "the\n",
      "class\n",
      "pro\n",
      "\n",
      "\n",
      "many\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "technique\n",
      "used\n",
      "information\n",
      "retrieval\n",
      "the\n",
      "result\n",
      "encouraging\n",
      "simple\n",
      "method\n",
      "stopwording\n",
      "porter\n",
      "style\n",
      "stemming\n",
      "etc\n",
      "usually\n",
      "yield\n",
      "significant\n",
      "improvement\n",
      "higher\n",
      "level\n",
      "processing\n",
      "chunking\n",
      "parsing\n",
      "word\n",
      "sense\n",
      "disambiguation\n",
      "e\n",
      "\n",
      "\n",
      "abstract\n",
      "this\n",
      "paper\n",
      "explains\n",
      "information\n",
      "retrieval\n",
      "using\n",
      "natural\n",
      "language\n",
      "processing\n",
      "malayalam\n",
      "language\n",
      "basic\n",
      "\n",
      "\n",
      "the\n",
      "research\n",
      "area\n",
      "plan\n",
      "recognition\n",
      "natural\n",
      "language\n",
      "parsing\n",
      "share\n",
      "many\n",
      "common\n",
      "feature\n",
      "even\n",
      "algorithm\n",
      "however\n",
      "dialog\n",
      "two\n",
      "discipline\n",
      "effective\n",
      "specifically\n",
      "significant\n",
      "recent\n",
      "result\n",
      "parsing\n",
      "mildly\n",
      "context\n",
      "sensitive\n",
      "grammar\n",
      "leveraged\n",
      "\n",
      "\n",
      "the\n",
      "research\n",
      "area\n",
      "plan\n",
      "recognition\n",
      "natural\n",
      "language\n",
      "parsing\n",
      "share\n",
      "many\n",
      "common\n",
      "feature\n",
      "even\n",
      "algorithm\n",
      "however\n",
      "dialog\n",
      "two\n",
      "discipline\n",
      "effective\n",
      "specifically\n",
      "significant\n",
      "recent\n",
      "result\n",
      "parsing\n",
      "mildly\n",
      "context\n",
      "sensitive\n",
      "grammar\n",
      "leveraged\n",
      "\n",
      "\n",
      "information\n",
      "retrieval\n",
      "process\n",
      "finding\n",
      "document\n",
      "document\n",
      "collection\n",
      "satisfies\n",
      "information\n",
      "need\n",
      "user\n",
      "the\n",
      "document\n",
      "natural\n",
      "language\n",
      "construct\n",
      "motivation\n",
      "work\n",
      "investigate\n",
      "natural\n",
      "language\n",
      "processing\n",
      "used\n",
      "improve\n",
      "performa\n",
      "\n",
      "\n",
      "while\n",
      "computational\n",
      "logic\n",
      "become\n",
      "widely\n",
      "used\n",
      "representing\n",
      "reasoning\n",
      "linguistic\n",
      "knowledge\n",
      "cross\n",
      "fertilization\n",
      "logic\n",
      "programming\n",
      "machine\n",
      "learning\n",
      "given\n",
      "rise\n",
      "new\n",
      "discipline\n",
      "known\n",
      "inductive\n",
      "logic\n",
      "programming\n",
      "inspired\n",
      "building\n",
      "achievement\n",
      "\n",
      "\n",
      "what\n",
      "statistical\n",
      "method\n",
      "used\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "in\n",
      "paper\n",
      "start\n",
      "definition\n",
      "nlp\n",
      "concerned\n",
      "design\n",
      "implementation\n",
      "effective\n",
      "natural\n",
      "language\n",
      "input\n",
      "output\n",
      "component\n",
      "computational\n",
      "system\n",
      "we\n",
      "distinguish\n",
      "three\n",
      "kind\n",
      "\n",
      "\n",
      "in\n",
      "report\n",
      "collaborative\n",
      "work\n",
      "field\n",
      "machine\n",
      "learning\n",
      "ml\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "presented\n",
      "the\n",
      "document\n",
      "structured\n",
      "two\n",
      "part\n",
      "the\n",
      "first\n",
      "part\n",
      "includes\n",
      "superficial\n",
      "comprehensive\n",
      "survey\n",
      "covering\n",
      "state\n",
      "art\n",
      "machine\n",
      "learning\n",
      "techniq\n",
      "\n",
      "\n",
      "abstract\n",
      "this\n",
      "thesis\n",
      "examines\n",
      "use\n",
      "machine\n",
      "learning\n",
      "technique\n",
      "various\n",
      "task\n",
      "natural\n",
      "language\n",
      "processing\n",
      "mainly\n",
      "task\n",
      "information\n",
      "extraction\n",
      "text\n",
      "the\n",
      "objective\n",
      "improvement\n",
      "adaptability\n",
      "information\n",
      "extraction\n",
      "system\n",
      "new\n",
      "thematic\n",
      "main\n",
      "even\n",
      "lang\n",
      "\n",
      "\n",
      "this\n",
      "chapter\n",
      "examines\n",
      "application\n",
      "natural\n",
      "language\n",
      "processing\n",
      "computerassisted\n",
      "language\n",
      "learning\n",
      "including\n",
      "history\n",
      "work\n",
      "field\n",
      "last\n",
      "thirtyfive\n",
      "year\n",
      "focus\n",
      "current\n",
      "development\n",
      "opportunity\n",
      "36\n",
      "1\n",
      "\n",
      "\n",
      "traditional\n",
      "approach\n",
      "tointerpretation\n",
      "natural\n",
      "language\n",
      "processing\n",
      "typically\n",
      "fall\n",
      "one\n",
      "three\n",
      "class\n",
      "syntax\n",
      "driven\n",
      "semantics\n",
      "driven\n",
      "frame\n",
      "task\n",
      "based\n",
      "syntax\n",
      "driven\n",
      "approach\n",
      "use\n",
      "domain\n",
      "independent\n",
      "grammar\n",
      "drive\n",
      "interpretation\n",
      "process\n",
      "produce\n",
      "global\n",
      "parse\n",
      "input\n",
      "\n",
      "\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "large\n",
      "diverse\n",
      "subtopic\n",
      "artificial\n",
      "intelligence\n",
      "a\n",
      "result\n",
      "nlp\n",
      "many\n",
      "subtopics\n",
      "including\n",
      "optical\n",
      "character\n",
      "recognition\n",
      "text\n",
      "speech\n",
      "translator\n",
      "foreign\n",
      "language\n",
      "reading\n",
      "writing\n",
      "aid\n",
      "machine\n",
      "translation\n",
      "speech\n",
      "recognition\n",
      "w\n",
      "\n",
      "\n",
      "probabilistic\n",
      "finite\n",
      "state\n",
      "string\n",
      "transducer\n",
      "fsts\n",
      "extremely\n",
      "popular\n",
      "natural\n",
      "language\n",
      "processing\n",
      "due\n",
      "powerful\n",
      "generic\n",
      "method\n",
      "applying\n",
      "composing\n",
      "learning\n",
      "unfortunately\n",
      "fsts\n",
      "good\n",
      "fit\n",
      "much\n",
      "current\n",
      "work\n",
      "probabilistic\n",
      "modeling\n",
      "machine\n",
      "translati\n",
      "\n",
      "\n",
      "abstract\n",
      "in\n",
      "special\n",
      "issue\n",
      "tal\n",
      "look\n",
      "fundamental\n",
      "principle\n",
      "underlying\n",
      "evaluation\n",
      "natural\n",
      "language\n",
      "processing\n",
      "we\n",
      "adopt\n",
      "global\n",
      "point\n",
      "view\n",
      "go\n",
      "beyond\n",
      "horizon\n",
      "single\n",
      "evaluation\n",
      "campaign\n",
      "particular\n",
      "protocol\n",
      "after\n",
      "brief\n",
      "review\n",
      "history\n",
      "terminology\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      "nlp\n",
      "extract\n",
      "clinical\n",
      "information\n",
      "textual\n",
      "report\n",
      "shown\n",
      "effective\n",
      "limited\n",
      "domain\n",
      "particular\n",
      "application\n",
      "because\n",
      "nlp\n",
      "system\n",
      "typically\n",
      "requires\n",
      "substantial\n",
      "resource\n",
      "develop\n",
      "beneficial\n",
      "designed\n",
      "easily\n",
      "\n",
      "\n",
      "we\n",
      "propose\n",
      "bifurcated\n",
      "paradigm\n",
      "construction\n",
      "prolog\n",
      "knowl\n",
      "edge\n",
      "base\n",
      "body\n",
      "document\n",
      "first\n",
      "information\n",
      "extraction\n",
      "ie\n",
      "ap\n",
      "plication\n",
      "annotate\n",
      "corpus\n",
      "output\n",
      "annotated\n",
      "document\n",
      "second\n",
      "prolog\n",
      "knowledge\n",
      "base\n",
      "kb\n",
      "application\n",
      "transform\n",
      "th\n",
      "\n",
      "\n",
      "we\n",
      "describe\n",
      "single\n",
      "convolutional\n",
      "neural\n",
      "network\n",
      "architecture\n",
      "given\n",
      "sentence\n",
      "output\n",
      "host\n",
      "language\n",
      "processing\n",
      "prediction\n",
      "part\n",
      "speech\n",
      "tag\n",
      "chunk\n",
      "named\n",
      "entity\n",
      "tag\n",
      "semantic\n",
      "role\n",
      "semantically\n",
      "similar\n",
      "word\n",
      "likelihood\n",
      "sentence\n",
      "make\n",
      "sense\n",
      "grammatically\n",
      "sem\n",
      "\n",
      "\n",
      "we\n",
      "developed\n",
      "prototype\n",
      "information\n",
      "retrieval\n",
      "system\n",
      "us\n",
      "advanced\n",
      "natural\n",
      "language\n",
      "processing\n",
      "technique\n",
      "enhance\n",
      "effectiveness\n",
      "traditional\n",
      "key\n",
      "word\n",
      "based\n",
      "document\n",
      "retrieval\n",
      "the\n",
      "backbone\n",
      "system\n",
      "statistical\n",
      "retrieval\n",
      "engine\n",
      "performs\n",
      "automated\n",
      "indexing\n",
      "docum\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "in\n",
      "paper\n",
      "discus\n",
      "several\n",
      "issue\n",
      "requirement\n",
      "enabling\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      "become\n",
      "context\n",
      "adaptive\n",
      "given\n",
      "fact\n",
      "emerging\n",
      "system\n",
      "feature\n",
      "speaker\n",
      "independent\n",
      "continuous\n",
      "speech\n",
      "recognition\n",
      "restricted\n",
      "individual\n",
      "domain\n",
      "equipped\n",
      "syntactic\n",
      "\n",
      "\n",
      "in\n",
      "fall\n",
      "2004\n",
      "i\n",
      "introduced\n",
      "new\n",
      "course\n",
      "called\n",
      "applied\n",
      "natural\n",
      "language\n",
      "processing\n",
      "student\n",
      "acquire\n",
      "understanding\n",
      "text\n",
      "analysis\n",
      "technique\n",
      "currently\n",
      "feasible\n",
      "practical\n",
      "application\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "abstract\n",
      "natural\n",
      "language\n",
      "processing\n",
      "study\n",
      "mathematical\n",
      "computational\n",
      "modelling\n",
      "various\n",
      "aspect\n",
      "language\n",
      "improvement\n",
      "wide\n",
      "range\n",
      "system\n",
      "natural\n",
      "language\n",
      "language\n",
      "arises\n",
      "innate\n",
      "facility\n",
      "language\n",
      "possessed\n",
      "human\n",
      "intellect\n",
      "may\n",
      "\n",
      "\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "branch\n",
      "artificial\n",
      "intelligence\n",
      "includes\n",
      "speech\n",
      "synthesis\n",
      "speech\n",
      "recognition\n",
      "machine\n",
      "translation\n",
      "natural\n",
      "language\n",
      "processing\n",
      "wide\n",
      "range\n",
      "application\n",
      "indian\n",
      "context\n",
      "most\n",
      "rural\n",
      "indian\n",
      "community\n",
      "unable\n",
      "make\n",
      "use\n",
      "th\n",
      "\n",
      "\n",
      "an\n",
      "evaluation\n",
      "lolita\n",
      "related\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      "paul\n",
      "callaghan\n",
      "submitted\n",
      "university\n",
      "durham\n",
      "degree\n",
      "ph\n",
      "d\n",
      "august\n",
      "1997\n",
      "this\n",
      "research\n",
      "address\n",
      "question\n",
      "evaluate\n",
      "system\n",
      "like\n",
      "lolita\n",
      "lolita\n",
      "natural\n",
      "\n",
      "\n",
      "previous\n",
      "work\n",
      "demonstrated\n",
      "web\n",
      "count\n",
      "used\n",
      "approximate\n",
      "bigram\n",
      "count\n",
      "suggesting\n",
      "web\n",
      "based\n",
      "frequency\n",
      "useful\n",
      "wide\n",
      "variety\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "task\n",
      "however\n",
      "limited\n",
      "number\n",
      "task\n",
      "far\n",
      "tested\n",
      "using\n",
      "web\n",
      "scale\n",
      "data\n",
      "set\n",
      "the\n",
      "pr\n",
      "\n",
      "\n",
      "this\n",
      "chapter\n",
      "examines\n",
      "application\n",
      "natural\n",
      "language\n",
      "processing\n",
      "computerassisted\n",
      "language\n",
      "learning\n",
      "including\n",
      "history\n",
      "work\n",
      "field\n",
      "last\n",
      "thirtyfive\n",
      "year\n",
      "focus\n",
      "current\n",
      "development\n",
      "opportunity\n",
      "16\n",
      "1\n",
      "introduction\n",
      "this\n",
      "chapter\n",
      "focus\n",
      "application\n",
      "\n",
      "\n",
      "this\n",
      "paper\n",
      "describes\n",
      "natural\n",
      "language\n",
      "system\n",
      "improves\n",
      "performance\n",
      "learning\n",
      "the\n",
      "system\n",
      "process\n",
      "short\n",
      "english\n",
      "narrative\n",
      "able\n",
      "acquire\n",
      "single\n",
      "narrative\n",
      "new\n",
      "schema\n",
      "stereotypical\n",
      "set\n",
      "action\n",
      "during\n",
      "understanding\n",
      "process\n",
      "system\n",
      "attempt\n",
      "\n",
      "\n",
      "we\n",
      "classify\n",
      "review\n",
      "current\n",
      "approach\n",
      "software\n",
      "infrastructure\n",
      "research\n",
      "development\n",
      "delivery\n",
      "nlp\n",
      "system\n",
      "the\n",
      "task\n",
      "\n",
      "\n",
      "confidence\n",
      "measure\n",
      "practical\n",
      "solution\n",
      "improving\n",
      "usefulness\n",
      "natural\n",
      "language\n",
      "processing\n",
      "application\n",
      "confidence\n",
      "estimation\n",
      "generic\n",
      "machine\n",
      "learning\n",
      "approach\n",
      "deriving\n",
      "confidence\n",
      "measure\n",
      "we\n",
      "give\n",
      "overview\n",
      "application\n",
      "confidence\n",
      "estimation\n",
      "various\n",
      "field\n",
      "n\n",
      "\n",
      "\n",
      "lex\n",
      "sign\n",
      "sense\n",
      "id\n",
      "sense\n",
      "id\n",
      "dictionary\n",
      "ldoce\n",
      "lex\n",
      "sign\n",
      "sense\n",
      "id\n",
      "sense\n",
      "id\n",
      "ldb\n",
      "entry\n",
      "12364\n",
      "lex\n",
      "sign\n",
      "sense\n",
      "id\n",
      "sense\n",
      "id\n",
      "sense\n",
      "0\n",
      "when\n",
      "loaded\n",
      "lkb\n",
      "9\n",
      "expanded\n",
      "fully\n",
      "fledged\n",
      "representation\n",
      "transitive\n",
      "use\n",
      "e\n",
      "\n",
      "\n",
      "we\n",
      "describe\n",
      "design\n",
      "use\n",
      "stanford\n",
      "corenlp\n",
      "toolkit\n",
      "extensible\n",
      "pipeline\n",
      "provides\n",
      "core\n",
      "natural\n",
      "lan\n",
      "guage\n",
      "analysis\n",
      "this\n",
      "toolkit\n",
      "quite\n",
      "widely\n",
      "used\n",
      "research\n",
      "nlp\n",
      "community\n",
      "also\n",
      "among\n",
      "commercial\n",
      "govern\n",
      "ment\n",
      "user\n",
      "open\n",
      "source\n",
      "nlp\n",
      "technol\n",
      "ogy\n",
      "we\n",
      "suggest\n",
      "\n",
      "\n",
      "gaussian\n",
      "process\n",
      "gps\n",
      "powerful\n",
      "mod\n",
      "elling\n",
      "framework\n",
      "incorporating\n",
      "kernel\n",
      "bayesian\n",
      "inference\n",
      "recognised\n",
      "state\n",
      "art\n",
      "many\n",
      "machine\n",
      "learning\n",
      "task\n",
      "\n",
      "\n",
      "a\n",
      "fundamental\n",
      "issue\n",
      "natural\n",
      "language\n",
      "processing\n",
      "prerequisite\n",
      "enormous\n",
      "quantity\n",
      "preprogrammed\n",
      "knowledge\n",
      "concerning\n",
      "language\n",
      "domain\n",
      "examination\n",
      "manual\n",
      "acquisition\n",
      "knowledge\n",
      "tedious\n",
      "error\n",
      "prone\n",
      "development\n",
      "automated\n",
      "acquisition\n",
      "process\n",
      "\n",
      "\n",
      "a\n",
      "general\n",
      "reusable\n",
      "computational\n",
      "resource\n",
      "de\n",
      "veloped\n",
      "within\n",
      "penman\n",
      "text\n",
      "generation\n",
      "project\n",
      "organizing\n",
      "domain\n",
      "knowledge\n",
      "appropriately\n",
      "linguistic\n",
      "realization\n",
      "this\n",
      "resource\n",
      "called\n",
      "upper\n",
      "model\n",
      "provides\n",
      "domain\n",
      "task\n",
      "independent\n",
      "classification\n",
      "system\n",
      "support\n",
      "\n",
      "\n",
      "kohonen\n",
      "self\n",
      "organizing\n",
      "map\n",
      "som\n",
      "one\n",
      "popular\n",
      "artificial\n",
      "neural\n",
      "network\n",
      "algorithm\n",
      "word\n",
      "category\n",
      "map\n",
      "som\n",
      "organized\n",
      "according\n",
      "word\n",
      "similarity\n",
      "measured\n",
      "similarity\n",
      "short\n",
      "context\n",
      "word\n",
      "conceptually\n",
      "interrelated\n",
      "word\n",
      "tend\n",
      "fall\n",
      "\n",
      "\n",
      "this\n",
      "paper\n",
      "present\n",
      "workbench\n",
      "built\n",
      "priberam\n",
      "informática\n",
      "development\n",
      "company\n",
      "natural\n",
      "language\n",
      "processing\n",
      "technology\n",
      "this\n",
      "workbench\n",
      "includes\n",
      "set\n",
      "linguistic\n",
      "resource\n",
      "software\n",
      "tool\n",
      "applied\n",
      "considerable\n",
      "number\n",
      "practical\n",
      "purpose\n",
      "covering\n",
      "proofing\n",
      "\n",
      "\n",
      "abstract\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "effective\n",
      "approach\n",
      "bringing\n",
      "improvement\n",
      "educational\n",
      "setting\n",
      "implementing\n",
      "nlp\n",
      "involves\n",
      "initiating\n",
      "process\n",
      "learning\n",
      "natural\n",
      "acquisition\n",
      "educational\n",
      "system\n",
      "it\n",
      "based\n",
      "effective\n",
      "approach\n",
      "providing\n",
      "solution\n",
      "f\n",
      "\n",
      "\n",
      "abstract\n",
      "after\n",
      "twenty\n",
      "year\n",
      "disfavor\n",
      "technology\n",
      "returned\n",
      "imitates\n",
      "process\n",
      "brain\n",
      "natural\n",
      "language\n",
      "experiment\n",
      "sejnowski\n",
      "rosenberg\n",
      "1986\n",
      "demonstrate\n",
      "neural\n",
      "network\n",
      "computing\n",
      "architecture\n",
      "learn\n",
      "actual\n",
      "spoken\n",
      "language\n",
      "observe\n",
      "rule\n",
      "pronunciation\n",
      "\n",
      "\n",
      "text\n",
      "statistic\n",
      "frequently\n",
      "used\n",
      "stylometry\n",
      "cryptography\n",
      "study\n",
      "in\n",
      "paper\n",
      "text\n",
      "statistic\n",
      "tool\n",
      "developed\n",
      "iso\n",
      "prolog\n",
      "natural\n",
      "language\n",
      "processing\n",
      "detail\n",
      "given\n",
      "usage\n",
      "21\n",
      "user\n",
      "callable\n",
      "predicate\n",
      "logic\n",
      "limitation\n",
      "program\n",
      "also\n",
      "discussed\n",
      "1\n",
      "\n",
      "\n",
      "we\n",
      "summarize\n",
      "experience\n",
      "using\n",
      "framenet\n",
      "two\n",
      "rather\n",
      "different\n",
      "project\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "we\n",
      "conclude\n",
      "nlp\n",
      "benefit\n",
      "framenet\n",
      "different\n",
      "way\n",
      "sketch\n",
      "problem\n",
      "need\n",
      "overcome\n",
      "1\n",
      "\n",
      "\n",
      "research\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "recent\n",
      "year\n",
      "benefited\n",
      "enormous\n",
      "amount\n",
      "raw\n",
      "textual\n",
      "data\n",
      "available\n",
      "world\n",
      "wide\n",
      "web\n",
      "the\n",
      "presence\n",
      "standard\n",
      "search\n",
      "engine\n",
      "made\n",
      "data\n",
      "accessible\n",
      "computational\n",
      "linguist\n",
      "corpus\n",
      "size\n",
      "never\n",
      "existed\n",
      "befo\n",
      "\n",
      "\n",
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "program\n",
      "confronted\n",
      "various\n",
      "di\n",
      "culties\n",
      "processing\n",
      "html\n",
      "xml\n",
      "document\n",
      "potential\n",
      "produce\n",
      "better\n",
      "result\n",
      "linguistic\n",
      "information\n",
      "annotated\n",
      "source\n",
      "text\n",
      "wehave\n",
      "therefore\n",
      "developed\n",
      "linguistic\n",
      "annotation\n",
      "language\n",
      "lal\n",
      "\n",
      "\n",
      "introduction\n",
      "natural\n",
      "language\n",
      "processing\n",
      "appears\n",
      "surface\n",
      "strongly\n",
      "symbolic\n",
      "activity\n",
      "word\n",
      "symbol\n",
      "stand\n",
      "object\n",
      "concept\n",
      "real\n",
      "world\n",
      "put\n",
      "together\n",
      "sentence\n",
      "obey\n",
      "well\n",
      "specified\n",
      "grammar\n",
      "rule\n",
      "it\n",
      "surprise\n",
      "several\n",
      "decade\n",
      "na\n",
      "\n",
      "\n",
      "abstract\n",
      "diff\n",
      "software\n",
      "program\n",
      "detects\n",
      "difference\n",
      "two\n",
      "data\n",
      "set\n",
      "useful\n",
      "natural\n",
      "language\n",
      "processing\n",
      "this\n",
      "paper\n",
      "show\n",
      "several\n",
      "example\n",
      "application\n",
      "diff\n",
      "they\n",
      "include\n",
      "detection\n",
      "difference\n",
      "two\n",
      "different\n",
      "datasets\n",
      "extraction\n",
      "rewriting\n",
      "rule\n",
      "mer\n",
      "\n",
      "\n",
      "in\n",
      "paper\n",
      "present\n",
      "compare\n",
      "automatically\n",
      "generated\n",
      "title\n",
      "machine\n",
      "translated\n",
      "document\n",
      "using\n",
      "several\n",
      "different\n",
      "statistic\n",
      "based\n",
      "method\n",
      "a\n",
      "naïve\n",
      "bayesian\n",
      "k\n",
      "nearest\n",
      "neighbour\n",
      "tf\n",
      "idf\n",
      "erative\n",
      "expectation\n",
      "maximization\n",
      "method\n",
      "title\n",
      "gen\n",
      "eration\n",
      "applied\n",
      "1000\n",
      "origi\n",
      "\n",
      "\n",
      "9\n",
      "bibliography\n",
      "\n",
      "\n",
      "applying\n",
      "natural\n",
      "language\n",
      "processing\n",
      "technique\n",
      "biomedical\n",
      "text\n",
      "potential\n",
      "aid\n",
      "curation\n",
      "become\n",
      "focus\n",
      "intensive\n",
      "research\n",
      "however\n",
      "developing\n",
      "integrated\n",
      "system\n",
      "address\n",
      "curator\n",
      "real\n",
      "world\n",
      "need\n",
      "studied\n",
      "le\n",
      "rigorously\n",
      "this\n",
      "paper\n",
      "address\n",
      "question\n",
      "\n",
      "\n",
      "example\n",
      "natural\n",
      "language\n",
      "chinese\n",
      "english\n",
      "italian\n",
      "they\n",
      "called\n",
      "natural\n",
      "evolved\n",
      "le\n",
      "natural\n",
      "way\n",
      "without\n",
      "many\n",
      "deliberate\n",
      "consideration\n",
      "this\n",
      "set\n",
      "apart\n",
      "formal\n",
      "language\n",
      "amongst\n",
      "programming\n",
      "language\n",
      "designed\n",
      "\n",
      "\n",
      "a\n",
      "number\n",
      "powerful\n",
      "modelling\n",
      "technique\n",
      "developed\n",
      "recent\n",
      "year\n",
      "compress\n",
      "natural\n",
      "language\n",
      "text\n",
      "the\n",
      "best\n",
      "adaptive\n",
      "model\n",
      "operating\n",
      "character\n",
      "word\n",
      "level\n",
      "able\n",
      "perform\n",
      "almost\n",
      "well\n",
      "human\n",
      "predicting\n",
      "text\n",
      "we\n",
      "show\n",
      "apply\n",
      "character\n",
      "based\n",
      "\n",
      "\n",
      "a\n",
      "semi\n",
      "automated\n",
      "approach\n",
      "design\n",
      "database\n",
      "enhanced\n",
      "erd\n",
      "notation\n",
      "presented\n",
      "it\n",
      "focus\n",
      "early\n",
      "stage\n",
      "database\n",
      "development\n",
      "stage\n",
      "user\n",
      "requirement\n",
      "analysis\n",
      "it\n",
      "supposed\n",
      "used\n",
      "requirement\n",
      "determination\n",
      "stage\n",
      "analysis\n",
      "the\n",
      "approa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "l = WordNetLemmatizer() \n",
    "for i in q1:\n",
    "  for j in i: \n",
    "    print(l.lemmatize(j))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5mmYIfN8eYV"
   },
   "source": [
    "# **Question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsi2y4z88ngX"
   },
   "source": [
    "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
    "\n",
    "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
    "\n",
    "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
    "\n",
    "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQKnPjPDHJHr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\racha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\racha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "x=[]\n",
    "for i in b:\n",
    "  text = word_tokenize(i)\n",
    "  x.append(nltk.pos_tag(text))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn=0\n",
    "cb=0\n",
    "\n",
    "for i in x:\n",
    "  for j,k in i:\n",
    "    \n",
    "    if k==\"NN\":\n",
    "      cn+=1\n",
    "    if k==\"JJ\":\n",
    "      cb+=1\n",
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building graph of deps:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Examining spacy=0.101.0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Examining python=3.7:  50%|#####     | 1/2 [00:00<00:00, 14.91it/s]\n",
      "                                                                   \n",
      "\n",
      "Determining conflicts:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Examining conflict for spacy python:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "                                                                          \n",
      "\n",
      "UnsatisfiableError: The following specifications were found\n",
      "to be incompatible with the existing python installation in your environment:\n",
      "\n",
      "Specifications:\n",
      "\n",
      "  - spacy=0.101.0 -> python[version='2.7.*|3.5.*']\n",
      "\n",
      "Your python: python=3.7\n",
      "\n",
      "If python is on the left-most side of the chain, that's the version you've asked for.\n",
      "When python appears to the right, that indicates that the thing on the left is somehow\n",
      "not available for the python version you are constrained to. Note that conda will not\n",
      "change your python version to a different minor version unless you explicitly specify\n",
      "that.\n",
      "\n",
      "\n",
      "\n",
      "C:\\Users\\racha\\anaconda3\\python.exe: Error while finding module specification for 'spacy.en.download' (ModuleNotFoundError: No module named 'spacy')\n"
     ]
    }
   ],
   "source": [
    "!conda install -c spacy spacy=0.101.0 -y\n",
    "\n",
    "!python -m spacy.en.download\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.0.3-cp37-cp37m-win_amd64.whl (11.6 MB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp37-cp37m-win_amd64.whl (108 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp37-cp37m-win_amd64.whl (20 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Using cached spacy_legacy-3.0.1-py2.py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy) (2.11.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy) (1.5.0)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Using cached typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy) (45.2.0.post20200210)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.3-cp37-cp37m-win_amd64.whl (1.7 MB)\n",
      "Collecting typing-extensions>=3.7.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp37-cp37m-win_amd64.whl (6.5 MB)\n",
      "Collecting pathy\n",
      "  Using cached pathy-0.4.0-py3-none-any.whl (36 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.1\n",
      "  Using cached catalogue-2.0.1-py3-none-any.whl (9.6 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.0-cp37-cp37m-win_amd64.whl (449 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy) (20.1)\n",
      "Collecting thinc<8.1.0,>=8.0.0\n",
      "  Downloading thinc-8.0.1-cp37-cp37m-win_amd64.whl (1.0 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (2.2.0)\n",
      "Collecting click<7.2.0,>=7.1.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Using cached smart_open-3.0.0.tar.gz (113 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\racha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.14.0)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107102 sha256=4ade16d798b9563f59bacdb2dda93d4307859aa6bd4062c5ab2a6d9ad01a8491\n",
      "  Stored in directory: c:\\users\\racha\\appdata\\local\\pip\\cache\\wheels\\83\\a6\\12\\bf3c1a667bde4251be5b7a3368b2d604c9af2105b5c1cb1870\n",
      "Successfully built smart-open\n",
      "Installing collected packages: cymem, murmurhash, preshed, wasabi, spacy-legacy, click, typer, pydantic, typing-extensions, blis, smart-open, pathy, catalogue, srsly, thinc, spacy\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: Click 7.0\n",
      "    Uninstalling Click-7.0:\n",
      "      Successfully uninstalled Click-7.0\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.1 click-7.1.2 cymem-2.0.5 murmurhash-1.0.5 pathy-0.4.0 preshed-3.0.5 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.3 spacy-legacy-3.0.1 srsly-2.4.0 thinc-8.0.1 typer-0.3.2 typing-extensions-3.7.4.3 wasabi-0.8.2\n",
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.42.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.5.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.22.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: pathy in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.18.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\racha\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2019.11.28)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\racha\\anaconda3\\lib\\site-packages (from pathy->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.0.0\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Pleaseuse the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spaCy in c:\\users\\racha\\.conda\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (1.18.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (4.47.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (0.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (0.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (2.24.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (20.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (2.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (2.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (3.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (2.11.2)\n",
      "Requirement already satisfied: pathy in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (0.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (49.2.0.post20200714)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (3.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (0.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (8.0.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (1.7.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from spaCy) (2.4.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\racha\\.conda\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spaCy) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\racha\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\racha\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spaCy) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\racha\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spaCy) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\racha\\.conda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\racha\\.conda\\lib\\site-packages (from packaging>=20.0->spaCy) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\racha\\.conda\\lib\\site-packages (from packaging>=20.0->spaCy) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\racha\\.conda\\lib\\site-packages (from jinja2->spaCy) (1.1.1)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\racha\\.conda\\lib\\site-packages (from pathy->spaCy) (3.0.0)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'spaCy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-c3757cc7ddac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip3 install spaCy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mn_l_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspaCy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en_core_web_sm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_l_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spaCy' is not defined"
     ]
    }
   ],
   "source": [
    "!pip3 install spaCy\n",
    "import spacy\n",
    "n_l_p=spaCy.load(\"en_core_web_sm\")\n",
    "for i in b:\n",
    "  for token in n_l_p(i):\n",
    "    print(token.text,\"=>\",token.pos_,\"=>\",token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWOtvT2rHNWy"
   },
   "source": [
    "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite your explanations of the constituency parsing tree and dependency parsing tree here\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "constituency Parsing Tree: \n",
    "\n",
    "Constituency Parsing is the process of analyzing the sentences by breaking down it into sub-phrases also known as constituents. \n",
    "These sub-phrases belong to a specific category of grammar like NP (noun phrase) and VP(verb phrase).\n",
    "The constituency parse tree is based on the formalism of context-free grammars. In this type of tree, the sentence is divided into constituents, that is, sub-phrases that belong to a specific category in the grammar.\n",
    "A constituency parse tree always contains the words of the sentence as its terminal nodes. Usually, each word has a parent node containing its part-of-speech tag (noun, adjective, verb, etc…), although this may be omitted in other graphical representations.\n",
    "All the other non-terminal nodes represent the constituents of the sentence and are usually one of verb phrase, noun phrase, or prepositional phrase (PP).\n",
    "To sum up, i can say that constituency parsing creates trees containing a syntactical representation of a sentence, according to a context-free grammar. This representation is highly hierarchical and divides the sentences into its single phrasal constituents.\n",
    "\n",
    "Dependency Parsing Tree: \n",
    "\n",
    "Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.The tree generated by dependency parsing is known as a dependency tree.\n",
    "As opposed to constituency parsing, dependency parsing doesn’t make use of phrasal constituents or sub-phrases. Instead, the syntax of the sentence is expressed in terms of dependencies between words\n",
    "In dependency parsing, we try to use dependency-based grammars to analyze and infer both structure and semantic dependencies and relationships between tokens in a sentence. \n",
    "The basic principle behind a dependency grammar is that in any sentence in the language, all words except one, have some relationship or dependency on other words in the sentence. \n",
    "The word that has no dependency is called the root of the sentence. The verb is taken as the root of the sentence in most cases. All the other words are directly or indirectly linked to the root verb using links , which are the dependencies\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNljc+o/lciN8B4S0X1+1d9",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "INFO5731_Assignment_Two.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
